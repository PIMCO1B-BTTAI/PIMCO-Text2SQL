{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sqlite3\n",
    "import io\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path(os.getcwd())\n",
    "parent_dir = str(current_dir.parent)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from typing import Union, List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "schema_path = \"/Users/virounikamina/Desktop/PIMCO-Text2SQL/chatgpt_api/schema.json\"\n",
    "with open(schema_path, 'r') as f:\n",
    "    schema_info = json.load(f)\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Simple Reasonings Schema\n",
    "reasonings_schema_json = json.dumps({\n",
    "    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"thought\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"A thought about the user's question\"\n",
    "            },\n",
    "            \"helpful\": {\n",
    "                \"type\": \"boolean\",\n",
    "                \"description\": \"Whether the thought is helpful to solving the user's question\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "# Simple Final Output Schema\n",
    "final_output_schema_json = json.dumps({\n",
    "    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"user_nlp_query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The original natural language query to be translated into SQL\"\n",
    "        },\n",
    "        \"reasonings\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"thought\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A thought about the user's question\"\n",
    "                    },\n",
    "                    \"helpful\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"Whether the thought is helpful to solving the user's question\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"description\": \"Step-by-step reasoning process for query generation\"\n",
    "        },\n",
    "        \"generated_sql_query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The final SQL query that answers the natural language question\"\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "thought_instructions = f\"\"\"\n",
    "```\n",
    "Thought Instructions:\n",
    "```\n",
    "\n",
    "```\n",
    "Generate thoughts of increasing complexity.\n",
    "Each thought should build on the previous ones and thoughts \n",
    "should progressively cover the nuances of the problem at hand.\n",
    "```\n",
    "\n",
    "```\n",
    "First set of thoughts should be on whether a the query requires \n",
    "Common Table Expressions (CTEs) to calculate the\n",
    "results for sub queries. \n",
    "\n",
    "Prefer using Common Table Expressions rather than\n",
    "case when statements or nested subqueries.\n",
    "\n",
    "If CTEs are required then for each CTE, an analysis of the purpose of each\n",
    "CTE should be done.\n",
    "An overall structure should be outlined as to what will be calculated in \n",
    "each CTE.\n",
    "```\n",
    "\n",
    "```\n",
    "Next set of thoughts should on \n",
    "extracting out the names of as many of \n",
    "the relevant columns as possible for all CTEs and for all the sql clauses such as the \n",
    "`select`, `where` and `group_by` clauses.\n",
    "There might be additions or deletions from this list based on the \n",
    "following additional thoughts to be generated.\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "Generate a thought to figure out the possible phrases in the query \n",
    "which can be used as values of the columns present in the table so as to use them \n",
    "in the `where` clause.\n",
    "```\n",
    "\n",
    "```\n",
    "Generate a thought to compare these extracted values with the list of possible values\n",
    "of columns listed in the information for the columns so as to use the exact string\n",
    "in the `where` clause.\n",
    "```\n",
    "\n",
    "```\n",
    "Generate a thought to reason whether `IS_TOP_TIER_ENTITY` flag is required or not.\n",
    "```\n",
    "\n",
    "```\n",
    "Generate a thought to figure out which time period is being queried.\n",
    "If nothing is specified use `PERIOD_ID = 2023Y`.\n",
    "```\n",
    "\n",
    "```\n",
    "Generate a thought to figure out if a group_by clause is required.\n",
    "Since the table is structured so that for a single entity multiple securities are listed,\n",
    "`group_by` is often required over `INS_ENTITY_NAME_LONG` column.\n",
    "```\n",
    "\n",
    "```\n",
    "The above thoughts about \n",
    "1. phrases for values of columns\n",
    "2. query phrase to column value mapping\n",
    "3. filters such as `IS_TOP_TIER_ENTITY` and others in the where clause\n",
    "4. Period_id value to use\n",
    "5. Group by column\n",
    "\n",
    "should be generated for each of the CTE separately.\n",
    "```\n",
    "\n",
    "```\n",
    "If the input question is similar to any of the examples given above,\n",
    "then a thought should be generated to detect that and then that example \n",
    "should be followed closely to get the SQL for the input question given.\n",
    "```\n",
    "\n",
    "```\n",
    "Closing Thoughts and Observations\n",
    "```\n",
    "These should summarize:\n",
    "1. The structure of the SQL query:\n",
    "    - This states whether the query has any nested query.\n",
    "    If so, the structure of the nested query is also mentioned.\n",
    "    If not, a summary of the function of each of the select`, `where`, `group_by` etc. clauses\n",
    "    should be mentioned.\n",
    "2. An explanation of how the query solves the user question.\n",
    "\"\"\"\n",
    "\n",
    "reasoning_instructions = \"\"\"\n",
    "```\n",
    "1. Reasoning you provide should first focus on why a nested query was chosen or why it wasn't chosen.\n",
    "2. It should give a query plan on how to solve this question - explain \n",
    "the mapping of the columns to the words in the input question.\n",
    "3. It should explain each of the clauses and why they are structured the way they are structured. \n",
    "For example, if there is a `group_by`, an explanation should be given as to why it exists.\n",
    "4. If there's any sum() or any other function used it should be explained as to why it was required.\n",
    "```\n",
    "\n",
    "```\n",
    "Format the generated sql with proper indentation - the columns in the\n",
    "(`select` statement should have more indentation than keyword `select`\n",
    "and so on for each SQL clause.)\n",
    "```\n",
    "\"\"\"\n",
    "def load_schema_from_json() -> dict:\n",
    "    schema_path = \"/Users/virounikamina/Desktop/PIMCO-Text2SQL/chatgpt_api/schema.json\"\n",
    "    try:\n",
    "        with open(schema_path, 'r') as f:\n",
    "            schema = json.load(f)\n",
    "        return schema\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading schema: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "class Background(BaseModel):\n",
    "    \"\"\"A setup description providing context for the user's question\"\"\"\n",
    "    background: str = Field(\n",
    "        description=\"Background for the user's question\",\n",
    "        min_length=10\n",
    "    )\n",
    "\n",
    "class Thought(BaseModel):\n",
    "    \"\"\"A thought about the user's question\"\"\"\n",
    "    thought: str = Field(\n",
    "        description=\"Text of the thought\"\n",
    "    )\n",
    "    helpful: bool = Field(\n",
    "        description=\"Whether the thought is helpful to solving the user's question\"\n",
    "    )\n",
    "\n",
    "class Observation(BaseModel):\n",
    "    \"\"\"An observation summarizing insights from the reasoning process\"\"\"\n",
    "    observation: str = Field(\n",
    "        description=\"An insightful observation on the sequence of thoughts and observations generated so far\"\n",
    "    )\n",
    "\n",
    "class FinalQueryOutput(BaseModel):\n",
    "    \"\"\"Complete output structure containing the query, reasoning, and SQL\"\"\"\n",
    "    user_nlp_query: str = Field(\n",
    "        description=\"The original natural language query to be translated into SQL\"\n",
    "    )\n",
    "    \n",
    "    reasonings: List[Union[Background, Thought, Observation]] = Field(\n",
    "        description=\"Step-by-step reasoning process for query generation\"\n",
    "    )\n",
    "    \n",
    "    generated_sql_query: str = Field(\n",
    "        description=\"The final SQL query that answers the natural language question\"\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"user_nlp_query\": \"Show top funds by total assets\",\n",
    "                \"reasonings\": [\n",
    "                    {\"background\": \"Analyzing fund asset query\"},\n",
    "                    {\"thought\": \"Need to sort by total assets\", \"helpful\": True},\n",
    "                    {\"observation\": \"Simple ranking query required\"}\n",
    "                ],\n",
    "                \"generated_sql_query\": \"SELECT * FROM fund_table ORDER BY total_assets DESC LIMIT 10\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def get_sql(self) -> str:\n",
    "        return self.generated_sql_query\n",
    "\n",
    "    def get_reasoning_steps(self) -> List[str]:\n",
    "        steps = []\n",
    "        for item in self.reasonings:\n",
    "            if isinstance(item, Background):\n",
    "                steps.append(f\"Background: {item.background}\")\n",
    "            elif isinstance(item, Thought):\n",
    "                steps.append(f\"Thought: {item.thought} (Helpful: {item.helpful})\")\n",
    "            elif isinstance(item, Observation):\n",
    "                steps.append(f\"Observation: {item.observation}\")\n",
    "        return steps\n",
    "\n",
    "def load_schema_from_json() -> dict:\n",
    "    schema_path = \"/Users/virounikamina/Desktop/PIMCO-Text2SQL/chatgpt_api/schema.json\"\n",
    "    try:\n",
    "        with open(schema_path, 'r') as f:\n",
    "            schema = json.load(f)\n",
    "        return schema\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading schema: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "def execute_sql(query: str) -> str:\n",
    "    conn = None\n",
    "    try:\n",
    "        db_path = \"/Users/virounikamina/Desktop/PIMCO-Text2SQL/sqlite/nport.db\"\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query)\n",
    "        columns = [description[0] for description in cursor.description]\n",
    "        rows = cursor.fetchall()\n",
    "        output = io.StringIO()\n",
    "        writer = csv.writer(output)\n",
    "        writer.writerow(columns)\n",
    "        writer.writerows(rows)\n",
    "        csv_data = output.getvalue()\n",
    "        output.close()\n",
    "        return csv_data\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {str(e)}\")\n",
    "        raise e\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "def generate_sql(question: str):\n",
    "    system_prompt = f\"\"\"\n",
    "You are the most intelligent person in the world.\n",
    "\n",
    "You will receive a $500 tip if you follow ALL the instructions specified.\n",
    "\n",
    "Instructions:\n",
    "Provide an explanation of why the given sql query is correct based \n",
    "on the input request and the description of the columns.\n",
    "\n",
    "Use step by step reasoning and at each step generate thoughts of increasing complexity.\n",
    "\n",
    "Getting this answer right is important for my career. Please do your best.\n",
    "\"\"\"\n",
    "\n",
    "    # Get schema JSONs\n",
    "    rreasonings_schema_json = reasonings_schema_json\n",
    "    final_output_schema_json = FinalQueryOutput.model_json_schema()\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "Generate a SQL query that retrieves from the database the answer to this question: {question}\n",
    "\n",
    "Database Schema:\n",
    "{schema_info}\n",
    "\n",
    "Use the following JSON Schema as the grammar to create the structure \n",
    "for the step by step reasoning, and then to create the final SQL query.\n",
    "\n",
    "Schema for Reasoning:\n",
    "{reasoning_instructions}\n",
    "{reasonings_schema_json}\n",
    "\n",
    "The instructions on how to structure the reasoning is provided below:\n",
    "{thought_instructions}\n",
    "\n",
    "Schema for Overall Output:\n",
    "{final_output_schema_json}\n",
    "\n",
    "The final response should be a json with names as:\n",
    "- user_nlp_query: exactly the same as the user query in string format\n",
    "- reasonings: reasoning steps adhering to the Reasonings schema\n",
    "- generated_sql_query: the SQL query generated in string format\n",
    "\n",
    "This is the final answer format required.\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "\n",
    "    final_response = response.choices[0].message.content\n",
    "    return final_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use here\n",
    "response = generate_sql(\"List the top 5 PIMCO fund series by total assets\")\n",
    "response_parsed = json.loads(response)\n",
    "print(response)\n",
    "print(response_parsed[\"generated_sql_query\"])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
