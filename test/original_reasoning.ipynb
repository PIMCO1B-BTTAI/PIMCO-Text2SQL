{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sqlite3\n",
    "import io\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path(os.getcwd())\n",
    "parent_dir = str(current_dir.parent)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from typing import Union, List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "schema_path = \"/Users/virounikamina/Desktop/PIMCO-Text2SQL/chatgpt_api/schema.json\"\n",
    "with open(schema_path, 'r') as f:\n",
    "    schema_info = json.load(f)\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Simple Reasonings Schema\n",
    "reasonings_schema_json = json.dumps({\n",
    "    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"thought\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"A thought about the user's question\"\n",
    "            },\n",
    "            \"helpful\": {\n",
    "                \"type\": \"boolean\",\n",
    "                \"description\": \"Whether the thought is helpful to solving the user's question\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "# Simple Final Output Schema\n",
    "final_output_schema_json = json.dumps({\n",
    "    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"user_nlp_query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The original natural language query to be translated into SQL\"\n",
    "        },\n",
    "        \"reasonings\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"thought\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A thought about the user's question\"\n",
    "                    },\n",
    "                    \"helpful\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"Whether the thought is helpful to solving the user's question\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"description\": \"Step-by-step reasoning process for query generation\"\n",
    "        },\n",
    "        \"generated_sql_query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The final SQL query that answers the natural language question\"\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "thought_instructions = f\"\"\"\n",
    "```\n",
    "Thought Instructions:\n",
    "```\n",
    "\n",
    "```\n",
    "Generate thoughts of increasing complexity.\n",
    "Each thought should build on the previous ones and thoughts \n",
    "should progressively cover the nuances of the problem at hand.\n",
    "```\n",
    "\n",
    "```\n",
    "First set of thoughts should be on whether a the query requires \n",
    "Common Table Expressions (CTEs) to calculate the\n",
    "results for sub queries. \n",
    "\n",
    "Prefer using Common Table Expressions rather than\n",
    "case when statements or nested subqueries.\n",
    "\n",
    "If CTEs are required then for each CTE, an analysis of the purpose of each\n",
    "CTE should be done.\n",
    "An overall structure should be outlined as to what will be calculated in \n",
    "each CTE.\n",
    "```\n",
    "\n",
    "```\n",
    "Next set of thoughts should on \n",
    "extracting out the names of as many of \n",
    "the relevant columns as possible for all CTEs and for all the sql clauses such as the \n",
    "`select`, `where` and `group_by` clauses.\n",
    "There might be additions or deletions from this list based on the \n",
    "following additional thoughts to be generated.\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "Generate a thought to figure out the possible phrases in the query \n",
    "which can be used as values of the columns present in the table so as to use them \n",
    "in the `where` clause.\n",
    "```\n",
    "\n",
    "```\n",
    "Generate a thought to compare these extracted values with the list of possible values\n",
    "of columns listed in the information for the columns so as to use the exact string\n",
    "in the `where` clause.\n",
    "```\n",
    "\n",
    "```\n",
    "Generate a thought to reason whether `IS_TOP_TIER_ENTITY` flag is required or not.\n",
    "```\n",
    "\n",
    "```\n",
    "Generate a thought to figure out which time period is being queried.\n",
    "If nothing is specified use `PERIOD_ID = 2023Y`.\n",
    "```\n",
    "\n",
    "```\n",
    "Generate a thought to figure out if a group_by clause is required.\n",
    "Since the table is structured so that for a single entity multiple securities are listed,\n",
    "`group_by` is often required over `INS_ENTITY_NAME_LONG` column.\n",
    "```\n",
    "\n",
    "```\n",
    "The above thoughts about \n",
    "1. phrases for values of columns\n",
    "2. query phrase to column value mapping\n",
    "3. filters such as `IS_TOP_TIER_ENTITY` and others in the where clause\n",
    "4. Period_id value to use\n",
    "5. Group by column\n",
    "\n",
    "should be generated for each of the CTE separately.\n",
    "```\n",
    "\n",
    "```\n",
    "If the input question is similar to any of the examples given above,\n",
    "then a thought should be generated to detect that and then that example \n",
    "should be followed closely to get the SQL for the input question given.\n",
    "```\n",
    "\n",
    "```\n",
    "Closing Thoughts and Observations\n",
    "```\n",
    "These should summarize:\n",
    "1. The structure of the SQL query:\n",
    "    - This states whether the query has any nested query.\n",
    "    If so, the structure of the nested query is also mentioned.\n",
    "    If not, a summary of the function of each of the select`, `where`, `group_by` etc. clauses\n",
    "    should be mentioned.\n",
    "2. An explanation of how the query solves the user question.\n",
    "\"\"\"\n",
    "\n",
    "reasoning_instructions = \"\"\"\n",
    "```\n",
    "1. Reasoning you provide should first focus on why a nested query was chosen or why it wasn't chosen.\n",
    "2. It should give a query plan on how to solve this question - explain \n",
    "the mapping of the columns to the words in the input question.\n",
    "3. It should explain each of the clauses and why they are structured the way they are structured. \n",
    "For example, if there is a `group_by`, an explanation should be given as to why it exists.\n",
    "4. If there's any sum() or any other function used it should be explained as to why it was required.\n",
    "```\n",
    "\n",
    "```\n",
    "Format the generated sql with proper indentation - the columns in the\n",
    "(`select` statement should have more indentation than keyword `select`\n",
    "and so on for each SQL clause.)\n",
    "```\n",
    "\"\"\"\n",
    "def load_schema_from_json() -> dict:\n",
    "    schema_path = \"/Users/virounikamina/Desktop/PIMCO-Text2SQL/chatgpt_api/schema.json\"\n",
    "    try:\n",
    "        with open(schema_path, 'r') as f:\n",
    "            schema = json.load(f)\n",
    "        return schema\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading schema: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "class Background(BaseModel):\n",
    "    \"\"\"A setup description providing context for the user's question\"\"\"\n",
    "    background: str = Field(\n",
    "        description=\"Background for the user's question\",\n",
    "        min_length=10\n",
    "    )\n",
    "\n",
    "class Thought(BaseModel):\n",
    "    \"\"\"A thought about the user's question\"\"\"\n",
    "    thought: str = Field(\n",
    "        description=\"Text of the thought\"\n",
    "    )\n",
    "    helpful: bool = Field(\n",
    "        description=\"Whether the thought is helpful to solving the user's question\"\n",
    "    )\n",
    "\n",
    "class Observation(BaseModel):\n",
    "    \"\"\"An observation summarizing insights from the reasoning process\"\"\"\n",
    "    observation: str = Field(\n",
    "        description=\"An insightful observation on the sequence of thoughts and observations generated so far\"\n",
    "    )\n",
    "\n",
    "class FinalOutput(BaseModel):\n",
    "    \"\"\"Complete output structure containing the query, reasoning, and SQL\"\"\"\n",
    "    user_nlp_query: str = Field(\n",
    "        description=\"The original natural language query to be translated into SQL\"\n",
    "    )\n",
    "    reasonings: List[Thought] = Field(\n",
    "        description=\"Step-by-step reasoning process for query generation\"\n",
    "    )\n",
    "    generated_sql_query: str = Field(\n",
    "        description=\"The final SQL query that answers the natural language question\"\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"user_nlp_query\": \"Show top funds by total assets\",\n",
    "                \"reasonings\": [\n",
    "                    {\"background\": \"Analyzing fund asset query\"},\n",
    "                    {\"thought\": \"Need to sort by total assets\", \"helpful\": True},\n",
    "                    {\"observation\": \"Simple ranking query required\"}\n",
    "                ],\n",
    "                \"generated_sql_query\": \"SELECT * FROM fund_table ORDER BY total_assets DESC LIMIT 10\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def get_sql(self) -> str:\n",
    "        return self.generated_sql_query\n",
    "\n",
    "    def get_reasoning_steps(self) -> List[str]:\n",
    "        steps = []\n",
    "        for item in self.reasonings:\n",
    "            if isinstance(item, Background):\n",
    "                steps.append(f\"Background: {item.background}\")\n",
    "            elif isinstance(item, Thought):\n",
    "                steps.append(f\"Thought: {item.thought} (Helpful: {item.helpful})\")\n",
    "            elif isinstance(item, Observation):\n",
    "                steps.append(f\"Observation: {item.observation}\")\n",
    "        return steps\n",
    "\n",
    "def load_schema_from_json() -> dict:\n",
    "    schema_path = \"/Users/virounikamina/Desktop/PIMCO-Text2SQL/chatgpt_api/schema.json\"\n",
    "    try:\n",
    "        with open(schema_path, 'r') as f:\n",
    "            schema = json.load(f)\n",
    "        return schema\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading schema: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "def execute_sql(query: str) -> str:\n",
    "    conn = None\n",
    "    try:\n",
    "        db_path = \"/Users/virounikamina/Desktop/PIMCO-Text2SQL/sqlite/nport.db\"\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query)\n",
    "        columns = [description[0] for description in cursor.description]\n",
    "        rows = cursor.fetchall()\n",
    "        output = io.StringIO()\n",
    "        writer = csv.writer(output)\n",
    "        writer.writerow(columns)\n",
    "        writer.writerows(rows)\n",
    "        csv_data = output.getvalue()\n",
    "        output.close()\n",
    "        return csv_data\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {str(e)}\")\n",
    "        raise e\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "def generate_sql(question: str, max_retries: int = 3) -> FinalOutput:\n",
    "    system_prompt = f\"\"\"\n",
    "You are the most intelligent person in the world.\n",
    "\n",
    "You will receive a $500 tip if you follow ALL the instructions specified.\n",
    "\n",
    "Instructions:\n",
    "Provide an explanation of why the given sql query is correct based \n",
    "on the input request and the description of the columns.\n",
    "\n",
    "Use step by step reasoning and at each step generate thoughts of increasing complexity.\n",
    "\n",
    "Getting this answer right is important for my career. Please do your best.\n",
    "\"\"\"\n",
    "\n",
    "    final_output_schema_json = FinalOutput.model_json_schema()\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "Generate a SQL query that retrieves from the database the answer to this question: {question}\n",
    "\n",
    "Database Schema:\n",
    "{schema_info}\n",
    "\n",
    "Use the following JSON Schema as the grammar to create the structure \n",
    "for the step by step reasoning, and then to create the final SQL query.\n",
    "\n",
    "Schema for Reasoning:\n",
    "{reasoning_instructions}\n",
    "{reasonings_schema_json}\n",
    "\n",
    "\n",
    "The instructions on how to structure the reasoning is provided below:\n",
    "{thought_instructions}\n",
    "\n",
    "Schema for Overall Output:\n",
    "{final_output_schema_json}\n",
    "\n",
    "The final response should be a json with names as:\n",
    "- user_nlp_query: exactly the same as the user query in string format\n",
    "- reasonings: reasoning steps adhering to the Reasonings schema\n",
    "- generated_sql_query: the SQL query generated in string format\n",
    "\n",
    "This is the final answer format required.\n",
    "\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "\n",
    "            final_response = response.choices[0].message.content\n",
    "            try:\n",
    "                result = json.loads(final_response)\n",
    "                return FinalOutput(\n",
    "                    user_nlp_query=result[\"user_nlp_query\"],\n",
    "                    reasonings=[\n",
    "                        Thought(**thought) for thought in result[\"reasonings\"]\n",
    "                    ],\n",
    "                    generated_sql_query=result[\"generated_sql_query\"]\n",
    "                )\n",
    "            except Exception:\n",
    "                return FinalOutput(\n",
    "                    user_nlp_query=question,\n",
    "                    reasonings=[\n",
    "                        Thought(\n",
    "                            thought=\"Failed to parse response\",\n",
    "                            helpful=False\n",
    "                        )\n",
    "                    ],\n",
    "                    generated_sql_query=\"SELECT 1\"\n",
    "                )\n",
    "        except Exception:\n",
    "            if attempt == max_retries - 1:\n",
    "                return FinalOutput(\n",
    "                    user_nlp_query=question,\n",
    "                    reasonings=[\n",
    "                        Thought(\n",
    "                            thought=\"Error in process\",\n",
    "                            helpful=False\n",
    "                        )\n",
    "                    ],\n",
    "                    generated_sql_query=\"SELECT 1\"\n",
    "                )\n",
    "            continue\n",
    "\n",
    "    return FinalOutput(\n",
    "        user_nlp_query=question,\n",
    "        reasonings=[\n",
    "            Thought(\n",
    "                thought=\"Maximum retries exceeded\",\n",
    "                helpful=False\n",
    "            )\n",
    "        ],\n",
    "        generated_sql_query=\"SELECT 1\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ COLUMN MAPPING\n",
    "\n",
    "from typing import Union, Tuple, List, Optional\n",
    "\n",
    "class CMBackground(BaseModel):\n",
    "    \"\"\"A setup to the background for the user.\"\"\"\n",
    "\n",
    "    background: str = Field(description=\"Background for the user's question\", min_length=10)\n",
    "\n",
    "\n",
    "class CMThought(BaseModel):\n",
    "    \"\"\"A thought about the user's question.\"\"\"\n",
    "\n",
    "    thought: str  = Field(description=\"Text of the thought.\")\n",
    "#     helpful: bool = Field(description=\"Whether the thought is helpful to solving the user's question.\")\n",
    "\n",
    "\n",
    "class CMObservation(BaseModel):\n",
    "    \"\"\"An observation on the sequence of thoughts and observations generated so far.\"\"\"\n",
    "\n",
    "    observation: str = Field(description=\"An insightful observation on the sequence of thoughts and observations generated so far.\")\n",
    "    \n",
    "\n",
    "class CMReasonings(BaseModel):\n",
    "    \"\"\"Returns a detailed reasoning to the user's question.\"\"\"\n",
    "\n",
    "    reasonings: list[Union[CMBackground, CMThought, CMObservation]] = Field(\n",
    "        description=\"Reasonings to solve the users questions.\"\n",
    "        #, min_length=5\n",
    "    )\n",
    "\n",
    "reasonings_schema_json_cm = CMReasonings.model_json_schema()\n",
    "\n",
    "class FinalQueryOutput(BaseModel):\n",
    "    \n",
    "    input_sql_query_1: str = Field(\n",
    "        description=f\"\"\"Returns the exact same first query that the user gave as input.\"\"\")\n",
    "        \n",
    "    input_sql_query_2: str = Field(\n",
    "        description=f\"\"\"Returns the exact same second query that the user gave as input.\"\"\")\n",
    "\n",
    "    reasonings: list[Union[CMBackground, CMThought, CMObservation]] = Field(\n",
    "        description=\"Reasonings to solve the users questions.\"\n",
    "        #, min_length=5\n",
    "    )\n",
    "        \n",
    "    column_mapping_list: List[Tuple[str, str]] = Field(\n",
    "        description=f\"\"\"Returns the list of the corresponding column names in first sql query, sql 1, which\n",
    "        corresponds to the column name in the other sql query, sql 2, as a list of tuple entries\"\"\")\n",
    "    \n",
    "column_mapping_schema_json = FinalQueryOutput.model_json_schema()\n",
    "\n",
    "complete_user_prompts = \"\"\"\n",
    "```\n",
    "Task Overview\n",
    "```\n",
    "Given two sql queries which are supposed to be equivalent, as inputs, \n",
    "the task is to give a column mapping between the output columns in one sql query\n",
    "to the other sql query.\n",
    "\n",
    "The mapping should include any table aliases present in the column names.\n",
    "For example, if one query uses 'COLUMN_NAME' and another uses 'alias.column_name',\n",
    "the mapping should be ['COLUMN_NAME', 'alias.column_name'].\n",
    "```\n",
    "\n",
    "```\n",
    "The mapping is to be generated as a list of tuples.\n",
    "```\n",
    "\n",
    "```\n",
    "For each element of the list which would be a tuple, \n",
    "the first entry in the tuple would be the column name used in sql query 1,\n",
    "and the second entry in the tuple would be the corresponding column name in the sql query 2.\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "reasoning_instructions_cm = \"\"\"\n",
    "```\n",
    "1. Reasoning you provide should first focus on whether the input sql queries contain \n",
    "a nested query or not.\n",
    "2. It should give a plan on how to solve this question.\n",
    "3. It should explain each of the clauses and why they are structured the way they are structured. \n",
    "For example, if there is a `group_by`, an explanation should be given as to why it exists.\n",
    "```\n",
    "\n",
    "```\n",
    "Format the generated sql with proper indentation - the columns in the\n",
    "(`select` statement should have more indentation than keyword `select`\n",
    "and so on for each SQL clause.)\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "thought_instructions_cm= f\"\"\"\n",
    "```\n",
    "Thought Instructions:\n",
    "```\n",
    "\n",
    "```\n",
    "Generate thoughts of increasing complexity.\n",
    "Each thought should build on the previous ones and thoughts \n",
    "should progressively cover the nuances of the problem at hand.\n",
    "```\n",
    "\n",
    "```\n",
    "Generate two separate thoughts, one each for the two input sql queries, \n",
    "to figure out the list of output columns in each of the sql queries.\n",
    "```\n",
    "\n",
    "```\n",
    "Generate a thought to figure out the list of columns in sql query 1\n",
    "which are present in both the sql queries.\n",
    "```\n",
    "\n",
    "```\n",
    "Generate a thought to figure out the list of columns in sql query 1 \n",
    "which are in sql query 1 but \n",
    "which are not present in sql query 2.\n",
    "```\n",
    "\n",
    "```\n",
    "Generate a thought to figure out the list of columns in sql query 1\n",
    "which are in sql query 2 but \n",
    "which are not present in sql query 1.\n",
    "```\n",
    "\n",
    "```\n",
    "If the query uses common table expressions or nested queries, \n",
    "the above thoughts should be generated for each of the CTE separately.\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "Closing Thoughts and Observations\n",
    "```\n",
    "These should summarize:\n",
    "1. The structure of the SQL query:\n",
    "    - This states whether the query has any nested query.\n",
    "    If so, the structure of the nested query is also mentioned.\n",
    "    If not, a summary of the function of each of the select`, `where`, `group_by` etc. clauses\n",
    "    should be mentioned.\n",
    "2. An explanation of why the mapping is correct.\n",
    "\"\"\"\n",
    "\n",
    "reasoning_schema_instructions = f\"\"\"\n",
    "```\n",
    "Use the following JSON Schema as the grammar to create the structure \n",
    "for the step by step reasoning, and then to \n",
    "create the final SQL query.\n",
    "```\n",
    "\n",
    "```\n",
    "Schema for Reasoning:\n",
    "```\n",
    "{reasonings_schema_json_cm}\n",
    "```\n",
    "\n",
    "```\n",
    "The instructions on how to structure the reasoning is provided below:\n",
    "```\n",
    "{thought_instructions_cm}\n",
    "```\n",
    "\n",
    "```\n",
    "Schema for Overall Output:\n",
    "(This includes the reasonings schema above as an element)\n",
    "```\n",
    "{column_mapping_schema_json}\n",
    "```\n",
    "\n",
    "```\n",
    "The final response should be a json with `names` as \n",
    "    `input_sql_query_1`,\n",
    "    `input_sql_query_2`,\n",
    "    `reasonings`,\n",
    "    `column_mapping_list`.\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_user_prompt_for_question(input_sql_query_1, input_sql_query_2, input_table_schema, complete_user_prompts):\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "```\n",
    "Here are the two sql statements that are to be compared:\n",
    "```\n",
    "\n",
    "```\n",
    "SQL Query 1:\n",
    "```\n",
    "{input_sql_query_1}\n",
    "```\n",
    "\n",
    "```\n",
    "SQL Query 2:\n",
    "```\n",
    "{input_sql_query_2}\n",
    "```\n",
    "\n",
    "```\n",
    "Generate a column mapping corresponding to the given input sql queries\n",
    "and the description of the table provided below.\n",
    "```\n",
    "{input_table_schema}\n",
    "```\n",
    "\n",
    "```\n",
    "Here's a more detailed set of instructions:\n",
    "```\n",
    "{complete_user_prompts}\n",
    "```\n",
    "\n",
    "```\n",
    "Reasoning as to why the query is correct:\n",
    "```\n",
    "{reasoning_instructions_cm}\n",
    "\n",
    "\n",
    "{reasoning_schema_instructions}\n",
    "\n",
    "```\n",
    "Response for Column Mapping Generation:\n",
    "```\n",
    "\"\"\"\n",
    "    \n",
    "    return user_prompt\n",
    "\n",
    "\n",
    "def call_openai_model(system_prompt, user_prompt, model_name):\n",
    "\n",
    "    chat_history = [\n",
    "        {\n",
    "            'role': 'system', \n",
    "            'content': system_prompt\n",
    "        },\n",
    "        {\n",
    "            'role': 'user', \n",
    "            'content': user_prompt\n",
    "        }, \n",
    "\n",
    "    ]\n",
    "    \n",
    "    final_response = {}\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model           = model_name, \n",
    "            messages        = chat_history, \n",
    "            response_format = {\"type\":\"json_object\"}\n",
    "        )\n",
    "        \n",
    "        final_response = response.choices[0].message.content\n",
    "    \n",
    "    except Exception:\n",
    "\n",
    "        response = {\n",
    "            \"content\": \"An error occured. Please retry your chat. \\\n",
    "                If you keep getting this error, you may be out of OpenAI \\\n",
    "                completion tokens. Contact #help-ai on slack for assistance.\"\n",
    "        }\n",
    "        return response\n",
    "\n",
    "    return final_response\n",
    "\n",
    "\n",
    "system_prompt_snippet_001 = \"\"\"\n",
    "```\n",
    "You are the most intelligent person in the world.\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_snippet_002 = \"\"\"\n",
    "\n",
    "```\n",
    "You will receive a $500 tip if you follow ALL the instructions specified.\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_snippet_003 = \"\"\"\n",
    "\n",
    "```\n",
    "Instructions\n",
    "```\n",
    "Give a column mapping between two equivalent sql statements\n",
    "which may differ in the names of columns used in the output\n",
    "and may also differ in the structure, but the overall meaning\n",
    "and function of the query is meant to be the same.\n",
    "```\n",
    "\n",
    "```\n",
    "Use step by step reasoning and at each step generate thoughts of increasing complexity.\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_snippet_004 = \"\"\"\n",
    "\n",
    "```\n",
    "Getting this answer right is important for my career. Please do your best.\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "{system_prompt_snippet_001}\n",
    "{system_prompt_snippet_002}\n",
    "{system_prompt_snippet_003}\n",
    "{system_prompt_snippet_004}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT \n",
      "    SERIES_NAME, \n",
      "    CAST(TOTAL_ASSETS AS NUMERIC) AS TOTAL_ASSETS_NUMERIC \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "ORDER BY \n",
      "    TOTAL_ASSETS_NUMERIC DESC \n",
      "LIMIT 10;\n",
      "\n",
      "user_nlp_query='Show top funds by total assets' reasonings=[Thought(thought='Considering whether the query requires Common Table Expressions (CTEs): Since we are interested in extracting a list of top funds based on their total assets, a single straightforward query should suffice. Typically, CTEs are preferable in scenarios where multiple intermediate calculations or recursive operations are needed, neither of which is required here. Thus, a CTE is not necessary.', helpful=True), Thought(thought=\"Mapping columns to the words in the input question: From the database schema, we identify that 'FUND_REPORTED_INFO' contains a column named 'TOTAL_ASSETS'. This maps directly to 'total assets' in the question. For identifying the 'funds', the 'SERIES_NAME' column from the same table can be used to represent the fund identity.\", helpful=True), Thought(thought='Explaining the SELECT clause: The SELECT statement should include the necessary columns to display the fund name (SERIES_NAME) and its corresponding total assets (TOTAL_ASSETS) to present the top funds accurately.', helpful=True), Thought(thought=\"Explaining the ORDER BY clause: To address 'top funds by total assets', an ORDER BY clause is essential. The 'TOTAL_ASSETS' column must be sorted in descending order (using DESC) to ensure that the highest assets appear first, which aligns with the meaning of 'top'.\", helpful=True), Thought(thought=\"Explaining the LIMIT clause: To explicitly show only the 'top' results, a LIMIT clause is recommended. By using LIMIT, we can restrict the output to a defined number of top entries (e.g., top 10), which is a typical approach when not specified.\", helpful=True), Thought(thought=\"Converting TOTAL_ASSETS to a numeric value: Given the schema shows TOTAL_ASSETS as TEXT, it's pivotal to convert it to a numeric type within the query (using CAST or a similar function) for proper sorting by value.\", helpful=True), Thought(thought='Considering potential data format issues: Care should be taken in how TOTAL_ASSETS is stored as TEXT. This requires ensuring the values do not contain formatting like commas or symbols that impede conversion to numeric. However, our primary focus remains on structuring the SQL query correctly.', helpful=True), Thought(thought='Summarizing Query Structure: The query will use SELECT for column retrieval, ORDER BY to sort by the total assets, and potentially LIMIT to focus on the top results.', helpful=True)] generated_sql_query='\\nSELECT \\n    SERIES_NAME, \\n    CAST(TOTAL_ASSETS AS NUMERIC) AS TOTAL_ASSETS_NUMERIC \\nFROM \\n    FUND_REPORTED_INFO \\nORDER BY \\n    TOTAL_ASSETS_NUMERIC DESC \\nLIMIT 10;\\n'\n"
     ]
    }
   ],
   "source": [
    "final_output = generate_sql(\"Show top funds by total assets\")\n",
    "print(final_output.generated_sql_query)\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/virounikamina/Desktop/PIMCO-Text2SQL/test\n"
     ]
    }
   ],
   "source": [
    "curr = os.getcwd()\n",
    "print(curr)\n",
    "output_file = os.path.join(curr, 'og_all_outputs')\n",
    "def append_to_file(output, qnum, filename=output_file):\n",
    "    # Check if file exists\n",
    "    output_filename= filename+str(qnum)+'.txt'\n",
    "    if not os.path.exists(output_filename):\n",
    "        with open(output_filename, 'w') as file:\n",
    "            file.write(\"Test_OG Output Log\\n\")\n",
    "            file.write(\"=\" * 80 + \"\\n\")\n",
    "    # Append the output\n",
    "    with open(output_filename, 'a') as file:\n",
    "        file.write(output + \"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def get_aggregate_columns(sql_query):\n",
    "    \"\"\"\n",
    "    Extract resulting output column names of aggregate functions in the SQL query,\n",
    "    handling duplicates and default naming conventions.\n",
    "    \"\"\"\n",
    "    aggregate_functions = [\"SUM\", \"AVG\", \"COUNT\", \"MAX\", \"MIN\"]\n",
    "    output_columns = []\n",
    "\n",
    "    # Regex to match aggregate functions with optional aliasing\n",
    "    pattern = rf\"({'|'.join(aggregate_functions)})\\((.*?)\\)(?:\\s+AS\\s+([\\w_]+))?\"\n",
    "    \n",
    "    matches = re.findall(pattern, sql_query, re.IGNORECASE)\n",
    "    function_counter = {}  # Track occurrences of each aggregate function\n",
    "    \n",
    "    for func, inner, alias in matches:\n",
    "        func_lower = func.lower()\n",
    "        if alias:  # Explicit alias defined\n",
    "            output_columns.append(alias)\n",
    "        else:  # No alias, use default naming conventions\n",
    "            if func_lower not in function_counter:\n",
    "                function_counter[func_lower] = 0\n",
    "            else:\n",
    "                function_counter[func_lower] += 1\n",
    "            # Generate default name (e.g., sum, sum_1, sum_2, etc.)\n",
    "            if function_counter[func_lower] == 0:\n",
    "                output_columns.append(f\"{func_lower}({inner.strip()})\")  # Default naming for SQLite\n",
    "            else:\n",
    "                output_columns.append(f\"{func_lower}({inner.strip()})_{function_counter[func_lower]}\")  # Add suffix\n",
    "\n",
    "    return output_columns\n",
    "\n",
    "def evaluate_sql_accuracy(generated_sql, ground_truth_sql, generated_csv, ground_truth_csv, qnum):\n",
    "    \"\"\"\n",
    "    Evaluate the accuracy of generated SQL by comparing the resulting CSV files.\n",
    "    \"\"\"\n",
    "    # Load CSV files\n",
    "    gen_df = pd.read_csv(io.StringIO(generated_csv))\n",
    "    gt_df = pd.read_csv(io.StringIO(ground_truth_csv))\n",
    "    \n",
    "    # Ensure all ground truth columns are in the generated DataFrame\n",
    "    for col in gt_df.columns:\n",
    "        if col not in gen_df.columns:\n",
    "            append_to_file(\"False, not all ground truth columns are in generated csv\",qnum)\n",
    "            return False\n",
    "\n",
    "    # Identify resulting output columns of aggregate functions in both SQL queries\n",
    "    gt_agg_columns = get_aggregate_columns(ground_truth_sql)\n",
    "\n",
    "    # Remove aggregate function columns from both DataFrames\n",
    "    gen_df = gen_df.drop(columns=gt_agg_columns, errors='ignore')\n",
    "    gt_df = gt_df.drop(columns=gt_agg_columns, errors='ignore')\n",
    "\n",
    "    # Align columns in the generated DataFrame to match ground truth\n",
    "    gen_subset = gen_df[gt_df.columns]\n",
    "\n",
    "    # Check if rows match exactly\n",
    "    if not gen_subset.equals(gt_df):\n",
    "        append_to_file(\"False, all ground truth columns exist, but rows mismatch\",qnum)\n",
    "        return False  # Row mismatch detected\n",
    "\n",
    "    append_to_file(\"True, all ground truth columns exist, and rows match\", qnum)\n",
    "    return True  # All checks passed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compare_csv_din(ground_truth_query: str, qnum: int) -> bool:\n",
    "    \"\"\"Compare ground truth query results with LLM-generated query results\"\"\"\n",
    "    append_to_file(f\"Ground Truth Query: {ground_truth_query}\", qnum)\n",
    "\n",
    "    final_output = generate_sql(ground_truth_query)\n",
    "    append_to_file(f\"Thoughts: {final_output.reasonings}\", qnum)\n",
    "    append_to_file(f\"SQL: {final_output.generated_sql_query}\", qnum)\n",
    "\n",
    "        \n",
    "    # Add print statements to debug\n",
    "    print(\"About to start column mapping...\")\n",
    "    print(f\"schema_info available: {schema_info is not None}\")\n",
    "    print(f\"complete_user_prompts available: {complete_user_prompts is not None}\")\n",
    "    print(f\"system_prompt available: {system_prompt is not None}\")\n",
    "        \n",
    "    try:\n",
    "        print(\"Getting column mappings prompt...\")\n",
    "        column_mappings_prompt = get_user_prompt_for_question(\n",
    "            ground_truth_query,\n",
    "            final_output,\n",
    "            schema_info,\n",
    "            complete_user_prompts\n",
    "        )\n",
    "\n",
    "        print(\"Calling OpenAI model...\")\n",
    "        column_mappings_response = call_openai_model(\n",
    "            system_prompt=system_prompt,\n",
    "            user_prompt=column_mappings_prompt,\n",
    "            model_name='gpt-4o'\n",
    "        )\n",
    "        \n",
    "        print(\"Parsing response...\")\n",
    "        response_parsed = json.loads(column_mappings_response)\n",
    "        append_to_file(f\"Column Mappings: {json.dumps(response_parsed['column_mapping_list'], indent=2)}\", qnum)\n",
    "        print(\"Column mappings appended to file\")\n",
    "\n",
    "    except Exception as e:\n",
    "        err_string = f\"Error Mapping Columns: {str(e)}\"\n",
    "        print(err_string)\n",
    "        append_to_file(err_string, qnum)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/virounikamina/Desktop/PIMCO-Text2SQL/test\n",
      "Parent directory: /Users/virounikamina/Desktop/PIMCO-Text2SQL\n",
      "Looking for input file at: /Users/virounikamina/Desktop/PIMCO-Text2SQL/query_summary.csv\n",
      "Successfully loaded 119 queries from /Users/virounikamina/Desktop/PIMCO-Text2SQL/query_summary.csv\n",
      "Processing question 1...\n",
      "About to start column mapping...\n",
      "schema_info available: True\n",
      "complete_user_prompts available: True\n",
      "system_prompt available: True\n",
      "Getting column mappings prompt...\n",
      "Calling OpenAI model...\n",
      "Parsing response...\n",
      "Column mappings appended to file\n",
      "Successfully generated log file for question 1\n",
      "Processing question 2...\n",
      "About to start column mapping...\n",
      "schema_info available: True\n",
      "complete_user_prompts available: True\n",
      "system_prompt available: True\n",
      "Getting column mappings prompt...\n",
      "Calling OpenAI model...\n",
      "Parsing response...\n",
      "Column mappings appended to file\n",
      "Successfully generated log file for question 2\n",
      "Processing question 3...\n",
      "About to start column mapping...\n",
      "schema_info available: True\n",
      "complete_user_prompts available: True\n",
      "system_prompt available: True\n",
      "Getting column mappings prompt...\n",
      "Calling OpenAI model...\n",
      "Parsing response...\n",
      "Column mappings appended to file\n",
      "Successfully generated log file for question 3\n",
      "Processing question 4...\n",
      "About to start column mapping...\n",
      "schema_info available: True\n",
      "complete_user_prompts available: True\n",
      "system_prompt available: True\n",
      "Getting column mappings prompt...\n",
      "Calling OpenAI model...\n",
      "Parsing response...\n",
      "Column mappings appended to file\n",
      "Successfully generated log file for question 4\n",
      "Processing question 5...\n",
      "About to start column mapping...\n",
      "schema_info available: True\n",
      "complete_user_prompts available: True\n",
      "system_prompt available: True\n",
      "Getting column mappings prompt...\n",
      "Calling OpenAI model...\n",
      "Parsing response...\n",
      "Column mappings appended to file\n",
      "Successfully generated log file for question 5\n",
      "Processing question 6...\n",
      "About to start column mapping...\n",
      "schema_info available: True\n",
      "complete_user_prompts available: True\n",
      "system_prompt available: True\n",
      "Getting column mappings prompt...\n",
      "Calling OpenAI model...\n",
      "Parsing response...\n",
      "Column mappings appended to file\n",
      "Successfully generated log file for question 6\n",
      "Processing question 7...\n",
      "About to start column mapping...\n",
      "schema_info available: True\n",
      "complete_user_prompts available: True\n",
      "system_prompt available: True\n",
      "Getting column mappings prompt...\n",
      "Calling OpenAI model...\n",
      "Parsing response...\n",
      "Column mappings appended to file\n",
      "Successfully generated log file for question 7\n",
      "Processing question 8...\n",
      "About to start column mapping...\n",
      "schema_info available: True\n",
      "complete_user_prompts available: True\n",
      "system_prompt available: True\n",
      "Getting column mappings prompt...\n",
      "Calling OpenAI model...\n",
      "Parsing response...\n",
      "Column mappings appended to file\n",
      "Successfully generated log file for question 8\n",
      "Processing question 9...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m         \u001b[43mprocess_queries\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[6], line 43\u001b[0m, in \u001b[0;36mprocess_queries\u001b[0;34m(input_file)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing question \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqnum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Call compare_csv_din which now includes the column mapping\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[43mcompare_csv_din\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqnum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully generated log file for question \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqnum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[5], line 75\u001b[0m, in \u001b[0;36mcompare_csv_din\u001b[0;34m(ground_truth_query, qnum)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compare ground truth query results with LLM-generated query results\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m append_to_file(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGround Truth Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mground_truth_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, qnum)\n\u001b[0;32m---> 75\u001b[0m final_output \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m append_to_file(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThoughts: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_output\u001b[38;5;241m.\u001b[39mreasonings\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, qnum)\n\u001b[1;32m     77\u001b[0m append_to_file(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSQL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_output\u001b[38;5;241m.\u001b[39mgenerated_sql_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, qnum)\n",
      "Cell \u001b[0;32mIn[1], line 335\u001b[0m, in \u001b[0;36mgenerate_sql\u001b[0;34m(question, max_retries)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_retries):\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson_object\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m         final_response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/PIMCO-Text2SQL/env/lib/python3.11/site-packages/openai/_utils/_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/PIMCO-Text2SQL/env/lib/python3.11/site-packages/openai/resources/chat/completions.py:815\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    813\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    814\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 815\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/PIMCO-Text2SQL/env/lib/python3.11/site-packages/openai/_base_client.py:1277\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1265\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1272\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1274\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1275\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1276\u001b[0m     )\n\u001b[0;32m-> 1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/PIMCO-Text2SQL/env/lib/python3.11/site-packages/openai/_base_client.py:954\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 954\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/PIMCO-Text2SQL/env/lib/python3.11/site-packages/openai/_base_client.py:990\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    987\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 990\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    996\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/PIMCO-Text2SQL/env/lib/python3.11/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Desktop/PIMCO-Text2SQL/env/lib/python3.11/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/PIMCO-Text2SQL/env/lib/python3.11/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Desktop/PIMCO-Text2SQL/env/lib/python3.11/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/Desktop/PIMCO-Text2SQL/env/lib/python3.11/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    245\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/PIMCO-Text2SQL/env/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/Desktop/PIMCO-Text2SQL/env/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/Desktop/PIMCO-Text2SQL/env/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/PIMCO-Text2SQL/env/lib/python3.11/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Desktop/PIMCO-Text2SQL/env/lib/python3.11/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/Desktop/PIMCO-Text2SQL/env/lib/python3.11/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/PIMCO-Text2SQL/env/lib/python3.11/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Desktop/PIMCO-Text2SQL/env/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/ssl.py:1296\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1294\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1295\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/ssl.py:1169\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Configure paths\n",
    "curr = os.getcwd()\n",
    "parent_dir = os.path.dirname(curr)  # Get parent directory\n",
    "print(f\"Current working directory: {curr}\")\n",
    "print(f\"Parent directory: {parent_dir}\")\n",
    "\n",
    "# Input file path (one directory up)\n",
    "input_file = os.path.join(parent_dir, \"query_summary.csv\")\n",
    "output_file = os.path.join(curr, 'og_all_outputs')\n",
    "\n",
    "print(f\"Looking for input file at: {input_file}\")\n",
    "\n",
    "def append_to_file(output: str, qnum: int, filename=output_file):\n",
    "    \"\"\"Append formatted output to a question-specific file\"\"\"\n",
    "    output_filename = filename + str(qnum) + '.txt'\n",
    "    if not os.path.exists(output_filename):\n",
    "        with open(output_filename, 'w', encoding='utf-8') as file:\n",
    "            file.write(\"Test_Din Output Log\\n\")\n",
    "            file.write(\"=\" * 80 + \"\\n\")\n",
    "    with open(output_filename, 'a', encoding='utf-8') as file:\n",
    "        file.write(output + \"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "\n",
    "def process_queries(input_file: str):\n",
    "    \"\"\"Process queries from CSV and generate output files\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(input_file, encoding='utf-8')\n",
    "        print(f\"Successfully loaded {len(df)} queries from {input_file}\")\n",
    "        \n",
    "        # Ensure these are globally accessible\n",
    "        global schema_info, system_prompt, complete_user_prompts\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            try:\n",
    "                qnum = index + 1\n",
    "                ground_truth_query = row['SQL']  # Adjust column name if needed\n",
    "                \n",
    "                print(f\"Processing question {qnum}...\")\n",
    "                \n",
    "                # Call compare_csv_din which now includes the column mapping\n",
    "                compare_csv_din(ground_truth_query, qnum)\n",
    "                \n",
    "                print(f\"Successfully generated log file for question {qnum}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing question {qnum}: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading input file: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        process_queries(input_file)\n",
    "        print(\"Processing complete!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fatal error: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
