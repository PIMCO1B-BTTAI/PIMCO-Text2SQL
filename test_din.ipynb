{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import compare_csv\n",
    "current_dir = os.path.dirname(os.path.abspath(\"/d/GithubRepos/PIMCO-Text2SQL\"))\n",
    "din_modules_path = os.path.join(current_dir, 'chatgpt_api')\n",
    "sys.path.append(din_modules_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_keys():\n",
    "    \"\"\"Explore potential primary and foreign keys in the database\"\"\"\n",
    "    import sqlite3\n",
    "    \n",
    "    # Connect to database\n",
    "    conn = sqlite3.connect('sqlite/nport.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Get all tables\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "\n",
    "    print(\"Database Key Analysis:\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Analyze each table\n",
    "    for table in tables:\n",
    "        table_name = table[0]\n",
    "        print(f\"\\nTable: {table_name}\")\n",
    "\n",
    "        # Get column info\n",
    "        cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "        columns = cursor.fetchall()\n",
    "        \n",
    "        # Get sample count for potential key columns\n",
    "        for col in columns:\n",
    "            col_name = col[1]\n",
    "            # Check if column name contains potential key indicators\n",
    "            if any(key_term in col_name.lower() for key_term in ['_id', 'accession', 'number']):\n",
    "                cursor.execute(f\"\"\"\n",
    "                    SELECT COUNT(*) total_rows, \n",
    "                           COUNT(DISTINCT {col_name}) unique_values \n",
    "                    FROM {table_name}\n",
    "                    WHERE {col_name} IS NOT NULL\n",
    "                \"\"\")\n",
    "                stats = cursor.fetchone()\n",
    "                print(f\"Column: {col_name}\")\n",
    "                print(f\"Total rows: {stats[0]}\")\n",
    "                print(f\"Unique values: {stats[1]}\")\n",
    "                \n",
    "                # If unique values equals total rows, likely a key\n",
    "                if stats[0] == stats[1] and stats[0] > 0:\n",
    "                    print(\">>> Potential PRIMARY KEY <<<\")\n",
    "\n",
    "        # Look for foreign key relationships\n",
    "        for col in columns:\n",
    "            col_name = col[1]\n",
    "            if col_name == 'ACCESSION_NUMBER':\n",
    "                cursor.execute(f\"\"\"\n",
    "                    SELECT COUNT(*) FROM {table_name} t1\n",
    "                    WHERE EXISTS (\n",
    "                        SELECT 1 FROM FUND_REPORTED_INFO t2 \n",
    "                        WHERE t1.ACCESSION_NUMBER = t2.ACCESSION_NUMBER\n",
    "                    )\n",
    "                \"\"\")\n",
    "                match_count = cursor.fetchone()[0]\n",
    "                if match_count > 0:\n",
    "                    print(f\"Foreign Key: {table_name}.ACCESSION_NUMBER -> FUND_REPORTED_INFO.ACCESSION_NUMBER\")\n",
    "            \n",
    "            elif col_name == 'HOLDING_ID':\n",
    "                cursor.execute(f\"\"\"\n",
    "                    SELECT COUNT(*) FROM {table_name} t1\n",
    "                    WHERE EXISTS (\n",
    "                        SELECT 1 FROM FUND_REPORTED_HOLDING t2 \n",
    "                        WHERE t1.HOLDING_ID = t2.HOLDING_ID\n",
    "                    )\n",
    "                \"\"\")\n",
    "                match_count = cursor.fetchone()[0]\n",
    "                if match_count > 0:\n",
    "                    print(f\"Foreign Key: {table_name}.HOLDING_ID -> FUND_REPORTED_HOLDING.HOLDING_ID\")\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "# Run the analysis\n",
    "explore_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "1. \"List the top 5 registrants by total net assets, including their CIK and country.\"\n",
    "   SQL: \n",
    "   WITH FundAssets AS (\n",
    "       SELECT R.CIK, R.REGISTRANT_NAME, R.COUNTRY, F.NET_ASSETS\n",
    "       FROM REGISTRANT R\n",
    "       JOIN FUND_REPORTED_INFO F ON R.ACCESSION_NUMBER = F.ACCESSION_NUMBER\n",
    "   )\n",
    "   SELECT CIK, REGISTRANT_NAME, COUNTRY, NET_ASSETS\n",
    "   FROM FundAssets\n",
    "   ORDER BY NET_ASSETS DESC\n",
    "   LIMIT 5;\n",
    "\n",
    "2. \"Find all holdings with a fair value level of Level 1 and their corresponding fund names.\"\n",
    "   SQL: \n",
    "   WITH HoldingsCTE AS (\n",
    "       SELECT H.HOLDING_ID, H.ISSUER_NAME, H.FAIR_VALUE_LEVEL, F.SERIES_NAME\n",
    "       FROM FUND_REPORTED_HOLDING H\n",
    "       JOIN FUND_REPORTED_INFO F ON H.ACCESSION_NUMBER = F.ACCESSION_NUMBER\n",
    "       WHERE H.FAIR_VALUE_LEVEL = 'Level 1'\n",
    "   )\n",
    "   SELECT HOLDING_ID, ISSUER_NAME, SERIES_NAME\n",
    "   FROM HoldingsCTE;\n",
    "\n",
    "3. \"Calculate the total collateral amount for repurchase agreements grouped by counterparty.\"\n",
    "   SQL: \n",
    "   WITH CollateralCTE AS (\n",
    "    SELECT RCP.NAME AS Counterparty_Name, SUM(RC.COLLATERAL_AMOUNT) AS Total_Collateral\n",
    "    FROM REPURCHASE_COLLATERAL RC\n",
    "    JOIN REPURCHASE_COUNTERPARTY RCP ON RC.HOLDING_ID = RCP.HOLDING_ID\n",
    "    GROUP BY RCP.NAME\n",
    "   )\n",
    "   SELECT Counterparty_Name, Total_Collateral\n",
    "   FROM CollateralCTE\n",
    "   ORDER BY Total_Collateral DESC;\n",
    "\n",
    "4. \"Locate funds that have both securities lending activities and repurchase agreements.\"\n",
    "   SQL: \n",
    "   WITH SecuritiesLending AS (\n",
    "       SELECT ACCESSION_NUMBER\n",
    "       FROM SECURITIES_LENDING\n",
    "       WHERE IS_LOAN_BY_FUND = 'Y'\n",
    "   ),\n",
    "   RepurchaseAgreements AS (\n",
    "       SELECT ACCESSION_NUMBER\n",
    "       FROM REPURCHASE_AGREEMENT\n",
    "   )\n",
    "   SELECT F.SERIES_NAME\n",
    "   FROM FUND_REPORTED_INFO F\n",
    "   WHERE F.ACCESSION_NUMBER IN (SELECT ACCESSION_NUMBER FROM SecuritiesLending)\n",
    "     AND F.ACCESSION_NUMBER IN (SELECT ACCESSION_NUMBER FROM RepurchaseAgreements);\n",
    "\n",
    "5. \"Find borrowers who have borrowed more than $5,000,000, including their names and LEIs.\"\n",
    "   SQL: \n",
    "   WITH BorrowedAmounts AS (\n",
    "       SELECT BORROWER_ID, SUM(AGGREGATE_VALUE) AS Total_Borrowed\n",
    "       FROM BORROWER\n",
    "       GROUP BY BORROWER_ID\n",
    "       HAVING SUM(AGGREGATE_VALUE) > 5000000\n",
    "   )\n",
    "   SELECT B.NAME, B.LEI, BA.Total_Borrowed\n",
    "   FROM BORROWER B\n",
    "   JOIN BorrowedAmounts BA ON B.BORROWER_ID = BA.BORROWER_ID;\n",
    "\n",
    "6. \"List all derivative counterparties along with the number of derivative instruments they are involved in.\"\n",
    "   SQL: \n",
    "   WITH CounterpartyCounts AS (\n",
    "       SELECT DC.DERIVATIVE_COUNTERPARTY_NAME, COUNT(*) AS Instrument_Count\n",
    "       FROM DERIVATIVE_COUNTERPARTY DC\n",
    "       JOIN FUND_REPORTED_HOLDING H ON DC.HOLDING_ID = H.HOLDING_ID\n",
    "       JOIN DEBT_SECURITY D ON H.HOLDING_ID = D.HOLDING_ID\n",
    "       GROUP BY DC.DERIVATIVE_COUNTERPARTY_NAME\n",
    "   )\n",
    "   SELECT DERIVATIVE_COUNTERPARTY_NAME, Instrument_Count\n",
    "   FROM CounterpartyCounts\n",
    "   ORDER BY Instrument_Count DESC;\n",
    "\n",
    "7. \"Compute the average annualized rate for debt securities grouped by coupon type.\"\n",
    "   SQL: \n",
    "   WITH RateAverages AS (\n",
    "       SELECT DS.COUPON_TYPE, AVG(DS.ANNUALIZED_RATE) AS Avg_Annualized_Rate\n",
    "       FROM DEBT_SECURITY DS\n",
    "       WHERE DS.ANNUALIZED_RATE IS NOT NULL\n",
    "       GROUP BY DS.COUPON_TYPE\n",
    "   )\n",
    "   SELECT COUPON_TYPE, Avg_Annualized_Rate\n",
    "   FROM RateAverages\n",
    "   ORDER BY Avg_Annualized_Rate DESC;\n",
    "\n",
    "8. \"Get funds that have experienced a net decrease in assets over the last three reporting periods.\"\n",
    "   SQL: \n",
    "   WITH AssetChanges AS (\n",
    "       SELECT F.ACCESSION_NUMBER, F.SERIES_NAME, S.REPORT_DATE, F.NET_ASSETS,\n",
    "              LAG(F.NET_ASSETS, 1) OVER (PARTITION BY F.SERIES_NAME ORDER BY S.REPORT_DATE) AS Previous_Period_Assets\n",
    "       FROM FUND_REPORTED_INFO F\n",
    "       JOIN SUBMISSION S ON F.ACCESSION_NUMBER = S.ACCESSION_NUMBER\n",
    "   )\n",
    "   SELECT DISTINCT AC.SERIES_NAME\n",
    "   FROM AssetChanges AC\n",
    "   WHERE AC.NET_ASSETS < AC.Previous_Period_Assets\n",
    "     AND AC.Previous_Period_Assets IS NOT NULL;\n",
    "\n",
    "9. \"Identify issuers with more than three different securities holdings, including their names and CUSIPs.\"\n",
    "   SQL: \n",
    "   WITH IssuerHoldings AS (\n",
    "       SELECT H.ISSUER_NAME, H.ISSUER_CUSIP, COUNT(DISTINCT H.HOLDING_ID) AS Holding_Count\n",
    "       FROM FUND_REPORTED_HOLDING H\n",
    "       GROUP BY H.ISSUER_NAME, H.ISSUER_CUSIP\n",
    "       HAVING COUNT(DISTINCT H.HOLDING_ID) > 3\n",
    "   )\n",
    "   SELECT ISSUER_NAME, ISSUER_CUSIP, Holding_Count\n",
    "   FROM IssuerHoldings\n",
    "   ORDER BY Holding_Count DESC;\n",
    "\n",
    "10. \"Calculate the total notional amount of derivatives per currency and identify the top 3 currencies by notional amount.\"\n",
    "    SQL: \n",
    "    WITH NotionalSums AS (\n",
    "        SELECT ODNA.CURRENCY_CODE, SUM(ODNA.NOTIONAL_AMOUNT) AS Total_Notional\n",
    "        FROM OTHER_DERIV_NOTIONAL_AMOUNT ODNA\n",
    "        GROUP BY ODNA.CURRENCY_CODE\n",
    "    )\n",
    "    SELECT CURRENCY_CODE, Total_Notional\n",
    "    FROM NotionalSums\n",
    "    ORDER BY Total_Notional DESC\n",
    "    LIMIT 3;\n",
    "\n",
    "11. \"List funds with liquidation preferences exceeding their net assets.\"\n",
    "    SQL: \n",
    "    WITH FundPreferences AS (\n",
    "        SELECT F.SERIES_NAME, F.LIQUIDATION_PREFERENCE, F.NET_ASSETS\n",
    "        FROM FUND_REPORTED_INFO F\n",
    "    )\n",
    "    SELECT SERIES_NAME, LIQUIDATION_PREFERENCE, NET_ASSETS\n",
    "    FROM FundPreferences\n",
    "    WHERE LIQUIDATION_PREFERENCE > NET_ASSETS;\n",
    "\n",
    "12. \"Find all convertible securities that are contingent and have a conversion ratio above 1.5.\"\n",
    "    SQL: \n",
    "    WITH ConvertibleCTE AS (\n",
    "        SELECT DS.HOLDING_ID, CSC.CONVERSION_RATIO\n",
    "        FROM DEBT_SECURITY DS\n",
    "        JOIN CONVERTIBLE_SECURITY_CURRENCY CSC ON DS.HOLDING_ID = CSC.HOLDING_ID\n",
    "        WHERE DS.IS_CONVTIBLE_CONTINGENT = 'Y' AND CSC.CONVERSION_RATIO > 1.5\n",
    "    )\n",
    "    SELECT HOLDING_ID, CONVERSION_RATIO\n",
    "    FROM ConvertibleCTE;\n",
    "\n",
    "13. \"Analyze the distribution of asset categories within the top 10 largest funds by total assets.\"\n",
    "    SQL: \n",
    "    WITH TopFunds AS (\n",
    "        SELECT SERIES_NAME, ACCESSION_NUMBER\n",
    "        FROM FUND_REPORTED_INFO\n",
    "        ORDER BY TOTAL_ASSETS DESC\n",
    "        LIMIT 10\n",
    "    ),\n",
    "    AssetDistribution AS (\n",
    "        SELECT H.ASSET_CAT, COUNT(*) AS Category_Count\n",
    "        FROM FUND_REPORTED_HOLDING H\n",
    "        JOIN TopFunds T ON H.ACCESSION_NUMBER = T.ACCESSION_NUMBER\n",
    "        GROUP BY H.ASSET_CAT\n",
    "    )\n",
    "    SELECT ASSET_CAT, Category_Count\n",
    "    FROM AssetDistribution\n",
    "    ORDER BY Category_Count DESC;\n",
    "    \n",
    "14. \"Find the top 10 funds with the highest average monthly returns in the past quarter.\"\n",
    "   SQL: \n",
    "   WITH AvgMonthlyReturn AS (\n",
    "       SELECT ACCESSION_NUMBER, \n",
    "              (MONTHLY_TOTAL_RETURN1 + MONTHLY_TOTAL_RETURN2 + MONTHLY_TOTAL_RETURN3) / 3.0 AS Avg_Return\n",
    "       FROM MONTHLY_TOTAL_RETURN\n",
    "   )\n",
    "   SELECT F.SERIES_NAME, A.ACCESSION_NUMBER, A.Avg_Return\n",
    "   FROM AvgMonthlyReturn A\n",
    "   JOIN FUND_REPORTED_INFO F ON A.ACCESSION_NUMBER = F.ACCESSION_NUMBER\n",
    "   ORDER BY A.Avg_Return DESC\n",
    "   LIMIT 10;\n",
    "\n",
    "15. \"Compare the latest net asset values of the top 5 performing funds.\"\n",
    "    SQL: \n",
    "    WITH TopPerformingFunds AS (\n",
    "        SELECT \n",
    "            ACCESSION_NUMBER, \n",
    "            (MONTHLY_TOTAL_RETURN1 + MONTHLY_TOTAL_RETURN2 + MONTHLY_TOTAL_RETURN3) / 3.0 AS Avg_Return\n",
    "        FROM \n",
    "            MONTHLY_TOTAL_RETURN\n",
    "        ORDER BY \n",
    "            Avg_Return DESC\n",
    "        LIMIT 5\n",
    "    )\n",
    "    SELECT \n",
    "        FR.SERIES_NAME, \n",
    "        FR.NET_ASSETS, \n",
    "        TP.Avg_Return\n",
    "    FROM \n",
    "        TopPerformingFunds TP\n",
    "    JOIN \n",
    "        FUND_REPORTED_INFO FR ON TP.ACCESSION_NUMBER = FR.ACCESSION_NUMBER;\n",
    "\n",
    "16. \"Calculate the overall average return across all funds for the most recent month.\"\n",
    "    SQL: \n",
    "    WITH LatestReturns AS (\n",
    "        SELECT \n",
    "            M.ACCESSION_NUMBER, \n",
    "            M.MONTHLY_TOTAL_RETURN1\n",
    "        FROM \n",
    "            MONTHLY_TOTAL_RETURN M\n",
    "        JOIN \n",
    "            SUBMISSION S ON M.ACCESSION_NUMBER = S.ACCESSION_NUMBER\n",
    "        WHERE \n",
    "            S.REPORT_DATE = (SELECT MAX(REPORT_DATE) FROM SUBMISSION)\n",
    "    )\n",
    "    SELECT \n",
    "        AVG(MONTHLY_TOTAL_RETURN1) AS Average_Return\n",
    "    FROM \n",
    "        LatestReturns;\n",
    "\n",
    "17. \"Find the interest rate risk for each fund and identify those with the highest risk scores.\"\n",
    "    SQL: \n",
    "    WITH InterestRiskScores AS (\n",
    "        SELECT \n",
    "            IR.ACCESSION_NUMBER, \n",
    "            -- Calculating composite risk score by summing absolute values of DV01 and DV100 columns\n",
    "            (ABS(CAST(IR.INTRST_RATE_CHANGE_3MON_DV01 AS FLOAT)) +\n",
    "            ABS(CAST(IR.INTRST_RATE_CHANGE_1YR_DV01 AS FLOAT)) +\n",
    "            ABS(CAST(IR.INTRST_RATE_CHANGE_5YR_DV01 AS FLOAT)) +\n",
    "            ABS(CAST(IR.INTRST_RATE_CHANGE_10YR_DV01 AS FLOAT)) +\n",
    "            ABS(CAST(IR.INTRST_RATE_CHANGE_30YR_DV01 AS FLOAT)) +\n",
    "            ABS(CAST(IR.INTRST_RATE_CHANGE_3MON_DV100 AS FLOAT)) +\n",
    "            ABS(CAST(IR.INTRST_RATE_CHANGE_1YR_DV100 AS FLOAT)) +\n",
    "            ABS(CAST(IR.INTRST_RATE_CHANGE_5YR_DV100 AS FLOAT)) +\n",
    "            ABS(CAST(IR.INTRST_RATE_CHANGE_10YR_DV100 AS FLOAT)) +\n",
    "            ABS(CAST(IR.INTRST_RATE_CHANGE_30YR_DV100 AS FLOAT))\n",
    "            ) AS Composite_Risk_Score\n",
    "        FROM \n",
    "            INTEREST_RATE_RISK IR\n",
    "    )\n",
    "    SELECT \n",
    "        FR.SERIES_NAME, \n",
    "        FR.ACCESSION_NUMBER, \n",
    "        IRS.Composite_Risk_Score\n",
    "    FROM \n",
    "        InterestRiskScores IRS\n",
    "    JOIN \n",
    "        FUND_REPORTED_INFO FR ON IRS.ACCESSION_NUMBER = FR.ACCESSION_NUMBER\n",
    "    ORDER BY \n",
    "        IRS.Composite_Risk_Score DESC\n",
    "    LIMIT 5;\n",
    "\n",
    "18. \"Analyze the composition of fund portfolios by categorizing assets and their total values.\"\n",
    "    SQL: \n",
    "    WITH PortfolioComposition AS (\n",
    "    SELECT \n",
    "        ACCESSION_NUMBER, \n",
    "        ASSET_CAT, \n",
    "        SUM(CAST(CURRENCY_VALUE AS FLOAT)) AS Total_Value\n",
    "    FROM \n",
    "        FUND_REPORTED_HOLDING\n",
    "    GROUP BY \n",
    "        ACCESSION_NUMBER, \n",
    "        ASSET_CAT\n",
    "    )\n",
    "    SELECT \n",
    "        F.SERIES_NAME, \n",
    "        PC.ASSET_CAT, \n",
    "        PC.Total_Value\n",
    "    FROM \n",
    "        PortfolioComposition PC\n",
    "    JOIN \n",
    "        FUND_REPORTED_INFO F ON PC.ACCESSION_NUMBER = F.ACCESSION_NUMBER\n",
    "    ORDER BY \n",
    "        F.SERIES_NAME, \n",
    "        PC.Total_Value DESC;\n",
    "\n",
    "19. \"Identify the most common asset categories across all fund portfolios.\"\n",
    "    SQL: \n",
    "    WITH AssetCounts AS (\n",
    "        SELECT ASSET_CAT, COUNT(*) AS Count\n",
    "        FROM FUND_REPORTED_HOLDING\n",
    "        GROUP BY ASSET_CAT\n",
    "    )\n",
    "    SELECT ASSET_CAT, Count\n",
    "    FROM AssetCounts\n",
    "    ORDER BY Count DESC\n",
    "    LIMIT 5;\n",
    "\n",
    "20. \"Retrieve funds that have experienced a net decrease in assets over the last three reporting periods.\"\n",
    "   SQL: \n",
    "   WITH AssetChanges AS (\n",
    "       SELECT F.ACCESSION_NUMBER, F.SERIES_NAME, S.REPORT_DATE, F.NET_ASSETS,\n",
    "              LAG(F.NET_ASSETS, 1) OVER (PARTITION BY F.SERIES_NAME ORDER BY S.REPORT_DATE) AS Previous_Period_Assets\n",
    "       FROM FUND_REPORTED_Iimport os\n",
    "print(os.getcwd())NFO F\n",
    "       JOIN SUBMISSION S ON F.ACCESSION_NUMBER = S.ACCESSION_NUMBER\n",
    "   )\n",
    "   SELECT DISTINCT AC.SERIES_NAME\n",
    "   FROM AssetChanges AC\n",
    "   WHERE AC.NET_ASSETS < AC.Previous_Period_Assets\n",
    "     AND AC.Previous_Period_Assets IS NOT NULL;\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\"\\s*(.*?)\\s*\"\\s*SQL:\\s*(WITH.*?;)(?=\\n\\s*\\d+|$)'\n",
    "matches = re.findall(pattern, text, re.DOTALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_query = [match[1] for match in matches]\n",
    "llm_query = [match[0] for match in matches]\n",
    "print(\"Queries:\", ground_truth_query)\n",
    "print(\"SQL Statements:\", llm_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "while len(results) < 20:\n",
    "    results.append(None)\n",
    "print(len(results))\n",
    "print(len(llm_query))\n",
    "\n",
    "print(\"Are the following queries the same?\")\n",
    "i=0\n",
    "print(\"i = \", i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if i<len(llm_query):\n",
    "    results[i]=(str(i)+'. '+ str(compare_csv.compare_csv_din(ground_truth_query[i],llm_query[i])))\n",
    "i+=1 #1\n",
    "print(\"i = \", i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/virounikamina/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/virounikamina/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/virounikamina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Loading schema file: chatgpt_api/schema.json\n",
      "\n",
      "DEBUG: Finding matches for 'fund'\n",
      "Found 4 initial candidates\n",
      "Found 4 matches\n",
      "  fund_reported_info: 0.4926\n",
      "  fund_reported_info.credit_spread_3mon_noninvest: 0.4480\n",
      "  fund_reported_holding.is_restricted_security: 0.4456\n",
      "  registrant.cik: 0.4155\n",
      "\n",
      "DEBUG: Finding matches for 'asset'\n",
      "Found 0 initial candidates\n",
      "Found 0 matches\n",
      "\n",
      "DEBUG: Finding matches for '1'\n",
      "Found 0 initial candidates\n",
      "Found 0 matches\n",
      "\n",
      "DEBUG: Finding matches for 'billion'\n",
      "Found 2 initial candidates\n",
      "Found 2 matches\n",
      "  fund_reported_info.sales_flow_mon3: 0.4231\n",
      "  fund_reported_info.sales_flow_mon2: 0.4231\n",
      "\n",
      "DEBUG: Finding matches for 'total'\n",
      "Found 1 initial candidates\n",
      "Found 1 matches\n",
      "  fund_reported_info.series_lei: 0.4170\n",
      "{'extracted_info': {'keyphrases': ['total asset'],\n",
      "                    'keywords': ['funds', 'asset'],\n",
      "                    'named_entities': [],\n",
      "                    'numerical_values': ['1 billion']},\n",
      " 'processed_words': ['fund', 'asset', '1', 'billion', 'total'],\n",
      " 'question': 'Show me all funds with total asset over 1 billion',\n",
      " 'schema_relationships': {'foreign_keys': ['REGISTRANT.ACCESSION_NUMBER = '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'INTEREST_RATE_RISK.ACCESSION_NUMBER '\n",
      "                                           '= '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'BORROWER.ACCESSION_NUMBER = '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'BORROW_AGGREGATE.ACCESSION_NUMBER '\n",
      "                                           '= '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'MONTHLY_TOTAL_RETURN.ACCESSION_NUMBER '\n",
      "                                           '= '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'MONTHLY_RETURN_CAT_INSTRUMENT.ACCESSION_NUMBER '\n",
      "                                           '= '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'FUND_VAR_INFO.ACCESSION_NUMBER = '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'FUND_REPORTED_HOLDING.ACCESSION_NUMBER '\n",
      "                                           '= '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'EXPLANATORY_NOTE.ACCESSION_NUMBER '\n",
      "                                           '= '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'SUBMISSION.ACCESSION_NUMBER = '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'IDENTIFIERS.HOLDING_ID = '\n",
      "                                           'FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'DEBT_SECURITY.HOLDING_ID = '\n",
      "                                           'FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'DEBT_SECURITY_REF_INSTRUMENT.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'CONVERTIBLE_SECURITY_CURRENCY.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'REPURCHASE_AGREEMENT.HOLDING_ID = '\n",
      "                                           'FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'REPURCHASE_COUNTERPARTY.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'REPURCHASE_COLLATERAL.HOLDING_ID = '\n",
      "                                           'FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'DERIVATIVE_COUNTERPARTY.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'SWAPTION_OPTION_WARNT_DERIV.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'DESC_REF_INDEX_BASKET.HOLDING_ID = '\n",
      "                                           'FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'DESC_REF_INDEX_COMPONENT.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'DESC_REF_OTHER.HOLDING_ID = '\n",
      "                                           'FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'FUT_FWD_NONFOREIGNCUR_CONTRACT.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'FWD_FOREIGNCUR_CONTRACT_SWAP.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'NONFOREIGN_EXCHANGE_SWAP.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'FLOATING_RATE_RESET_TENOR.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'OTHER_DERIV.HOLDING_ID = '\n",
      "                                           'FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'OTHER_DERIV_NOTIONAL_AMOUNT.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'SECURITIES_LENDING.HOLDING_ID = '\n",
      "                                           'FUND_REPORTED_HOLDING.HOLDING_ID'],\n",
      "                          'primary_keys': ['SUBMISSION.ACCESSION_NUMBER',\n",
      "                                           'REGISTRANT.ACCESSION_NUMBER',\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'INTEREST_RATE_RISK.ACCESSION_NUMBER',\n",
      "                                           'INTEREST_RATE_RISK.INTEREST_RATE_RISK_ID',\n",
      "                                           'BORROWER.ACCESSION_NUMBER',\n",
      "                                           'BORROWER.BORROWER_ID',\n",
      "                                           'BORROW_AGGREGATE.ACCESSION_NUMBER',\n",
      "                                           'BORROW_AGGREGATE.BORROW_AGGREGATE_ID',\n",
      "                                           'MONTHLY_TOTAL_RETURN.ACCESSION_NUMBER',\n",
      "                                           'MONTHLY_TOTAL_RETURN.MONTHLY_TOTAL_RETURN_ID',\n",
      "                                           'MONTHLY_RETURN_CAT_INSTRUMENT.ACCESSION_NUMBER',\n",
      "                                           'MONTHLY_RETURN_CAT_INSTRUMENT.ASSET_CAT',\n",
      "                                           'MONTHLY_RETURN_CAT_INSTRUMENT.INSTRUMENT_KIND',\n",
      "                                           'FUND_VAR_INFO.ACCESSION_NUMBER',\n",
      "                                           'FUND_REPORTED_HOLDING.ACCESSION_NUMBER',\n",
      "                                           'FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'IDENTIFIERS.HOLDING_ID',\n",
      "                                           'IDENTIFIERS.IDENTIFIERS_ID',\n",
      "                                           'DEBT_SECURITY_REF_INSTRUMENT.HOLDING_ID',\n",
      "                                           'DEBT_SECURITY_REF_INSTRUMENT.DEBT_SECURITY_REF_ID',\n",
      "                                           'CONVERTIBLE_SECURITY_CURRENCY.HOLDING_ID',\n",
      "                                           'CONVERTIBLE_SECURITY_CURRENCY.CONVERTIBLE_SECURITY_ID',\n",
      "                                           'REPURCHASE_AGREEMENT.HOLDING_ID',\n",
      "                                           'REPURCHASE_COUNTERPARTY.HOLDING_ID',\n",
      "                                           'REPURCHASE_COUNTERPARTY.REPURCHASE_COUNTERPARTY_ID',\n",
      "                                           'REPURCHASE_COLLATERAL.HOLDING_ID',\n",
      "                                           'REPURCHASE_COLLATERAL.REPURCHASE_COLLATERAL_ID',\n",
      "                                           'DERIVATIVE_COUNTERPARTY.HOLDING_ID',\n",
      "                                           'DERIVATIVE_COUNTERPARTY.DERIVATIVE_COUNTERPARTY_ID',\n",
      "                                           'SWAPTION_OPTION_WARNT_DERIV.HOLDING_ID',\n",
      "                                           'DESC_REF_INDEX_BASKET.HOLDING_ID',\n",
      "                                           'DESC_REF_INDEX_COMPONENT.HOLDING_ID',\n",
      "                                           'DESC_REF_INDEX_COMPONENT.DESC_REF_INDEX_COMPONENT_ID',\n",
      "                                           'DESC_REF_OTHER.HOLDING_ID',\n",
      "                                           'DESC_REF_OTHER.DESC_REF_OTHER_ID',\n",
      "                                           'FUT_FWD_NONFOREIGNCUR_CONTRACT.HOLDING_ID',\n",
      "                                           'FWD_FOREIGNCUR_CONTRACT_SWAP.HOLDING_ID',\n",
      "                                           'NONFOREIGN_EXCHANGE_SWAP.HOLDING_ID',\n",
      "                                           'FLOATING_RATE_RESET_TENOR.HOLDING_ID',\n",
      "                                           'FLOATING_RATE_RESET_TENOR.RATE_RESET_TENOR_ID',\n",
      "                                           'OTHER_DERIV.HOLDING_ID',\n",
      "                                           'OTHER_DERIV_NOTIONAL_AMOUNT.HOLDING_ID',\n",
      "                                           'OTHER_DERIV_NOTIONAL_AMOUNT.OTHER_DERIV_NOTIONAL_AMOUNT_ID',\n",
      "                                           'SECURITIES_LENDING.HOLDING_ID',\n",
      "                                           'EXPLANATORY_NOTE.ACCESSION_NUMBER',\n",
      "                                           'EXPLANATORY_NOTE.EXPLANATORY_NOTE_ID']},\n",
      " 'similar_matches': {'1': [],\n",
      "                     'asset': [],\n",
      "                     'billion': [('fund_reported_info.sales_flow_mon3',\n",
      "                                  np.float64(0.423081487435128)),\n",
      "                                 ('fund_reported_info.sales_flow_mon2',\n",
      "                                  np.float64(0.4230564059769255))],\n",
      "                     'fund': [('fund_reported_info',\n",
      "                               np.float64(0.4925965946676029)),\n",
      "                              ('fund_reported_info.credit_spread_3mon_noninvest',\n",
      "                               np.float64(0.44797694158955337)),\n",
      "                              ('fund_reported_holding.is_restricted_security',\n",
      "                               np.float64(0.44557996089647334)),\n",
      "                              ('registrant.cik',\n",
      "                               np.float64(0.4154847316449587))],\n",
      "                     'total': [('fund_reported_info.series_lei',\n",
      "                                np.float64(0.41700278283085457))]}}\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from rapidfuzz.distance.Levenshtein import distance\n",
    "import nltk\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "class PSLsh:\n",
    "    def __init__(self, vectors, n_planes=10, n_tables=5, seed: int = 42):\n",
    "        self.n_planes = n_planes\n",
    "        self.n_tables = n_tables\n",
    "        self.hash_tables = [{} for _ in range(n_tables)]\n",
    "        self.random_planes = []\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        for _ in range(n_tables):\n",
    "            planes = np.random.randn(vectors.shape[1], n_planes)\n",
    "            self.random_planes.append(planes)\n",
    "            \n",
    "        self.num_vectors = vectors.shape[0]\n",
    "        self.vectors = vectors\n",
    "        self.build_hash_tables()\n",
    "\n",
    "    def build_hash_tables(self):\n",
    "        for idx in range(self.num_vectors):\n",
    "            vector = self.vectors[idx].toarray()[0]\n",
    "            hashes = self.hash_vector(vector)\n",
    "            for i, h in enumerate(hashes):\n",
    "                if h not in self.hash_tables[i]:\n",
    "                    self.hash_tables[i][h] = []\n",
    "                self.hash_tables[i][h].append(idx)\n",
    "\n",
    "    def hash_vector(self, vector):\n",
    "        hashes = []\n",
    "        for planes in self.random_planes:\n",
    "            projections = np.dot(vector, planes)\n",
    "            hash_code = ''.join(['1' if x > 0 else '0' for x in projections])\n",
    "            hashes.append(hash_code)\n",
    "        return hashes\n",
    "\n",
    "    def query(self, vector):\n",
    "        hashes = self.hash_vector(vector)\n",
    "        candidates = set()\n",
    "        for i, h in enumerate(hashes):\n",
    "            candidates.update(self.hash_tables[i].get(h, []))\n",
    "        return candidates\n",
    "\n",
    "\n",
    "class ValueRetrieval:\n",
    "    def __init__(self, schema_path: str = 'chatgpt_api/schema.json', lsh_seed: int = 42):\n",
    "        load_dotenv()\n",
    "        self.client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "        # Load schema\n",
    "        print(\"DEBUG: Loading schema file:\", schema_path)\n",
    "        with open(schema_path, 'r') as f:\n",
    "            self.schema = json.load(f)\n",
    "\n",
    "        # Initialize lemmatizer and stop words\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        # Build vectorizer and LSH\n",
    "        self.build_vectorizer_and_lsh(seed=lsh_seed)\n",
    "\n",
    "        # Get schema relationships\n",
    "        self.primary_keys, self.foreign_keys = self.discover_schema_relationships()\n",
    "\n",
    "    def build_vectorizer_and_lsh(self, seed: int):\n",
    "        self.vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1, 3), min_df=1, max_df=0.95)\n",
    "        self.term_list = self.get_schema_terms()\n",
    "        self.term_vectors = self.vectorizer.fit_transform(self.term_list)\n",
    "        self.lsh = PSLsh(self.term_vectors, n_planes=10, n_tables=5)\n",
    "\n",
    "    def get_schema_terms(self) -> List[str]:\n",
    "        terms = []\n",
    "        tables = self.schema.get('schema', {}).get('tables', [])\n",
    "        for table in tables:\n",
    "            table_name = table.get('name', '').lower()\n",
    "            terms.append(table_name)\n",
    "            for column in table.get('columns', []):\n",
    "                column_name = column.get('name', '').lower()\n",
    "                terms.append(f\"{table_name}.{column_name}\")\n",
    "        return terms\n",
    "\n",
    "    def discover_schema_relationships(self):\n",
    "        # Define our primary keys and foreign keys here / needs edits (this is based on nport readme)\n",
    "        primary_keys = {\n",
    "            'SUBMISSION': ['ACCESSION_NUMBER'],\n",
    "            'REGISTRANT': ['ACCESSION_NUMBER'],\n",
    "            'FUND_REPORTED_INFO': ['ACCESSION_NUMBER'],\n",
    "            'INTEREST_RATE_RISK': ['ACCESSION_NUMBER', 'INTEREST_RATE_RISK_ID'],\n",
    "            'BORROWER': ['ACCESSION_NUMBER', 'BORROWER_ID'],\n",
    "            'BORROW_AGGREGATE': ['ACCESSION_NUMBER', 'BORROW_AGGREGATE_ID'],\n",
    "            'MONTHLY_TOTAL_RETURN': ['ACCESSION_NUMBER', 'MONTHLY_TOTAL_RETURN_ID'],\n",
    "            'MONTHLY_RETURN_CAT_INSTRUMENT': ['ACCESSION_NUMBER', 'ASSET_CAT', 'INSTRUMENT_KIND'],\n",
    "            'FUND_VAR_INFO': ['ACCESSION_NUMBER'],\n",
    "            'FUND_REPORTED_HOLDING': ['ACCESSION_NUMBER', 'HOLDING_ID'],\n",
    "            'IDENTIFIERS': ['HOLDING_ID', 'IDENTIFIERS_ID'],\n",
    "            'DEBT_SECURITY': [],  \n",
    "            'DEBT_SECURITY_REF_INSTRUMENT': ['HOLDING_ID', 'DEBT_SECURITY_REF_ID'],\n",
    "            'CONVERTIBLE_SECURITY_CURRENCY': ['HOLDING_ID', 'CONVERTIBLE_SECURITY_ID'],\n",
    "            'REPURCHASE_AGREEMENT': ['HOLDING_ID'],\n",
    "            'REPURCHASE_COUNTERPARTY': ['HOLDING_ID', 'REPURCHASE_COUNTERPARTY_ID'],\n",
    "            'REPURCHASE_COLLATERAL': ['HOLDING_ID', 'REPURCHASE_COLLATERAL_ID'],\n",
    "            'DERIVATIVE_COUNTERPARTY': ['HOLDING_ID', 'DERIVATIVE_COUNTERPARTY_ID'],\n",
    "            'SWAPTION_OPTION_WARNT_DERIV': ['HOLDING_ID'],\n",
    "            'DESC_REF_INDEX_BASKET': ['HOLDING_ID'],\n",
    "            'DESC_REF_INDEX_COMPONENT': ['HOLDING_ID', 'DESC_REF_INDEX_COMPONENT_ID'],\n",
    "            'DESC_REF_OTHER': ['HOLDING_ID', 'DESC_REF_OTHER_ID'],\n",
    "            'FUT_FWD_NONFOREIGNCUR_CONTRACT': ['HOLDING_ID'],\n",
    "            'FWD_FOREIGNCUR_CONTRACT_SWAP': ['HOLDING_ID'],\n",
    "            'NONFOREIGN_EXCHANGE_SWAP': ['HOLDING_ID'],\n",
    "            'FLOATING_RATE_RESET_TENOR': ['HOLDING_ID', 'RATE_RESET_TENOR_ID'],\n",
    "            'OTHER_DERIV': ['HOLDING_ID'],\n",
    "            'OTHER_DERIV_NOTIONAL_AMOUNT': ['HOLDING_ID', 'OTHER_DERIV_NOTIONAL_AMOUNT_ID'],\n",
    "            'SECURITIES_LENDING': ['HOLDING_ID'],\n",
    "            'EXPLANATORY_NOTE': ['ACCESSION_NUMBER', 'EXPLANATORY_NOTE_ID']\n",
    "            }\n",
    "\n",
    "     \n",
    "        foreign_keys = [# ACCESSION_NUMBER relationships (all link back to FUND_REPORTED_INFO)\n",
    "            'REGISTRANT.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'INTEREST_RATE_RISK.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'BORROWER.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'BORROW_AGGREGATE.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'MONTHLY_TOTAL_RETURN.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'MONTHLY_RETURN_CAT_INSTRUMENT.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'FUND_VAR_INFO.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'FUND_REPORTED_HOLDING.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'EXPLANATORY_NOTE.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'SUBMISSION.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "\n",
    "            # HOLDING_ID relationships (all link back to FUND_REPORTED_HOLDING)\n",
    "            'IDENTIFIERS.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'DEBT_SECURITY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'DEBT_SECURITY_REF_INSTRUMENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'CONVERTIBLE_SECURITY_CURRENCY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'REPURCHASE_AGREEMENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'REPURCHASE_COUNTERPARTY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'REPURCHASE_COLLATERAL.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'DERIVATIVE_COUNTERPARTY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'SWAPTION_OPTION_WARNT_DERIV.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'DESC_REF_INDEX_BASKET.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'DESC_REF_INDEX_COMPONENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'DESC_REF_OTHER.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'FUT_FWD_NONFOREIGNCUR_CONTRACT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'FWD_FOREIGNCUR_CONTRACT_SWAP.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'NONFOREIGN_EXCHANGE_SWAP.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'FLOATING_RATE_RESET_TENOR.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'OTHER_DERIV.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'OTHER_DERIV_NOTIONAL_AMOUNT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'SECURITIES_LENDING.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID'\n",
    "             ]\n",
    "\n",
    "        formatted_pks = []\n",
    "        for table, keys in primary_keys.items():\n",
    "            for key in keys:\n",
    "                formatted_pks.append(f\"{table}.{key}\")\n",
    "\n",
    "        return formatted_pks, foreign_keys\n",
    "\n",
    "    def find_similar_words(self, word: str) -> List[Tuple[str, float]]:\n",
    "        # Find similar words in the schema with their similarity scores using p-stable LSH\n",
    "        if not word:\n",
    "            return []\n",
    "\n",
    "        word = word.lower()\n",
    "        print(f\"\\nDEBUG: Finding matches for '{word}'\")\n",
    "\n",
    "        word_vector = self.vectorizer.transform([word]).toarray()[0]\n",
    "        candidate_indices = self.lsh.query(word_vector)\n",
    "        print(f\"Found {len(candidate_indices)} initial candidates\")\n",
    "\n",
    "        similarities = []\n",
    "        for idx in candidate_indices:\n",
    "            candidate_term = self.term_list[idx]\n",
    "            candidate_vector = self.term_vectors[idx].toarray()[0]\n",
    "            # Compute Euclidean distance\n",
    "            dist = np.linalg.norm(word_vector - candidate_vector)\n",
    "            sim = 1 / (1 + dist)\n",
    "            similarities.append((candidate_term, sim))\n",
    "\n",
    "        # Sort by similarity\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Print top matches\n",
    "        print(f\"Found {len(similarities)} matches\")\n",
    "        for match, score in similarities[:5]: \n",
    "            print(f\"  {match}: {score:.4f}\")\n",
    "\n",
    "        return similarities[:5]  # Return top 5 matches\n",
    "\n",
    "    def extract_keywords(self, question: str) -> Dict:\n",
    "        system_prompt = \"\"\"You are an expert financial data analyst specializing in natural language understanding and database schema analysis.\n",
    "Your task is to analyze questions about financial data and extract key components that will help in database queries.\n",
    "\n",
    "Objective: Break down the given question into essential components that will help formulate a database query.\n",
    "\n",
    "Instructions:\n",
    "1. Read the question carefully to identify:\n",
    "- Individual keywords that map to database columns or values\n",
    "- Technical terms related to financial data\n",
    "- Named entities (companies, funds, locations)\n",
    "- Numerical thresholds or values\n",
    "\n",
    "2. For each identified element, categorize it as:\n",
    "- keywords: Individual significant words that might match database columns\n",
    "- keyphrases: Multi-word expressions that represent single concepts\n",
    "- named_entities: Specific names of companies, funds, or locations\n",
    "- numerical_values: Any numbers, amounts, or thresholds\n",
    "\n",
    "3. Return a JSON object with these categories.\"\"\"\n",
    "\n",
    "        few_shot_examples = \"\"\"\n",
    "Example Question: \"Which PIMCO funds were registered between 2020 and 2023 with California addresses?\"\n",
    "{\n",
    "    \"keywords\": [\"funds\", \"registered\", \"addresses\"],\n",
    "    \"keyphrases\": [\"PIMCO funds\"],\n",
    "    \"named_entities\": [\"PIMCO\", \"California\"],\n",
    "    \"numerical_values\": [\"2020\", \"2023\"]\n",
    "}\n",
    "\n",
    "Example Question: \"Show me BlackRock funds with total assets over 1 billion managed in New York\"\n",
    "{\n",
    "    \"keywords\": [\"funds\", \"assets\", \"managed\"],\n",
    "    \"keyphrases\": [\"total assets\"],\n",
    "    \"named_entities\": [\"BlackRock\", \"New York\"],\n",
    "    \"numerical_values\": [\"1 billion\"]\n",
    "}\"\"\"\n",
    "\n",
    "        formatted_prompt = system_prompt\n",
    "        user_prompt = f\"Question: \\\"{question}\\\"\\n\\nExtract the key components and return as JSON.\"\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": formatted_prompt},\n",
    "                {\"role\": \"user\", \"content\": few_shot_examples + \"\\n\" + user_prompt}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        return json.loads(response.choices[0].message.content)\n",
    "\n",
    "    def preprocess_text(self, text: str) -> List[str]:\n",
    "        \"\"\"Tokenize and lemmatize input text, removing stop words.\"\"\"\n",
    "        tokens = nltk.word_tokenize(text.lower())\n",
    "        filtered_tokens = [word for word in tokens if word not in self.stop_words and word.isalnum()]\n",
    "        lemmatized_tokens = [self.lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "        return lemmatized_tokens\n",
    "\n",
    "    def process_question(self, question: str) -> Dict:\n",
    "        # Extract keywords using gpt\n",
    "        extracted_info = self.extract_keywords(question)\n",
    "\n",
    "        words = []\n",
    "        for key in ['keywords', 'keyphrases', 'named_entities', 'numerical_values']:\n",
    "            words.extend(extracted_info.get(key, []))\n",
    "\n",
    "        # Preprocess the words (lemmatize, remove stop words)\n",
    "        processed_words = []\n",
    "        for word in words:\n",
    "            processed_words.extend(self.preprocess_text(word))\n",
    "\n",
    "        # Remove duplicates\n",
    "        processed_words = list(set(processed_words))\n",
    "\n",
    "        # Find similar columns for each word\n",
    "        similar_matches = {}\n",
    "        for word in processed_words:\n",
    "            similar_matches[word] = self.find_similar_words(word)\n",
    "\n",
    "        # Combine the results\n",
    "        result = {\n",
    "            \"question\": question,\n",
    "            \"extracted_info\": extracted_info,\n",
    "            \"processed_words\": processed_words,\n",
    "            \"similar_matches\": similar_matches,\n",
    "            \"schema_relationships\": {\n",
    "                \"primary_keys\": self.primary_keys,\n",
    "                \"foreign_keys\": self.foreign_keys\n",
    "            }\n",
    "        }\n",
    "        return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    vr = ValueRetrieval(schema_path='chatgpt_api/schema.json')\n",
    "\n",
    "    question = \"Show me all funds with total asset over 1 billion\"\n",
    "    result = vr.process_question(question)\n",
    "\n",
    "    from pprint import pprint\n",
    "    pprint(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/virounikamina/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/virounikamina/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/virounikamina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Loading schema file: chatgpt_api/schema.json\n",
      "\n",
      "DEBUG: Finding matches for 'fund'\n",
      "\n",
      "DEBUG: Finding matches for 'asset'\n",
      "\n",
      "DEBUG: Finding matches for '1'\n",
      "\n",
      "DEBUG: Finding matches for 'billion'\n",
      "\n",
      "DEBUG: Finding matches for 'total'\n",
      "{'extracted_info': {'keyphrases': ['total asset'],\n",
      "                    'keywords': ['funds', 'asset'],\n",
      "                    'named_entities': [],\n",
      "                    'numerical_values': ['1 billion']},\n",
      " 'processed_words': ['fund', 'asset', '1', 'billion', 'total'],\n",
      " 'question': 'Show me all funds with total asset over 1 billion',\n",
      " 'schema_relationships': {'foreign_keys': ['REGISTRANT.ACCESSION_NUMBER = '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'INTEREST_RATE_RISK.ACCESSION_NUMBER '\n",
      "                                           '= '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'BORROWER.ACCESSION_NUMBER = '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'BORROW_AGGREGATE.ACCESSION_NUMBER '\n",
      "                                           '= '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'MONTHLY_TOTAL_RETURN.ACCESSION_NUMBER '\n",
      "                                           '= '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'MONTHLY_RETURN_CAT_INSTRUMENT.ACCESSION_NUMBER '\n",
      "                                           '= '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'FUND_VAR_INFO.ACCESSION_NUMBER = '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'FUND_REPORTED_HOLDING.ACCESSION_NUMBER '\n",
      "                                           '= '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'EXPLANATORY_NOTE.ACCESSION_NUMBER '\n",
      "                                           '= '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'SUBMISSION.ACCESSION_NUMBER = '\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'IDENTIFIERS.HOLDING_ID = '\n",
      "                                           'FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'DEBT_SECURITY.HOLDING_ID = '\n",
      "                                           'FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'DEBT_SECURITY_REF_INSTRUMENT.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'CONVERTIBLE_SECURITY_CURRENCY.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'REPURCHASE_AGREEMENT.HOLDING_ID = '\n",
      "                                           'FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'REPURCHASE_COUNTERPARTY.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'REPURCHASE_COLLATERAL.HOLDING_ID = '\n",
      "                                           'FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'DERIVATIVE_COUNTERPARTY.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'SWAPTION_OPTION_WARNT_DERIV.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'DESC_REF_INDEX_BASKET.HOLDING_ID = '\n",
      "                                           'FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'DESC_REF_INDEX_COMPONENT.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'DESC_REF_OTHER.HOLDING_ID = '\n",
      "                                           'FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'FUT_FWD_NONFOREIGNCUR_CONTRACT.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'FWD_FOREIGNCUR_CONTRACT_SWAP.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'NONFOREIGN_EXCHANGE_SWAP.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'FLOATING_RATE_RESET_TENOR.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'OTHER_DERIV.HOLDING_ID = '\n",
      "                                           'FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'OTHER_DERIV_NOTIONAL_AMOUNT.HOLDING_ID '\n",
      "                                           '= FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'SECURITIES_LENDING.HOLDING_ID = '\n",
      "                                           'FUND_REPORTED_HOLDING.HOLDING_ID'],\n",
      "                          'primary_keys': ['SUBMISSION.ACCESSION_NUMBER',\n",
      "                                           'REGISTRANT.ACCESSION_NUMBER',\n",
      "                                           'FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
      "                                           'INTEREST_RATE_RISK.ACCESSION_NUMBER',\n",
      "                                           'INTEREST_RATE_RISK.INTEREST_RATE_RISK_ID',\n",
      "                                           'BORROWER.ACCESSION_NUMBER',\n",
      "                                           'BORROWER.BORROWER_ID',\n",
      "                                           'BORROW_AGGREGATE.ACCESSION_NUMBER',\n",
      "                                           'BORROW_AGGREGATE.BORROW_AGGREGATE_ID',\n",
      "                                           'MONTHLY_TOTAL_RETURN.ACCESSION_NUMBER',\n",
      "                                           'MONTHLY_TOTAL_RETURN.MONTHLY_TOTAL_RETURN_ID',\n",
      "                                           'MONTHLY_RETURN_CAT_INSTRUMENT.ACCESSION_NUMBER',\n",
      "                                           'MONTHLY_RETURN_CAT_INSTRUMENT.ASSET_CAT',\n",
      "                                           'MONTHLY_RETURN_CAT_INSTRUMENT.INSTRUMENT_KIND',\n",
      "                                           'FUND_VAR_INFO.ACCESSION_NUMBER',\n",
      "                                           'FUND_REPORTED_HOLDING.ACCESSION_NUMBER',\n",
      "                                           'FUND_REPORTED_HOLDING.HOLDING_ID',\n",
      "                                           'IDENTIFIERS.HOLDING_ID',\n",
      "                                           'IDENTIFIERS.IDENTIFIERS_ID',\n",
      "                                           'DEBT_SECURITY_REF_INSTRUMENT.HOLDING_ID',\n",
      "                                           'DEBT_SECURITY_REF_INSTRUMENT.DEBT_SECURITY_REF_ID',\n",
      "                                           'CONVERTIBLE_SECURITY_CURRENCY.HOLDING_ID',\n",
      "                                           'CONVERTIBLE_SECURITY_CURRENCY.CONVERTIBLE_SECURITY_ID',\n",
      "                                           'REPURCHASE_AGREEMENT.HOLDING_ID',\n",
      "                                           'REPURCHASE_COUNTERPARTY.HOLDING_ID',\n",
      "                                           'REPURCHASE_COUNTERPARTY.REPURCHASE_COUNTERPARTY_ID',\n",
      "                                           'REPURCHASE_COLLATERAL.HOLDING_ID',\n",
      "                                           'REPURCHASE_COLLATERAL.REPURCHASE_COLLATERAL_ID',\n",
      "                                           'DERIVATIVE_COUNTERPARTY.HOLDING_ID',\n",
      "                                           'DERIVATIVE_COUNTERPARTY.DERIVATIVE_COUNTERPARTY_ID',\n",
      "                                           'SWAPTION_OPTION_WARNT_DERIV.HOLDING_ID',\n",
      "                                           'DESC_REF_INDEX_BASKET.HOLDING_ID',\n",
      "                                           'DESC_REF_INDEX_COMPONENT.HOLDING_ID',\n",
      "                                           'DESC_REF_INDEX_COMPONENT.DESC_REF_INDEX_COMPONENT_ID',\n",
      "                                           'DESC_REF_OTHER.HOLDING_ID',\n",
      "                                           'DESC_REF_OTHER.DESC_REF_OTHER_ID',\n",
      "                                           'FUT_FWD_NONFOREIGNCUR_CONTRACT.HOLDING_ID',\n",
      "                                           'FWD_FOREIGNCUR_CONTRACT_SWAP.HOLDING_ID',\n",
      "                                           'NONFOREIGN_EXCHANGE_SWAP.HOLDING_ID',\n",
      "                                           'FLOATING_RATE_RESET_TENOR.HOLDING_ID',\n",
      "                                           'FLOATING_RATE_RESET_TENOR.RATE_RESET_TENOR_ID',\n",
      "                                           'OTHER_DERIV.HOLDING_ID',\n",
      "                                           'OTHER_DERIV_NOTIONAL_AMOUNT.HOLDING_ID',\n",
      "                                           'OTHER_DERIV_NOTIONAL_AMOUNT.OTHER_DERIV_NOTIONAL_AMOUNT_ID',\n",
      "                                           'SECURITIES_LENDING.HOLDING_ID',\n",
      "                                           'EXPLANATORY_NOTE.ACCESSION_NUMBER',\n",
      "                                           'EXPLANATORY_NOTE.EXPLANATORY_NOTE_ID']},\n",
      " 'similar_matches': {'1': None,\n",
      "                     'asset': None,\n",
      "                     'billion': None,\n",
      "                     'fund': None,\n",
      "                     'total': None}}\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from rapidfuzz.distance.Levenshtein import distance\n",
    "from rapidfuzz import fuzz\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "class PSLsh:\n",
    "    def __init__(self, vectors, n_planes=10, n_tables=5, seed: int = 42):\n",
    "        self.n_planes = n_planes\n",
    "        self.n_tables = n_tables\n",
    "        self.hash_tables = [{} for _ in range(n_tables)]\n",
    "        self.random_planes = []\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        for _ in range(n_tables):\n",
    "            planes = np.random.randn(vectors.shape[1], n_planes)\n",
    "            self.random_planes.append(planes)\n",
    "            \n",
    "        self.num_vectors = vectors.shape[0]\n",
    "        self.vectors = vectors\n",
    "        self.build_hash_tables()\n",
    "\n",
    "    def build_hash_tables(self):\n",
    "        for idx in range(self.num_vectors):\n",
    "            vector = self.vectors[idx].toarray()[0]\n",
    "            hashes = self.hash_vector(vector)\n",
    "            for i, h in enumerate(hashes):\n",
    "                if h not in self.hash_tables[i]:\n",
    "                    self.hash_tables[i][h] = []\n",
    "                self.hash_tables[i][h].append(idx)\n",
    "\n",
    "    def hash_vector(self, vector):\n",
    "        hashes = []\n",
    "        for planes in self.random_planes:\n",
    "            projections = np.dot(vector, planes)\n",
    "            hash_code = ''.join(['1' if x > 0 else '0' for x in projections])\n",
    "            hashes.append(hash_code)\n",
    "        return hashes\n",
    "\n",
    "    def query(self, vector):\n",
    "        hashes = self.hash_vector(vector)\n",
    "        candidates = set()\n",
    "        for i, h in enumerate(hashes):\n",
    "            candidates.update(self.hash_tables[i].get(h, []))\n",
    "        return candidates\n",
    "\n",
    "\n",
    "class ValueRetrieval:\n",
    "    financial_terms = {\n",
    "            'total': ['total', 'sum', 'aggregate', 'combined'],\n",
    "            'assets': ['asset', 'holdings', 'investments', 'securities'],\n",
    "            'liabilities': ['liability', 'debt', 'obligations'],\n",
    "            'net': ['net', 'pure', 'adjusted'],\n",
    "            'fund': ['fund', 'portfolio', 'investment vehicle'],\n",
    "            'return': ['return', 'yield', 'profit', 'gain'],\n",
    "            'monthly': ['monthly', 'month', 'monthly basis'],\n",
    "            'rate': ['rate', 'percentage', 'ratio'],\n",
    "            'risk': ['risk', 'exposure', 'vulnerability']\n",
    "        }\n",
    "    def __init__(self, schema_path: str = 'chatgpt_api/schema.json', lsh_seed: int = 42):\n",
    "        load_dotenv()\n",
    "        self.client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "        # Load schema\n",
    "        print(\"DEBUG: Loading schema file:\", schema_path)\n",
    "        with open(schema_path, 'r') as f:\n",
    "            self.schema = json.load(f)\n",
    "\n",
    "        # Initialize lemmatizer and stop words\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        # Build column name index\n",
    "        self.column_index = self._build_column_index()\n",
    "        \n",
    "        # Build common financial terms dictionary\n",
    "        \n",
    "\n",
    "        # Build vectorizer and LSH for backup matching\n",
    "        self.build_vectorizer_and_lsh(seed=lsh_seed)\n",
    "        \n",
    "        # Get schema relationships\n",
    "        self.primary_keys, self.foreign_keys = self.discover_schema_relationships()\n",
    "\n",
    "    def _build_column_index(self) -> Dict:\n",
    "        \"\"\"Build an index of all columns with their metadata.\"\"\"\n",
    "        column_index = {}\n",
    "        tables = self.schema.get('schema', {}).get('tables', [])\n",
    "        \n",
    "        for table in tables:\n",
    "            table_name = table.get('name', '').lower()\n",
    "            for column in table.get('columns', []):\n",
    "                column_name = column.get('name', '').lower()\n",
    "                \n",
    "                # Store both the full qualified name and column properties\n",
    "                qualified_name = f\"{table_name}.{column_name}\"\n",
    "                column_index[qualified_name] = {\n",
    "                    'table': table_name,\n",
    "                    'column': column_name,\n",
    "                    'type': column.get('type', ''),\n",
    "                    'words': self._split_column_name(column_name),\n",
    "                    'synonyms': self._get_column_synonyms(column_name)\n",
    "                }\n",
    "                \n",
    "        return column_index\n",
    "\n",
    "    def _split_column_name(self, column_name: str) -> List[str]:\n",
    "        \"\"\"Split column name into individual words.\"\"\"\n",
    "        # Handle both underscore and camel case\n",
    "        words = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', column_name)).split()\n",
    "        words.extend(column_name.split('_'))\n",
    "        return [word.lower() for word in words if word]\n",
    "\n",
    "    def _get_column_synonyms(self, column_name: str) -> List[str]:\n",
    "        \"\"\"Get synonyms for words in column name.\"\"\"\n",
    "        words = self._split_column_name(column_name)\n",
    "        synonyms = []\n",
    "        \n",
    "        for word in words:\n",
    "            if word in self.financial_terms:\n",
    "                synonyms.extend(self.financial_terms[word])\n",
    "                \n",
    "        return list(set(synonyms))\n",
    "\n",
    "    def build_vectorizer_and_lsh(self, seed: int):\n",
    "        self.vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1, 3), min_df=1, max_df=0.95)\n",
    "        self.term_list = self.get_schema_terms()\n",
    "        self.term_vectors = self.vectorizer.fit_transform(self.term_list)\n",
    "        self.lsh = PSLsh(self.term_vectors, n_planes=10, n_tables=5)\n",
    "\n",
    "    def get_schema_terms(self) -> List[str]:\n",
    "        terms = []\n",
    "        tables = self.schema.get('schema', {}).get('tables', [])\n",
    "        for table in tables:\n",
    "            table_name = table.get('name', '').lower()\n",
    "            terms.append(table_name)\n",
    "            for column in table.get('columns', []):\n",
    "                column_name = column.get('name', '').lower()\n",
    "                terms.append(f\"{table_name}.{column_name}\")\n",
    "        return terms\n",
    "\n",
    "    def discover_schema_relationships(self):\n",
    "        # Define our primary keys and foreign keys here\n",
    "        primary_keys = {\n",
    "            'SUBMISSION': ['ACCESSION_NUMBER'],\n",
    "            'REGISTRANT': ['ACCESSION_NUMBER'],\n",
    "            'FUND_REPORTED_INFO': ['ACCESSION_NUMBER'],\n",
    "            'INTEREST_RATE_RISK': ['ACCESSION_NUMBER', 'INTEREST_RATE_RISK_ID'],\n",
    "            'BORROWER': ['ACCESSION_NUMBER', 'BORROWER_ID'],\n",
    "            'BORROW_AGGREGATE': ['ACCESSION_NUMBER', 'BORROW_AGGREGATE_ID'],\n",
    "            'MONTHLY_TOTAL_RETURN': ['ACCESSION_NUMBER', 'MONTHLY_TOTAL_RETURN_ID'],\n",
    "            'MONTHLY_RETURN_CAT_INSTRUMENT': ['ACCESSION_NUMBER', 'ASSET_CAT', 'INSTRUMENT_KIND'],\n",
    "            'FUND_VAR_INFO': ['ACCESSION_NUMBER'],\n",
    "            'FUND_REPORTED_HOLDING': ['ACCESSION_NUMBER', 'HOLDING_ID'],\n",
    "            'IDENTIFIERS': ['HOLDING_ID', 'IDENTIFIERS_ID'],\n",
    "            'DEBT_SECURITY': [],  \n",
    "            'DEBT_SECURITY_REF_INSTRUMENT': ['HOLDING_ID', 'DEBT_SECURITY_REF_ID'],\n",
    "            'CONVERTIBLE_SECURITY_CURRENCY': ['HOLDING_ID', 'CONVERTIBLE_SECURITY_ID'],\n",
    "            'REPURCHASE_AGREEMENT': ['HOLDING_ID'],\n",
    "            'REPURCHASE_COUNTERPARTY': ['HOLDING_ID', 'REPURCHASE_COUNTERPARTY_ID'],\n",
    "            'REPURCHASE_COLLATERAL': ['HOLDING_ID', 'REPURCHASE_COLLATERAL_ID'],\n",
    "            'DERIVATIVE_COUNTERPARTY': ['HOLDING_ID', 'DERIVATIVE_COUNTERPARTY_ID'],\n",
    "            'SWAPTION_OPTION_WARNT_DERIV': ['HOLDING_ID'],\n",
    "            'DESC_REF_INDEX_BASKET': ['HOLDING_ID'],\n",
    "            'DESC_REF_INDEX_COMPONENT': ['HOLDING_ID', 'DESC_REF_INDEX_COMPONENT_ID'],\n",
    "            'DESC_REF_OTHER': ['HOLDING_ID', 'DESC_REF_OTHER_ID'],\n",
    "            'FUT_FWD_NONFOREIGNCUR_CONTRACT': ['HOLDING_ID'],\n",
    "            'FWD_FOREIGNCUR_CONTRACT_SWAP': ['HOLDING_ID'],\n",
    "            'NONFOREIGN_EXCHANGE_SWAP': ['HOLDING_ID'],\n",
    "            'FLOATING_RATE_RESET_TENOR': ['HOLDING_ID', 'RATE_RESET_TENOR_ID'],\n",
    "            'OTHER_DERIV': ['HOLDING_ID'],\n",
    "            'OTHER_DERIV_NOTIONAL_AMOUNT': ['HOLDING_ID', 'OTHER_DERIV_NOTIONAL_AMOUNT_ID'],\n",
    "            'SECURITIES_LENDING': ['HOLDING_ID'],\n",
    "            'EXPLANATORY_NOTE': ['ACCESSION_NUMBER', 'EXPLANATORY_NOTE_ID']\n",
    "        }\n",
    "\n",
    "        foreign_keys = [\n",
    "            # ACCESSION_NUMBER relationships\n",
    "            'REGISTRANT.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'INTEREST_RATE_RISK.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'BORROWER.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'BORROW_AGGREGATE.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'MONTHLY_TOTAL_RETURN.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'MONTHLY_RETURN_CAT_INSTRUMENT.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'FUND_VAR_INFO.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'FUND_REPORTED_HOLDING.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'EXPLANATORY_NOTE.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'SUBMISSION.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "\n",
    "            # HOLDING_ID relationships\n",
    "            'IDENTIFIERS.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'DEBT_SECURITY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'DEBT_SECURITY_REF_INSTRUMENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'CONVERTIBLE_SECURITY_CURRENCY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'REPURCHASE_AGREEMENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'REPURCHASE_COUNTERPARTY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'REPURCHASE_COLLATERAL.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'DERIVATIVE_COUNTERPARTY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'SWAPTION_OPTION_WARNT_DERIV.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'DESC_REF_INDEX_BASKET.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'DESC_REF_INDEX_COMPONENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'DESC_REF_OTHER.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'FUT_FWD_NONFOREIGNCUR_CONTRACT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'FWD_FOREIGNCUR_CONTRACT_SWAP.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'NONFOREIGN_EXCHANGE_SWAP.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'FLOATING_RATE_RESET_TENOR.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'OTHER_DERIV.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'OTHER_DERIV_NOTIONAL_AMOUNT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'SECURITIES_LENDING.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID'\n",
    "        ]\n",
    "\n",
    "        formatted_pks = []\n",
    "        for table, keys in primary_keys.items():\n",
    "            for key in keys:\n",
    "                formatted_pks.append(f\"{table}.{key}\")\n",
    "\n",
    "        return formatted_pks, foreign_keys\n",
    "\n",
    "    def find_similar_words(self, word: str) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Enhanced matching using multiple techniques.\"\"\"\n",
    "        if not word:\n",
    "            return []\n",
    "\n",
    "        word = word.lower()\n",
    "        print(f\"\\nDEBUG: Finding matches for '{word}'\")\n",
    "        \n",
    "        matches = []\n",
    "        \n",
    "        # 1. Direct matching with column names and their components\n",
    "        for qualified_name, metadata in self.column_index.items():\n",
    "            score = 0.0\n",
    "            \n",
    "            # Check exact matches in column words\n",
    "            if word in metadata['words']:\n",
    "                matches.append((qualified_name, 1.0))\n",
    "                continue\n",
    "                \n",
    "            # Check synonyms\n",
    "            if word in self.financial_terms.get(word, []):\n",
    "                matches.append((qualified_name, 0.9))\n",
    "                continue\n",
    "            \n",
    "            # Fuzzy match with column words\n",
    "            for col_word in metadata['words']:\n",
    "                ratio = fuzz.ratio(word, col_word) / 100.0\n",
    "                if ratio > score:\n",
    "                    score = ratio\n",
    "            \n",
    "            # Fuzzy match with synonyms\n",
    "            for term, synonyms in self.financial_terms.items():\n",
    "                if term in metadata['words']:\n",
    "                    for synonym in synonyms:\n",
    "                        ratio = fuzz.ratio(word, synonym) / 100.0\n",
    "                        if ratio > score:\n",
    "                            score = ratio * 0.9  # Slightly lower weight for synonym matches\n",
    "            \n",
    "            if score > 0.6:  # Only include if similarity is above 60%\n",
    "                matches.append((qualified_name, score))\n",
    "\n",
    "        # 2. LSH-based matching as backup\n",
    "        if len(matches) < 5:  # If we have fewer than 5 matches, try LSH\n",
    "            try:\n",
    "                word_vector = self.vectorizer.transform([word]).toarray()[0]\n",
    "                candidate_indices = self.lsh.query(word_vector)\n",
    "                \n",
    "                for idx in candidate_indices:\n",
    "                    term = self.term_list[idx]\n",
    "                    if not any(term == m[0] for m in matches):  # Avoid duplicates\n",
    "                        candidate_vector = self.term_vectors[idx].toarray()[0]\n",
    "                        dist = np.linalg.norm(word_vector - candidate_vector)\n",
    "                        sim = 1 / (1 + dist)\n",
    "                        if sim > 0.5:  # Only include if similarity is above 50%\n",
    "                            matches.append((term, sim * 0.8))\n",
    "            except Exception as e:\n",
    "                print(f\"LSH matching failed: {e}\")\n",
    "\n",
    "        # Remove duplicates keeping highest score and sort by score\n",
    "        unique_matches = {}\n",
    "        for term, score in matches:\n",
    "            if term not in unique_matches or score > unique_matches[term]:\n",
    "                unique_matches[term] = score\n",
    "        \n",
    "        matches = [(term, score) for term, score in unique_matches.items()]\n",
    "        matches.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Print debug info\n",
    "        print(f\"Found {len(matches)} matches for '{word}':\")\n",
    "        for match, score in matches[:5]:\n",
    "            print(f\"  {match}: {score:.4f}\")\n",
    "        \n",
    "        return matches[:5] if matches else [('fund_reported_info.total_assets', 0.6)] if word in ['total', 'asset', 'assets'] else []\n",
    "\n",
    "    def extract_keywords(self, question: str) -> Dict:\n",
    "        system_prompt = \"\"\"You are an expert financial data analyst specializing in natural language understanding and database schema analysis.\n",
    "Your task is to analyze questions about financial data and extract key components that will help in database queries.\n",
    "\n",
    "Objective: Break down the given question into essential components that will help formulate a database query.\n",
    "\n",
    "Instructions:\n",
    "1. Read the question carefully to identify:\n",
    "- Individual keywords that map to database columns or values\n",
    "- Technical terms related to financial data\n",
    "- Named entities (companies, funds, locations)\n",
    "- Numerical thresholds or values\n",
    "\n",
    "2. For each identified element, categorize it as:\n",
    "- keywords: Individual significant words that might match database columns\n",
    "- keyphrases: Multi-word expressions that represent single concepts\n",
    "- named_entities: Specific names of companies, funds, or locations\n",
    "- numerical_values: Any numbers, amounts, or thresholds\n",
    "\n",
    "3. Return a JSON object with these categories.\"\"\"\n",
    "\n",
    "        few_shot_examples = \"\"\"\n",
    "Example Question: \"Which PIMCO funds were registered between 2020 and 2023 with California addresses?\"\n",
    "{\n",
    "    \"keywords\": [\"funds\", \"registered\", \"addresses\"],\n",
    "    \"keyphrases\": [\"PIMCO funds\"],\n",
    "    \"named_entities\": [\"PIMCO\", \"California\"],\n",
    "    \"numerical_values\": [\"2020\", \"2023\"]\n",
    "}\n",
    "\n",
    "Example Question: \"Show me BlackRock funds with total assets over 1 billion managed in New York\"\n",
    "{\n",
    "    \"keywords\": [\"funds\", \"assets\", \"managed\"],\n",
    "    \"keyphrases\": [\"total assets\"],\n",
    "    \"named_entities\": [\"BlackRock\", \"New York\"],\n",
    "    \"numerical_values\": [\"1 billion\"]\n",
    "}\"\"\"\n",
    "\n",
    "        formatted_prompt = system_prompt\n",
    "        user_prompt = f\"Question: \\\"{question}\\\"\\n\\nExtract the key components and return as JSON.\"\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": formatted_prompt},\n",
    "                {\"role\": \"user\", \"content\": few_shot_examples + \"\\n\" + user_prompt}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        return json.loads(response.choices[0].message.content)\n",
    "\n",
    "    def preprocess_text(self, text: str) -> List[str]:\n",
    "        \"\"\"Tokenize and lemmatize input text, removing stop words.\"\"\"\n",
    "        tokens = nltk.word_tokenize(text.lower())\n",
    "        filtered_tokens = [word for word in tokens if word not in self.stop_words and word.isalnum()]\n",
    "        lemmatized_tokens = [self.lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "        return lemmatized_tokens\n",
    "    \n",
    "    def process_question(self, question: str) -> Dict:\n",
    "        # Extract keywords using gpt\n",
    "        extracted_info = self.extract_keywords(question)\n",
    "\n",
    "        words = []\n",
    "        for key in ['keywords', 'keyphrases', 'named_entities', 'numerical_values']:\n",
    "            words.extend(extracted_info.get(key, []))\n",
    "\n",
    "        # Preprocess the words (lemmatize, remove stop words)\n",
    "        processed_words = []\n",
    "        for word in words:\n",
    "            processed_words.extend(self.preprocess_text(word))\n",
    "\n",
    "        # Remove duplicates\n",
    "        processed_words = list(set(processed_words))\n",
    "\n",
    "        # Find similar columns for each word\n",
    "        similar_matches = {}\n",
    "        for word in processed_words:\n",
    "            similar_matches[word] = self.find_similar_words(word)\n",
    "\n",
    "        # Combine the results\n",
    "        result = {\n",
    "            \"question\": question,\n",
    "            \"extracted_info\": extracted_info,\n",
    "            \"processed_words\": processed_words,\n",
    "            \"similar_matches\": similar_matches,\n",
    "            \"schema_relationships\": {\n",
    "                \"primary_keys\": self.primary_keys,\n",
    "                \"foreign_keys\": self.foreign_keys\n",
    "            }\n",
    "        }\n",
    "        return result\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    vr = ValueRetrieval(schema_path='chatgpt_api/schema.json')\n",
    "\n",
    "    question = \"Show me all funds with total asset over 1 billion\"\n",
    "    result = vr.process_question(question)\n",
    "\n",
    "    from pprint import pprint\n",
    "    pprint(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
