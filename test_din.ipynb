{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\GithubRepos\\PIMCO-Text2SQL\n",
      "\n",
      "```\n",
      "Task Description:\n",
      "The task is to transform the natural language query into a SQL query for SQLite database.\n",
      "This involves parsing the intent of the query and understanding the structure of the data to generate an appropriate SQL command.\n",
      "```\n",
      "\n",
      "```\n",
      "Database Overview:\n",
      "- The Database combines information from 30 tables of the NPORT dataset from quarter 4 of 2019 to quarter 3 of 2024.\n",
      "- The data includes a comprehensive view of fund-level information, holdings, debt securities, repurchase agreements, and derivative instruments.\n",
      "- Each relation represents detailed information about financial transactions, security holdings, and fund performance, including key identifiers like ACCESSION_NUMBER, HOLDING_ID, and CUSIP for borrowers, holdings, and securities.\n",
      "- The table provides essential metrics like total assets, liabilities, interest rate risks, monthly returns, and details for securities lending and collateral.\n",
      "- The table aggregates all the data to provide a holistic view of financial activities for the 2019q4 to 2024q3 period.\n",
      "```\n",
      "\n",
      "```\n",
      "Natural Language Processing Instructions:\n",
      "- Decompose the user's query to identify requirements regarding asset classes, sectors, time periods, or specific filings.\n",
      "- Detect keywords related to filing dates, submission types, registrant details, and financial data.\n",
      "- Default to the most recent time period ('2024q3') if not specified, and consider all asset classes unless otherwise mentioned.\n",
      "```\n",
      "\n",
      "```\n",
      "Default values and assumptions:\n",
      "- Assume the most recent filing period ('2024q3') if no time period is specified, which is indicated by QUARTER column in the database.\n",
      "- Include all asset classes and sectors unless specified in the query.\n",
      "- Retrieve all filings if no specific criteria are provided.\n",
      "```\n",
      "\n",
      "```\n",
      "Example queries set 1, where Natural language request is encased in double quotations \" and desired output is the SQL query after 'SQL:'\n",
      "1. \"List the top 5 registrants by total net assets, including their CIK and country.\"\n",
      "   SQL: \n",
      "   WITH FundAssets AS (\n",
      "       SELECT R.CIK, R.REGISTRANT_NAME, R.COUNTRY, F.NET_ASSETS\n",
      "       FROM REGISTRANT R\n",
      "       JOIN FUND_REPORTED_INFO F ON R.ACCESSION_NUMBER = F.ACCESSION_NUMBER\n",
      "   )\n",
      "   SELECT CIK, REGISTRANT_NAME, COUNTRY, NET_ASSETS\n",
      "   FROM FundAssets\n",
      "   ORDER BY NET_ASSETS DESC\n",
      "   LIMIT 5;\n",
      "\n",
      "2. \"Calculate the collateral amount for repurchase agreements grouped by counterparty.\"\n",
      "   SQL: \n",
      "   WITH CollateralCTE AS (\n",
      "    SELECT RCP.NAME AS Counterparty_Name, SUM(RC.COLLATERAL_AMOUNT) AS Total_Collateral\n",
      "    FROM REPURCHASE_COLLATERAL RC\n",
      "    JOIN REPURCHASE_COUNTERPARTY RCP ON RC.HOLDING_ID = RCP.HOLDING_ID\n",
      "    GROUP BY RCP.NAME\n",
      "   )\n",
      "   SELECT Counterparty_Name, Total_Collateral\n",
      "   FROM CollateralCTE\n",
      "   ORDER BY Total_Collateral DESC;\n",
      "\n",
      "3. \"Find funds that have both securities lending activities and repurchase agreements.\"\n",
      "   SQL: \n",
      "   WITH SecuritiesLending AS (\n",
      "       SELECT ACCESSION_NUMBER\n",
      "       FROM SECURITIES_LENDING\n",
      "       WHERE IS_LOAN_BY_FUND = 'Y'\n",
      "   ),\n",
      "   RepurchaseAgreements AS (\n",
      "       SELECT ACCESSION_NUMBER\n",
      "       FROM REPURCHASE_AGREEMENT\n",
      "   )\n",
      "   SELECT F.SERIES_NAME\n",
      "   FROM FUND_REPORTED_INFO F\n",
      "   WHERE F.ACCESSION_NUMBER IN (SELECT ACCESSION_NUMBER FROM SecuritiesLending)\n",
      "     AND F.ACCESSION_NUMBER IN (SELECT ACCESSION_NUMBER FROM RepurchaseAgreements);\n",
      "\n",
      "4. \"Find borrowers who have borrowed more than $5,000,000, including their names and LEIs.\"\n",
      "   SQL: \n",
      "   WITH BorrowedAmounts AS (\n",
      "       SELECT BORROWER_ID, SUM(AGGREGATE_VALUE) AS Total_Borrowed\n",
      "       FROM BORROWER\n",
      "       GROUP BY BORROWER_ID\n",
      "       HAVING SUM(AGGREGATE_VALUE) > 5000000\n",
      "   )\n",
      "   SELECT B.NAME, B.LEI, BA.Total_Borrowed\n",
      "   FROM BORROWER B\n",
      "   JOIN BorrowedAmounts BA ON B.BORROWER_ID = BA.BORROWER_ID;\n",
      "\n",
      "5. \"Calculate the average annualized rate for debt securities grouped by coupon.\"\n",
      "   SQL: \n",
      "   WITH RateAverages AS (\n",
      "       SELECT DS.COUPON_TYPE, AVG(DS.ANNUALIZED_RATE) AS Avg_Annualized_Rate\n",
      "       FROM DEBT_SECURITY DS\n",
      "       WHERE DS.ANNUALIZED_RATE IS NOT NULL\n",
      "       GROUP BY DS.COUPON_TYPE\n",
      "   )\n",
      "   SELECT COUPON_TYPE, Avg_Annualized_Rate\n",
      "   FROM RateAverages\n",
      "   ORDER BY Avg_Annualized_Rate DESC;\n",
      "\n",
      "6. \"Find funds that have experienced a net decrease in assets over the last three reporting periods.\"\n",
      "   SQL: \n",
      "   WITH AssetChanges AS (\n",
      "       SELECT F.ACCESSION_NUMBER, F.SERIES_NAME, S.REPORT_DATE, F.NET_ASSETS,\n",
      "              LAG(F.NET_ASSETS, 1) OVER (PARTITION BY F.SERIES_NAME ORDER BY S.REPORT_DATE) AS Previous_Period_Assets\n",
      "       FROM FUND_REPORTED_INFO F\n",
      "       JOIN SUBMISSION S ON F.ACCESSION_NUMBER = S.ACCESSION_NUMBER\n",
      "   )\n",
      "   SELECT DISTINCT AC.SERIES_NAME\n",
      "   FROM AssetChanges AC\n",
      "   WHERE AC.NET_ASSETS < AC.Previous_Period_Assets\n",
      "     AND AC.Previous_Period_Assets IS NOT NULL;\n",
      "\n",
      "7. \"Identify issuers with more than three different securities holdings, include their names and CUSIPs.\"\n",
      "   SQL: \n",
      "   WITH IssuerHoldings AS (\n",
      "       SELECT H.ISSUER_NAME, H.ISSUER_CUSIP, COUNT(DISTINCT H.HOLDING_ID) AS Holding_Count\n",
      "       FROM FUND_REPORTED_HOLDING H\n",
      "       GROUP BY H.ISSUER_NAME, H.ISSUER_CUSIP\n",
      "       HAVING COUNT(DISTINCT H.HOLDING_ID) > 3\n",
      "   )\n",
      "   SELECT ISSUER_NAME, ISSUER_CUSIP, Holding_Count\n",
      "   FROM IssuerHoldings\n",
      "   ORDER BY Holding_Count DESC;\n",
      "\n",
      "8. \"Calculate the total notional amount of derivatives per currency and return the top 3 currencies by notional amount.\"\n",
      "    SQL: \n",
      "    WITH NotionalSums AS (\n",
      "        SELECT ODNA.CURRENCY_CODE, SUM(ODNA.NOTIONAL_AMOUNT) AS Total_Notional\n",
      "        FROM OTHER_DERIV_NOTIONAL_AMOUNT ODNA\n",
      "        GROUP BY ODNA.CURRENCY_CODE\n",
      "    )\n",
      "    SELECT CURRENCY_CODE, Total_Notional\n",
      "    FROM NotionalSums\n",
      "    ORDER BY Total_Notional DESC\n",
      "    LIMIT 3;\n",
      "\n",
      "9. \"Get the funds with liquidation preferences greater than their net assets.\"\n",
      "    SQL: \n",
      "    WITH FundPreferences AS (\n",
      "        SELECT F.SERIES_NAME, F.LIQUIDATION_PREFERENCE, F.NET_ASSETS\n",
      "        FROM FUND_REPORTED_INFO F\n",
      "    )\n",
      "    SELECT SERIES_NAME, LIQUIDATION_PREFERENCE, NET_ASSETS\n",
      "    FROM FundPreferences\n",
      "    WHERE LIQUIDATION_PREFERENCE > NET_ASSETS;\n",
      "\n",
      "10. \"Find all convertible securities that are contingent and have a conversion ratio above 1.5.\"\n",
      "    SQL: \n",
      "    WITH ConvertibleCTE AS (\n",
      "        SELECT DS.HOLDING_ID, CSC.CONVERSION_RATIO\n",
      "        FROM DEBT_SECURITY DS\n",
      "        JOIN CONVERTIBLE_SECURITY_CURRENCY CSC ON DS.HOLDING_ID = CSC.HOLDING_ID\n",
      "        WHERE DS.IS_CONVTIBLE_CONTINGENT = 'Y' AND CSC.CONVERSION_RATIO > 1.5\n",
      "    )\n",
      "    SELECT HOLDING_ID, CONVERSION_RATIO\n",
      "    FROM ConvertibleCTE;\n",
      "\n",
      "11. \"Find the total unrealized appreciation for each asset category for all funds.\"\n",
      "    SQL: \n",
      "    WITH AppreciationCTE AS (\n",
      "        SELECT H.ASSET_CAT, SUM(H.PERCENTAGE * H.CURRENCY_VALUE) AS Total_Unrealized_App\n",
      "        FROM FUND_REPORTED_HOLDING H\n",
      "        GROUP BY H.ASSET_CAT\n",
      "    )\n",
      "    SELECT ASSET_CAT, Total_Unrealized_App\n",
      "    FROM AppreciationCTE\n",
      "    ORDER BY Total_Unrealized_App DESC;\n",
      "\n",
      "12. \"Analyze the distribution of asset categories for the top 10 largest funds by their total assets.\"\n",
      "    SQL: \n",
      "    WITH TopFunds AS (\n",
      "        SELECT SERIES_NAME, ACCESSION_NUMBER\n",
      "        FROM FUND_REPORTED_INFO\n",
      "        ORDER BY TOTAL_ASSETS DESC\n",
      "        LIMIT 10\n",
      "    ),\n",
      "    AssetDistribution AS (\n",
      "        SELECT H.ASSET_CAT, COUNT(*) AS Category_Count\n",
      "        FROM FUND_REPORTED_HOLDING H\n",
      "        JOIN TopFunds T ON H.ACCESSION_NUMBER = T.ACCESSION_NUMBER\n",
      "        GROUP BY H.ASSET_CAT\n",
      "    )\n",
      "    SELECT ASSET_CAT, Category_Count\n",
      "    FROM AssetDistribution\n",
      "    ORDER BY Category_Count DESC;\n",
      "\n",
      "13. \"Find the top 10 funds with the highest average monthly returns in the past quarter.\"\n",
      "   SQL: \n",
      "   WITH AvgMonthlyReturn AS (\n",
      "       SELECT ACCESSION_NUMBER, \n",
      "              (MONTHLY_TOTAL_RETURN1 + MONTHLY_TOTAL_RETURN2 + MONTHLY_TOTAL_RETURN3) / 3.0 AS Avg_Return\n",
      "       FROM MONTHLY_TOTAL_RETURN\n",
      "   )\n",
      "   SELECT F.SERIES_NAME, A.ACCESSION_NUMBER, A.Avg_Return\n",
      "   FROM AvgMonthlyReturn A\n",
      "   JOIN FUND_REPORTED_INFO F ON A.ACCESSION_NUMBER = F.ACCESSION_NUMBER\n",
      "   ORDER BY A.Avg_Return DESC\n",
      "   LIMIT 10;\n",
      "\n",
      "14. \"Compare the latest net assets of the top 5 funds.\"\n",
      "   SQL: \n",
      "   WITH TopPerformingFunds AS (\n",
      "    SELECT \n",
      "        ACCESSION_NUMBER, \n",
      "        (MONTHLY_TOTAL_RETURN1 + MONTHLY_TOTAL_RETURN2 + MONTHLY_TOTAL_RETURN3) / 3.0 AS Avg_Return\n",
      "    FROM \n",
      "        MONTHLY_TOTAL_RETURN\n",
      "    ORDER BY \n",
      "        Avg_Return DESC\n",
      "    LIMIT 5\n",
      "   )\n",
      "   SELECT \n",
      "      FR.SERIES_NAME, \n",
      "      FR.NET_ASSETS, \n",
      "      TP.Avg_Return\n",
      "   FROM \n",
      "      TopPerformingFunds TP\n",
      "   JOIN \n",
      "      FUND_REPORTED_INFO FR ON TP.ACCESSION_NUMBER = FR.ACCESSION_NUMBER;\n",
      "\n",
      "15. \"Calculate the average return across all funds for the most recent month.\"\n",
      "   SQL: \n",
      "   WITH LatestReturns AS (\n",
      "    SELECT \n",
      "        M.ACCESSION_NUMBER, \n",
      "        M.MONTHLY_TOTAL_RETURN1\n",
      "    FROM \n",
      "        MONTHLY_TOTAL_RETURN M\n",
      "    JOIN \n",
      "        SUBMISSION S ON M.ACCESSION_NUMBER = S.ACCESSION_NUMBER\n",
      "    WHERE \n",
      "        S.REPORT_DATE = (SELECT MAX(REPORT_DATE) FROM SUBMISSION)\n",
      "   )\n",
      "   SELECT \n",
      "      AVG(MONTHLY_TOTAL_RETURN1) AS Average_Return\n",
      "   FROM \n",
      "      LatestReturns;\n",
      "\n",
      "16. \"Find the interest rate risk for each fund and give me those with the highest risk scores.\"\n",
      "   SQL: \n",
      "   WITH InterestRiskScores AS (\n",
      "    SELECT \n",
      "        IR.ACCESSION_NUMBER, \n",
      "        -- Calculating composite risk score by summing absolute values of DV01 and DV100 columns\n",
      "        (ABS(CAST(IR.INTRST_RATE_CHANGE_3MON_DV01 AS FLOAT)) +\n",
      "         ABS(CAST(IR.INTRST_RATE_CHANGE_1YR_DV01 AS FLOAT)) +\n",
      "         ABS(CAST(IR.INTRST_RATE_CHANGE_5YR_DV01 AS FLOAT)) +\n",
      "         ABS(CAST(IR.INTRST_RATE_CHANGE_10YR_DV01 AS FLOAT)) +\n",
      "         ABS(CAST(IR.INTRST_RATE_CHANGE_30YR_DV01 AS FLOAT)) +\n",
      "         ABS(CAST(IR.INTRST_RATE_CHANGE_3MON_DV100 AS FLOAT)) +\n",
      "         ABS(CAST(IR.INTRST_RATE_CHANGE_1YR_DV100 AS FLOAT)) +\n",
      "         ABS(CAST(IR.INTRST_RATE_CHANGE_5YR_DV100 AS FLOAT)) +\n",
      "         ABS(CAST(IR.INTRST_RATE_CHANGE_10YR_DV100 AS FLOAT)) +\n",
      "         ABS(CAST(IR.INTRST_RATE_CHANGE_30YR_DV100 AS FLOAT))\n",
      "        ) AS Composite_Risk_Score\n",
      "    FROM \n",
      "        INTEREST_RATE_RISK IR\n",
      "   )\n",
      "   SELECT \n",
      "      FR.SERIES_NAME, \n",
      "      FR.ACCESSION_NUMBER, \n",
      "      IRS.Composite_Risk_Score\n",
      "   FROM \n",
      "      InterestRiskScores IRS\n",
      "   JOIN \n",
      "      FUND_REPORTED_INFO FR ON IRS.ACCESSION_NUMBER = FR.ACCESSION_NUMBER\n",
      "   ORDER BY \n",
      "      IRS.Composite_Risk_Score DESC\n",
      "   LIMIT 5;\n",
      "\n",
      "17. \"Return funds that have experienced a decrease in assets over the last three reporting periods.\"\n",
      "   SQL: \n",
      "   WITH AssetChanges AS (\n",
      "       SELECT F.ACCESSION_NUMBER, F.SERIES_NAME, S.REPORT_DATE, F.NET_ASSETS,\n",
      "              LAG(F.NET_ASSETS, 1) OVER (PARTITION BY F.SERIES_NAME ORDER BY S.REPORT_DATE) AS Previous_Period_Assets\n",
      "       FROM FUND_REPORTED_INFO F\n",
      "       JOIN SUBMISSION S ON F.ACCESSION_NUMBER = S.ACCESSION_NUMBER\n",
      "   )\n",
      "   SELECT DISTINCT AC.SERIES_NAME\n",
      "   FROM AssetChanges AC\n",
      "   WHERE AC.NET_ASSETS < AC.Previous_Period_Assets\n",
      "     AND AC.Previous_Period_Assets IS NOT NULL;\n",
      "\n",
      "18. \"Analyze the composition of fund portfolios by categorizing assets and their total values.\"\n",
      "   SQL: \n",
      "   WITH PortfolioComposition AS (\n",
      "    SELECT \n",
      "        ACCESSION_NUMBER, \n",
      "        ASSET_CAT, \n",
      "        SUM(CAST(CURRENCY_VALUE AS FLOAT)) AS Total_Value\n",
      "    FROM \n",
      "        FUND_REPORTED_HOLDING\n",
      "    GROUP BY \n",
      "        ACCESSION_NUMBER, \n",
      "        ASSET_CAT\n",
      ")\n",
      "SELECT \n",
      "    F.SERIES_NAME, \n",
      "    PC.ASSET_CAT, \n",
      "    PC.Total_Value\n",
      "FROM \n",
      "    PortfolioComposition PC\n",
      "JOIN \n",
      "    FUND_REPORTED_INFO F ON PC.ACCESSION_NUMBER = F.ACCESSION_NUMBER\n",
      "ORDER BY \n",
      "    F.SERIES_NAME, \n",
      "    PC.Total_Value DESC;\n",
      "\n",
      "19. \"Find the most common asset categories for all fund portfolios.\"\n",
      "    SQL: \n",
      "    WITH AssetCounts AS (\n",
      "        SELECT ASSET_CAT, COUNT(*) AS Count\n",
      "        FROM FUND_REPORTED_HOLDING\n",
      "        GROUP BY ASSET_CAT\n",
      "    )\n",
      "    SELECT ASSET_CAT, Count\n",
      "    FROM AssetCounts\n",
      "    ORDER BY Count DESC\n",
      "    LIMIT 5;\n",
      "\n",
      "20. \"Determine the percentage of each asset category within individual funds.\"\n",
      "    SQL: \n",
      "    WITH TotalAssets AS (\n",
      "    SELECT \n",
      "        ACCESSION_NUMBER, \n",
      "        SUM(CAST(CURRENCY_VALUE AS FLOAT)) AS Total_Value\n",
      "    FROM \n",
      "        FUND_REPORTED_HOLDING\n",
      "    GROUP BY \n",
      "        ACCESSION_NUMBER\n",
      "),\n",
      "CategoryAllocation AS (\n",
      "    SELECT \n",
      "        FH.ACCESSION_NUMBER, \n",
      "        FH.ASSET_CAT, \n",
      "        SUM(CAST(FH.CURRENCY_VALUE AS FLOAT)) AS Category_Value\n",
      "    FROM \n",
      "        FUND_REPORTED_HOLDING FH\n",
      "    GROUP BY \n",
      "        FH.ACCESSION_NUMBER, \n",
      "        FH.ASSET_CAT\n",
      "   )\n",
      "   SELECT \n",
      "      F.SERIES_NAME, \n",
      "      CA.ASSET_CAT, \n",
      "      (CA.Category_Value * 100.0 / TA.Total_Value) AS Percentage_Allocation\n",
      "   FROM \n",
      "      CategoryAllocation CA\n",
      "   JOIN \n",
      "      TotalAssets TA ON CA.ACCESSION_NUMBER = TA.ACCESSION_NUMBER\n",
      "   JOIN \n",
      "      FUND_REPORTED_INFO F ON CA.ACCESSION_NUMBER = F.ACCESSION_NUMBER\n",
      "   ORDER BY \n",
      "      F.SERIES_NAME, \n",
      "      Percentage_Allocation DESC;\n",
      "```\n",
      "\n",
      "```\n",
      "Reasoning Instructions:\n",
      "1. Reasoning you provide should first focus on why a nested query was chosen or why it wasn't chosen.\n",
      "2. It should give a query plan on how to solve this question - explain \n",
      "the mapping of the columns to the words in the input question.\n",
      "3. It should explain each of the clauses and why they are structured the way they are structured. \n",
      "   For example, if there is a `GROUP BY`, an explanation should be given as to why it exists.\n",
      "4. If there's any `SUM()` or any other function used, it should be explained as to why it was required.\n",
      "```\n",
      "\n",
      "```\n",
      "Example queries set (easy difficulty) that should not require any nested queries or join statements.\n",
      "1. \"Show me the top 5 largest funds by total assets\"\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    TOTAL_ASSETS \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "ORDER BY \n",
      "    CAST(TOTAL_ASSETS AS FLOAT) DESC \n",
      "LIMIT 5;\n",
      "\n",
      "2. \"Show me the top 20 largest funds by total assets\"\n",
      "WITH FundSizes AS (\n",
      "    SELECT \n",
      "        SERIES_NAME,\n",
      "        CAST(TOTAL_ASSETS AS FLOAT) as Total_Assets,\n",
      "        CAST(NET_ASSETS AS FLOAT) as Net_Assets\n",
      "    FROM \n",
      "        FUND_REPORTED_INFO\n",
      "    WHERE \n",
      "        TOTAL_ASSETS IS NOT NULL\n",
      ")\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    ROUND(Total_Assets / 1000000, 2) as Total_Assets_Millions,\n",
      "    ROUND(Net_Assets / 1000000, 2) as Net_Assets_Millions\n",
      "FROM \n",
      "    FundSizes\n",
      "ORDER BY \n",
      "    Total_Assets DESC\n",
      "LIMIT 20;\n",
      "\n",
      "3. \"List all funds with net assets over 1 billion dollars\"\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    NET_ASSETS \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "WHERE \n",
      "    CAST(NET_ASSETS AS FLOAT) > 1000000000;\n",
      "\n",
      "4. \"How many funds does each registrant have?\"\n",
      "SELECT \n",
      "    REGISTRANT_NAME,\n",
      "    COUNT(F.SERIES_NAME) as Fund_Count\n",
      "FROM \n",
      "    REGISTRANT R\n",
      "    JOIN FUND_REPORTED_INFO F \n",
      "        ON R.ACCESSION_NUMBER = F.ACCESSION_NUMBER\n",
      "GROUP BY \n",
      "    REGISTRANT_NAME;\n",
      "\n",
      "5. \"What are the total assets of BlackRock funds?\"\n",
      "SELECT \n",
      "    SUM(CAST(TOTAL_ASSETS AS FLOAT)) as Total_BlackRock_Assets\n",
      "FROM \n",
      "    FUND_REPORTED_INFO F\n",
      "    JOIN REGISTRANT R \n",
      "        ON F.ACCESSION_NUMBER = R.ACCESSION_NUMBER\n",
      "WHERE \n",
      "    R.REGISTRANT_NAME LIKE '%BLACKROCK%';\n",
      "\n",
      "6. \"List all funds with their registrant names\"\n",
      "SELECT \n",
      "    R.REGISTRANT_NAME,\n",
      "    F.SERIES_NAME\n",
      "FROM \n",
      "    REGISTRANT R\n",
      "    JOIN FUND_REPORTED_INFO F \n",
      "        ON R.ACCESSION_NUMBER = F.ACCESSION_NUMBER;\n",
      "\n",
      "7. \"Which funds have the highest total liabilities?\"\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    TOTAL_LIABILITIES \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "ORDER BY \n",
      "    CAST(TOTAL_LIABILITIES AS FLOAT) DESC \n",
      "LIMIT 10;\n",
      "\n",
      "8. \"Which asset categories have the highest total investment value?\"\n",
      "WITH AssetTotals AS (\n",
      "    SELECT \n",
      "        ASSET_CAT,\n",
      "        COUNT(*) as Holdings_Count,\n",
      "        SUM(CAST(CURRENCY_VALUE AS FLOAT)) as Total_Value\n",
      "    FROM \n",
      "        FUND_REPORTED_HOLDING\n",
      "    WHERE \n",
      "        ASSET_CAT IS NOT NULL\n",
      "    GROUP BY \n",
      "        ASSET_CAT\n",
      ")\n",
      "SELECT \n",
      "    ASSET_CAT,\n",
      "    Holdings_Count,\n",
      "    ROUND(Total_Value / 1000000, 2) as Value_Millions\n",
      "FROM \n",
      "    AssetTotals\n",
      "ORDER BY \n",
      "    Total_Value DESC;\n",
      "\n",
      "9. \"What's the latest filing date for each fund?\"\n",
      "SELECT \n",
      "    F.SERIES_NAME,\n",
      "    MAX(S.FILING_DATE) as Latest_Filing\n",
      "FROM \n",
      "    FUND_REPORTED_INFO F\n",
      "    JOIN SUBMISSION S \n",
      "        ON F.ACCESSION_NUMBER = S.ACCESSION_NUMBER\n",
      "GROUP BY \n",
      "    F.SERIES_NAME;\n",
      "\n",
      "10. \"Show me the largest bond funds\"\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    ROUND(CAST(TOTAL_ASSETS AS FLOAT) / 1000000, 2) as Assets_Millions\n",
      "FROM \n",
      "    FUND_REPORTED_INFO\n",
      "WHERE \n",
      "    SERIES_NAME LIKE '%BOND%'\n",
      "ORDER BY \n",
      "    Assets_Millions DESC\n",
      "LIMIT 15;\n",
      "\n",
      "11. \"Show me the phone numbers of all Vanguard registrants\"\n",
      "SELECT \n",
      "    REGISTRANT_NAME,\n",
      "    PHONE \n",
      "FROM \n",
      "    REGISTRANT \n",
      "WHERE \n",
      "    REGISTRANT_NAME LIKE '%VANGUARD%';\n",
      "\n",
      "12. \"Which funds have assets between 100M and 500M?\"\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    TOTAL_ASSETS \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "WHERE \n",
      "    CAST(TOTAL_ASSETS AS FLOAT) BETWEEN 100000000 AND 500000000;\n",
      "\n",
      "13. \"List all registrants and their cities\"\n",
      "SELECT \n",
      "    REGISTRANT_NAME,\n",
      "    CITY,\n",
      "    STATE \n",
      "FROM \n",
      "    REGISTRANT \n",
      "ORDER BY \n",
      "    STATE,\n",
      "    CITY;\n",
      "\n",
      "14. \"Show me the earliest filing date for each registrant\"\n",
      "SELECT \n",
      "    R.REGISTRANT_NAME,\n",
      "    MIN(S.FILING_DATE) as First_Filing\n",
      "FROM \n",
      "    REGISTRANT R\n",
      "    JOIN SUBMISSION S \n",
      "        ON R.ACCESSION_NUMBER = S.ACCESSION_NUMBER\n",
      "GROUP BY \n",
      "    R.REGISTRANT_NAME;\n",
      "\n",
      "15. \"Which funds have total assets equal to net assets?\"\n",
      "SELECT \n",
      "    SERIES_NAME \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "WHERE \n",
      "    TOTAL_ASSETS = NET_ASSETS;\n",
      "\n",
      "16. \"List all funds with 'Income' in their name\"\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    TOTAL_ASSETS \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "WHERE \n",
      "    SERIES_NAME LIKE '%INCOME%';\n",
      "\n",
      "17. \"Group funds into size categories based on their net assets\"\n",
      "WITH FundSizeBuckets AS (\n",
      "    SELECT \n",
      "        SERIES_NAME,\n",
      "        CAST(NET_ASSETS AS FLOAT) as Net_Assets,\n",
      "        CASE \n",
      "            WHEN CAST(NET_ASSETS AS FLOAT) >= 10000000000 THEN 'Very Large (>10B)'\n",
      "            WHEN CAST(NET_ASSETS AS FLOAT) >= 1000000000 THEN 'Large (1B-10B)'\n",
      "            WHEN CAST(NET_ASSETS AS FLOAT) >= 100000000 THEN 'Medium (100M-1B)'\n",
      "            ELSE 'Small (<100M)'\n",
      "        END as Size_Category\n",
      "    FROM \n",
      "        FUND_REPORTED_INFO\n",
      "    WHERE \n",
      "        NET_ASSETS IS NOT NULL\n",
      ")\n",
      "SELECT \n",
      "    Size_Category,\n",
      "    COUNT(*) as Number_of_Funds,\n",
      "    ROUND(AVG(Net_Assets) / 1000000, 2) as Avg_Net_Assets_Millions,\n",
      "    ROUND(MIN(Net_Assets) / 1000000, 2) as Min_Net_Assets_Millions,\n",
      "    ROUND(MAX(Net_Assets) / 1000000, 2) as Max_Net_Assets_Millions\n",
      "FROM \n",
      "    FundSizeBuckets\n",
      "GROUP BY \n",
      "    Size_Category\n",
      "ORDER BY \n",
      "    MIN(Net_Assets);\n",
      "\n",
      "18. \"Which funds have the highest liabilities to assets ratio?\"\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    CAST(TOTAL_LIABILITIES AS FLOAT) / CAST(TOTAL_ASSETS AS FLOAT) as Liability_Ratio\n",
      "FROM \n",
      "    FUND_REPORTED_INFO\n",
      "WHERE \n",
      "    TOTAL_ASSETS != '0'\n",
      "ORDER BY \n",
      "    Liability_Ratio DESC\n",
      "LIMIT 5;\n",
      "\n",
      "19. \"List all registrants with their fund count and total assets\"\n",
      "SELECT \n",
      "    R.REGISTRANT_NAME,\n",
      "    COUNT(F.SERIES_NAME) as Fund_Count,\n",
      "    SUM(CAST(F.TOTAL_ASSETS AS FLOAT)) as Total_Assets\n",
      "FROM \n",
      "    REGISTRANT R\n",
      "    JOIN FUND_REPORTED_INFO F \n",
      "        ON R.ACCESSION_NUMBER = F.ACCESSION_NUMBER\n",
      "GROUP BY \n",
      "    R.REGISTRANT_NAME;\n",
      "\n",
      "20. \"Show me all funds with 'Growth' in their name\"\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    TOTAL_ASSETS \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "WHERE \n",
      "    SERIES_NAME LIKE '%GROWTH%';\n",
      "\n",
      "21. \"Show me the funds with over $1 billion in assets\"\n",
      "WITH LargeFunds AS (\n",
      "    SELECT \n",
      "        SERIES_NAME,\n",
      "        CAST(TOTAL_ASSETS AS FLOAT) / 1000000 as Assets_Millions\n",
      "    FROM \n",
      "        FUND_REPORTED_INFO\n",
      "    WHERE \n",
      "        TOTAL_ASSETS >= 1000000000\n",
      ")\n",
      "SELECT * FROM LargeFunds\n",
      "ORDER BY Assets_Millions DESC\n",
      "LIMIT 15;\n",
      "\n",
      "22. \"List the top 10 funds by net assets\"\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    NET_ASSETS \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "ORDER BY \n",
      "    CAST(NET_ASSETS AS FLOAT) DESC \n",
      "LIMIT 10;\n",
      "\n",
      "23. \"Show me all Fidelity funds\"\n",
      "SELECT \n",
      "    F.SERIES_NAME,\n",
      "    F.TOTAL_ASSETS\n",
      "FROM \n",
      "    FUND_REPORTED_INFO F\n",
      "    JOIN REGISTRANT R \n",
      "        ON F.ACCESSION_NUMBER = R.ACCESSION_NUMBER\n",
      "WHERE \n",
      "    R.REGISTRANT_NAME LIKE '%FIDELITY%';\n",
      "\n",
      "24. \"Which funds have zero liabilities?\"\n",
      "SELECT \n",
      "    SERIES_NAME \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "WHERE \n",
      "    TOTAL_LIABILITIES = '0' \n",
      "    OR TOTAL_LIABILITIES IS NULL;\n",
      "\n",
      "25. \"List all registrants with their latest fund's assets\"\n",
      "SELECT \n",
      "    R.REGISTRANT_NAME,\n",
      "    F.TOTAL_ASSETS\n",
      "FROM \n",
      "    REGISTRANT R\n",
      "    JOIN FUND_REPORTED_INFO F \n",
      "        ON R.ACCESSION_NUMBER = F.ACCESSION_NUMBER;\n",
      "\n",
      "26. \"Show me all funds with 'International' in their name\"\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    TOTAL_ASSETS \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "WHERE \n",
      "    SERIES_NAME LIKE '%INTERNATIONAL%';\n",
      "\n",
      "27. \"Which funds have the most cash on hand?\"\n",
      "WITH CashHoldings AS (\n",
      "    SELECT \n",
      "        SERIES_NAME,\n",
      "        ROUND(CAST(CASH_NOT_RPTD_IN_C_OR_D AS FLOAT) / 1000000, 2) as Cash_Millions\n",
      "    FROM \n",
      "        FUND_REPORTED_INFO\n",
      "    WHERE \n",
      "        CASH_NOT_RPTD_IN_C_OR_D IS NOT NULL\n",
      ")\n",
      "SELECT * FROM CashHoldings\n",
      "ORDER BY Cash_Millions DESC\n",
      "LIMIT 10;\n",
      "\n",
      "28. \"List all funds with their submission dates\"\n",
      "SELECT \n",
      "    F.SERIES_NAME,\n",
      "    S.FILING_DATE\n",
      "FROM \n",
      "    FUND_REPORTED_INFO F\n",
      "    JOIN SUBMISSION S \n",
      "        ON F.ACCESSION_NUMBER = S.ACCESSION_NUMBER;\n",
      "\n",
      "29. \"Show me the smallest 5 funds by total assets\"\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    TOTAL_ASSETS \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "WHERE \n",
      "    TOTAL_ASSETS IS NOT NULL\n",
      "ORDER BY \n",
      "    CAST(TOTAL_ASSETS AS FLOAT) ASC \n",
      "LIMIT 5;\n",
      "\n",
      "30. \"Which registrants have multiple phone numbers?\"\n",
      "SELECT \n",
      "    REGISTRANT_NAME,\n",
      "    COUNT(DISTINCT PHONE) as Phone_Count\n",
      "FROM \n",
      "    REGISTRANT\n",
      "GROUP BY \n",
      "    REGISTRANT_NAME\n",
      "HAVING \n",
      "    Phone_Count > 1;\n",
      "\n",
      "31. \"List all funds with 'Bond' in their name\"\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    TOTAL_ASSETS \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "WHERE \n",
      "    SERIES_NAME LIKE '%BOND%';\n",
      "\n",
      "32. \"Show me all registrants from Florida\"\n",
      "SELECT \n",
      "    REGISTRANT_NAME,\n",
      "    CITY,\n",
      "    ADDRESS1 \n",
      "FROM \n",
      "    REGISTRANT \n",
      "WHERE \n",
      "    STATE = 'FL';\n",
      "\n",
      "33. \"Show me funds with the highest ratio of cash to total assets\"\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    ROUND(CAST(CASH_NOT_RPTD_IN_C_OR_D AS FLOAT) * 100.0 / \n",
      "          CAST(TOTAL_ASSETS AS FLOAT), 2) as Cash_Percentage\n",
      "FROM \n",
      "    FUND_REPORTED_INFO\n",
      "WHERE \n",
      "    CASH_NOT_RPTD_IN_C_OR_D IS NOT NULL \n",
      "    AND TOTAL_ASSETS > 0\n",
      "ORDER BY \n",
      "    Cash_Percentage DESC\n",
      "LIMIT 15;\n",
      "\n",
      "34. \"List all funds with 'Index' in their name\"\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    TOTAL_ASSETS \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "WHERE \n",
      "    SERIES_NAME LIKE '%INDEX%';\n",
      "\n",
      "35. \"Show me the registrants with the most recent filings\"\n",
      "SELECT \n",
      "    R.REGISTRANT_NAME,\n",
      "    MAX(S.FILING_DATE) as Latest_Filing\n",
      "FROM \n",
      "    REGISTRANT R\n",
      "    JOIN SUBMISSION S \n",
      "        ON R.ACCESSION_NUMBER = S.ACCESSION_NUMBER\n",
      "GROUP BY \n",
      "    R.REGISTRANT_NAME\n",
      "ORDER BY \n",
      "    Latest_Filing DESC\n",
      "LIMIT 5;\n",
      "\n",
      "36. \"Which funds have 'ETF' in their name?\"\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    TOTAL_ASSETS \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "WHERE \n",
      "    SERIES_NAME LIKE '%ETF%';\n",
      "\n",
      "37. \"List all registrants with their ZIP codes\"\n",
      "SELECT \n",
      "    REGISTRANT_NAME,\n",
      "    ZIP,\n",
      "    STATE \n",
      "FROM \n",
      "    REGISTRANT \n",
      "ORDER BY \n",
      "    ZIP;\n",
      "\n",
      "38.\"Show me all equity-focused funds\"\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    ROUND(CAST(TOTAL_ASSETS AS FLOAT) / 1000000, 2) as Assets_Millions\n",
      "FROM \n",
      "    FUND_REPORTED_INFO\n",
      "WHERE \n",
      "    SERIES_NAME LIKE '%EQUITY%'\n",
      "    OR SERIES_NAME LIKE '%STOCK%'\n",
      "ORDER BY \n",
      "    Assets_Millions DESC\n",
      "LIMIT 20;\n",
      "\n",
      "39. \"Which funds have assets over 10 billion?\"\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    TOTAL_ASSETS \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "WHERE \n",
      "    CAST(TOTAL_ASSETS AS FLOAT) > 10000000000;\n",
      "\n",
      "40. \"List all registrants with their country\"\n",
      "SELECT \n",
      "    REGISTRANT_NAME,\n",
      "    COUNTRY,\n",
      "    STATE \n",
      "FROM \n",
      "    REGISTRANT \n",
      "ORDER BY \n",
      "    COUNTRY,\n",
      "    STATE;\n",
      "```\n",
      "\n",
      "```\n",
      "Final output:\n",
      "Format the generated SQL with proper indentation - the columns in the \n",
      "(`SELECT` statement should have more indentation than the keyword `SELECT` \n",
      "and so on for each SQL clause.)\n",
      "Output only the SQLite's SQL query syntax, without blank padding on the left or right, any string prefix suffix, or any delimiters ```.\n",
      "\n",
      "```\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='C:\\\\Users\\\\User\\\\anaconda3\\\\Library\\\\ssl\\\\cacert.pem'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import openai as OpenAI\n",
    "from typing import List, Tuple, Dict\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from rapidfuzz.distance.Levenshtein import distance\n",
    "from rapidfuzz import fuzz\n",
    "import re\n",
    "from chatgpt_api import chat_prompt\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(\"/d/GithubRepos/PIMCO-Text2SQL\"))\n",
    "din_modules_path = os.path.join(current_dir, 'chatgpt_api')\n",
    "sys.path.append(din_modules_path)\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "if not client.api_key:\n",
    "    raise ValueError(\"OpenAI API key not configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Key Analysis:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Table: REGISTRANT\n",
      "Column: ACCESSION_NUMBER\n",
      "Total rows: 2822\n",
      "Unique values: 2822\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: REGISTRANT.ACCESSION_NUMBER -> FUND_REPORTED_INFO.ACCESSION_NUMBER\n",
      "\n",
      "Table: FUND_REPORTED_INFO\n",
      "Column: ACCESSION_NUMBER\n",
      "Total rows: 2822\n",
      "Unique values: 2822\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Column: SERIES_ID\n",
      "Total rows: 2822\n",
      "Unique values: 2643\n",
      "Foreign Key: FUND_REPORTED_INFO.ACCESSION_NUMBER -> FUND_REPORTED_INFO.ACCESSION_NUMBER\n",
      "\n",
      "Table: INTEREST_RATE_RISK\n",
      "Column: ACCESSION_NUMBER\n",
      "Total rows: 4629\n",
      "Unique values: 1460\n",
      "Column: INTEREST_RATE_RISK_ID\n",
      "Total rows: 4629\n",
      "Unique values: 4629\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: INTEREST_RATE_RISK.ACCESSION_NUMBER -> FUND_REPORTED_INFO.ACCESSION_NUMBER\n",
      "\n",
      "Table: BORROWER\n",
      "Column: ACCESSION_NUMBER\n",
      "Total rows: 12685\n",
      "Unique values: 1189\n",
      "Column: BORROWER_ID\n",
      "Total rows: 12685\n",
      "Unique values: 12685\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: BORROWER.ACCESSION_NUMBER -> FUND_REPORTED_INFO.ACCESSION_NUMBER\n",
      "\n",
      "Table: MONTHLY_TOTAL_RETURN\n",
      "Column: ACCESSION_NUMBER\n",
      "Total rows: 7949\n",
      "Unique values: 2822\n",
      "Column: MONTHLY_TOTAL_RETURN_ID\n",
      "Total rows: 7949\n",
      "Unique values: 7949\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Column: CLASS_ID\n",
      "Total rows: 7949\n",
      "Unique values: 7701\n",
      "Foreign Key: MONTHLY_TOTAL_RETURN.ACCESSION_NUMBER -> FUND_REPORTED_INFO.ACCESSION_NUMBER\n",
      "\n",
      "Table: MONTHLY_RETURN_CAT_INSTRUMENT\n",
      "Column: ACCESSION_NUMBER\n",
      "Total rows: 62912\n",
      "Unique values: 2195\n",
      "Foreign Key: MONTHLY_RETURN_CAT_INSTRUMENT.ACCESSION_NUMBER -> FUND_REPORTED_INFO.ACCESSION_NUMBER\n",
      "\n",
      "Table: EXPLANATORY_NOTE\n",
      "Column: ACCESSION_NUMBER\n",
      "Total rows: 3420\n",
      "Unique values: 1391\n",
      "Column: EXPLANATORY_NOTE_ID\n",
      "Total rows: 3420\n",
      "Unique values: 3420\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: EXPLANATORY_NOTE.ACCESSION_NUMBER -> FUND_REPORTED_INFO.ACCESSION_NUMBER\n",
      "\n",
      "Table: DEBT_SECURITY\n",
      "Column: HOLDING_ID\n",
      "Total rows: 3557\n",
      "Unique values: 3557\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: DEBT_SECURITY.HOLDING_ID -> FUND_REPORTED_HOLDING.HOLDING_ID\n",
      "\n",
      "Table: CONVERTIBLE_SECURITY_CURRENCY\n",
      "Column: HOLDING_ID\n",
      "Total rows: 30\n",
      "Unique values: 30\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Column: CONVERTIBLE_SECURITY_ID\n",
      "Total rows: 30\n",
      "Unique values: 30\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: CONVERTIBLE_SECURITY_CURRENCY.HOLDING_ID -> FUND_REPORTED_HOLDING.HOLDING_ID\n",
      "\n",
      "Table: REPURCHASE_COUNTERPARTY\n",
      "Column: HOLDING_ID\n",
      "Total rows: 8\n",
      "Unique values: 8\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Column: REPURCHASE_COUNTERPARTY_ID\n",
      "Total rows: 8\n",
      "Unique values: 8\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: REPURCHASE_COUNTERPARTY.HOLDING_ID -> FUND_REPORTED_HOLDING.HOLDING_ID\n",
      "\n",
      "Table: DERIVATIVE_COUNTERPARTY\n",
      "Column: HOLDING_ID\n",
      "Total rows: 23\n",
      "Unique values: 23\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Column: DERIVATIVE_COUNTERPARTY_ID\n",
      "Total rows: 23\n",
      "Unique values: 23\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: DERIVATIVE_COUNTERPARTY.HOLDING_ID -> FUND_REPORTED_HOLDING.HOLDING_ID\n",
      "\n",
      "Table: DESC_REF_INDEX_COMPONENT\n",
      "Column: HOLDING_ID\n",
      "Total rows: 0\n",
      "Unique values: 0\n",
      "Column: DESC_REF_INDEX_COMPONENT_ID\n",
      "Total rows: 0\n",
      "Unique values: 0\n",
      "Column: OTHER_IDENTIFIER\n",
      "Total rows: 0\n",
      "Unique values: 0\n",
      "\n",
      "Table: DESC_REF_OTHER\n",
      "Column: HOLDING_ID\n",
      "Total rows: 5\n",
      "Unique values: 4\n",
      "Column: DESC_REF_OTHER_ID\n",
      "Total rows: 5\n",
      "Unique values: 5\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Column: OTHER_IDENTIFIER\n",
      "Total rows: 5\n",
      "Unique values: 2\n",
      "Foreign Key: DESC_REF_OTHER.HOLDING_ID -> FUND_REPORTED_HOLDING.HOLDING_ID\n",
      "\n",
      "Table: FUT_FWD_NONFOREIGNCUR_CONTRACT\n",
      "Column: HOLDING_ID\n",
      "Total rows: 0\n",
      "Unique values: 0\n",
      "\n",
      "Table: FWD_FOREIGNCUR_CONTRACT_SWAP\n",
      "Column: HOLDING_ID\n",
      "Total rows: 0\n",
      "Unique values: 0\n",
      "\n",
      "Table: FLOATING_RATE_RESET_TENOR\n",
      "Column: HOLDING_ID\n",
      "Total rows: 26\n",
      "Unique values: 18\n",
      "Column: RATE_RESET_TENOR_ID\n",
      "Total rows: 26\n",
      "Unique values: 26\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: FLOATING_RATE_RESET_TENOR.HOLDING_ID -> FUND_REPORTED_HOLDING.HOLDING_ID\n",
      "\n",
      "Table: OTHER_DERIV\n",
      "Column: HOLDING_ID\n",
      "Total rows: 0\n",
      "Unique values: 0\n",
      "\n",
      "Table: OTHER_DERIV_NOTIONAL_AMOUNT\n",
      "Column: HOLDING_ID\n",
      "Total rows: 0\n",
      "Unique values: 0\n",
      "Column: OTHER_DERIV_NOTIONAL_AMOUNT_ID\n",
      "Total rows: 0\n",
      "Unique values: 0\n",
      "\n",
      "Table: FUND_REPORTED_HOLDING\n",
      "Column: ACCESSION_NUMBER\n",
      "Total rows: 6310\n",
      "Unique values: 2822\n",
      "Column: HOLDING_ID\n",
      "Total rows: 6310\n",
      "Unique values: 6310\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: FUND_REPORTED_HOLDING.ACCESSION_NUMBER -> FUND_REPORTED_INFO.ACCESSION_NUMBER\n",
      "Foreign Key: FUND_REPORTED_HOLDING.HOLDING_ID -> FUND_REPORTED_HOLDING.HOLDING_ID\n",
      "\n",
      "Table: SUBMISSION\n",
      "Column: ACCESSION_NUMBER\n",
      "Total rows: 2822\n",
      "Unique values: 2822\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: SUBMISSION.ACCESSION_NUMBER -> FUND_REPORTED_INFO.ACCESSION_NUMBER\n",
      "\n",
      "Table: BORROW_AGGREGATE\n",
      "Column: ACCESSION_NUMBER\n",
      "Total rows: 377\n",
      "Unique values: 357\n",
      "Column: BORROW_AGGREGATE_ID\n",
      "Total rows: 377\n",
      "Unique values: 377\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: BORROW_AGGREGATE.ACCESSION_NUMBER -> FUND_REPORTED_INFO.ACCESSION_NUMBER\n",
      "\n",
      "Table: IDENTIFIERS\n",
      "Column: HOLDING_ID\n",
      "Total rows: 8179\n",
      "Unique values: 6310\n",
      "Column: IDENTIFIERS_ID\n",
      "Total rows: 8179\n",
      "Unique values: 8179\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: IDENTIFIERS.HOLDING_ID -> FUND_REPORTED_HOLDING.HOLDING_ID\n",
      "\n",
      "Table: DEBT_SECURITY_REF_INSTRUMENT\n",
      "Column: HOLDING_ID\n",
      "Total rows: 48\n",
      "Unique values: 30\n",
      "Column: DEBT_SECURITY_REF_ID\n",
      "Total rows: 48\n",
      "Unique values: 48\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: DEBT_SECURITY_REF_INSTRUMENT.HOLDING_ID -> FUND_REPORTED_HOLDING.HOLDING_ID\n",
      "\n",
      "Table: REPURCHASE_AGREEMENT\n",
      "Column: HOLDING_ID\n",
      "Total rows: 8\n",
      "Unique values: 8\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: REPURCHASE_AGREEMENT.HOLDING_ID -> FUND_REPORTED_HOLDING.HOLDING_ID\n",
      "\n",
      "Table: REPURCHASE_COLLATERAL\n",
      "Column: HOLDING_ID\n",
      "Total rows: 8\n",
      "Unique values: 8\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Column: REPURCHASE_COLLATERAL_ID\n",
      "Total rows: 8\n",
      "Unique values: 8\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: REPURCHASE_COLLATERAL.HOLDING_ID -> FUND_REPORTED_HOLDING.HOLDING_ID\n",
      "\n",
      "Table: SWAPTION_OPTION_WARNT_DERIV\n",
      "Column: HOLDING_ID\n",
      "Total rows: 5\n",
      "Unique values: 5\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: SWAPTION_OPTION_WARNT_DERIV.HOLDING_ID -> FUND_REPORTED_HOLDING.HOLDING_ID\n",
      "\n",
      "Table: DESC_REF_INDEX_BASKET\n",
      "Column: HOLDING_ID\n",
      "Total rows: 1\n",
      "Unique values: 1\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Column: INDEX_IDENTIFIER\n",
      "Total rows: 1\n",
      "Unique values: 1\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: DESC_REF_INDEX_BASKET.HOLDING_ID -> FUND_REPORTED_HOLDING.HOLDING_ID\n",
      "\n",
      "Table: NONFOREIGN_EXCHANGE_SWAP\n",
      "Column: HOLDING_ID\n",
      "Total rows: 18\n",
      "Unique values: 18\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: NONFOREIGN_EXCHANGE_SWAP.HOLDING_ID -> FUND_REPORTED_HOLDING.HOLDING_ID\n",
      "\n",
      "Table: SECURITIES_LENDING\n",
      "Column: HOLDING_ID\n",
      "Total rows: 6310\n",
      "Unique values: 6310\n",
      ">>> Potential PRIMARY KEY <<<\n",
      "Foreign Key: SECURITIES_LENDING.HOLDING_ID -> FUND_REPORTED_HOLDING.HOLDING_ID\n"
     ]
    }
   ],
   "source": [
    "def explore_keys():\n",
    "    \"\"\"Explore potential primary and foreign keys in the database\"\"\"\n",
    "    import sqlite3\n",
    "    \n",
    "    # Connect to database\n",
    "    conn = sqlite3.connect('sqlite/nport.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Get all tables\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "\n",
    "    print(\"Database Key Analysis:\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Analyze each table\n",
    "    for table in tables:\n",
    "        table_name = table[0]\n",
    "        print(f\"\\nTable: {table_name}\")\n",
    "\n",
    "        # Get column info\n",
    "        cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "        columns = cursor.fetchall()\n",
    "        \n",
    "        # Get sample count for potential key columns\n",
    "        for col in columns:\n",
    "            col_name = col[1]\n",
    "            # Check if column name contains potential key indicators\n",
    "            if any(key_term in col_name.lower() for key_term in ['_id', 'accession', 'number']):\n",
    "                cursor.execute(f\"\"\"\n",
    "                    SELECT COUNT(*) total_rows, \n",
    "                           COUNT(DISTINCT {col_name}) unique_values \n",
    "                    FROM {table_name}\n",
    "                    WHERE {col_name} IS NOT NULL\n",
    "                \"\"\")\n",
    "                stats = cursor.fetchone()\n",
    "                print(f\"Column: {col_name}\")\n",
    "                print(f\"Total rows: {stats[0]}\")\n",
    "                print(f\"Unique values: {stats[1]}\")\n",
    "                \n",
    "                # If unique values equals total rows, likely a key\n",
    "                if stats[0] == stats[1] and stats[0] > 0:\n",
    "                    print(\">>> Potential PRIMARY KEY <<<\")\n",
    "\n",
    "        # Look for foreign key relationships\n",
    "        for col in columns:\n",
    "            col_name = col[1]\n",
    "            if col_name == 'ACCESSION_NUMBER':\n",
    "                cursor.execute(f\"\"\"\n",
    "                    SELECT COUNT(*) FROM {table_name} t1\n",
    "                    WHERE EXISTS (\n",
    "                        SELECT 1 FROM FUND_REPORTED_INFO t2 \n",
    "                        WHERE t1.ACCESSION_NUMBER = t2.ACCESSION_NUMBER\n",
    "                    )\n",
    "                \"\"\")\n",
    "                match_count = cursor.fetchone()[0]\n",
    "                if match_count > 0:\n",
    "                    print(f\"Foreign Key: {table_name}.ACCESSION_NUMBER -> FUND_REPORTED_INFO.ACCESSION_NUMBER\")\n",
    "            \n",
    "            elif col_name == 'HOLDING_ID':\n",
    "                cursor.execute(f\"\"\"\n",
    "                    SELECT COUNT(*) FROM {table_name} t1\n",
    "                    WHERE EXISTS (\n",
    "                        SELECT 1 FROM FUND_REPORTED_HOLDING t2 \n",
    "                        WHERE t1.HOLDING_ID = t2.HOLDING_ID\n",
    "                    )\n",
    "                \"\"\")\n",
    "                match_count = cursor.fetchone()[0]\n",
    "                if match_count > 0:\n",
    "                    print(f\"Foreign Key: {table_name}.HOLDING_ID -> FUND_REPORTED_HOLDING.HOLDING_ID\")\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "# Run the analysis\n",
    "explore_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='C:\\\\Users\\\\User\\\\anaconda3\\\\Library\\\\ssl\\\\cacert.pem'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Loading schema file: chatgpt_api/schema.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert financial data analyst specializing in natural language understanding and database schema analysis.\\nYour task is to analyze questions about financial data and extract key components that will help in database queries.\\n\\nObjective: Break down the given question into essential components that will help formulate a database query.\\n\\nInstructions:\\n1. Read the question carefully to identify:\\n- Individual keywords that map to database columns or values\\n- Technical terms related to financial data\\n- Named entities (companies, funds, locations)\\n- Numerical thresholds or values\\n\\n2. For each identified element, categorize it as:\\n- keywords: Individual significant words that might match database columns\\n- keyphrases: Multi-word expressions that represent single concepts\\n- named_entities: Specific names of companies, funds, or locations\\n- numerical_values: Any numbers, amounts, or thresholds\\n\\n3. Return a JSON object with these categories.'}, {'role': 'user', 'content': '\\nExample Question: \"Which PIMCO funds were registered between 2020 and 2023 with California addresses?\"\\n{\\n    \"keywords\": [\"funds\", \"registered\", \"addresses\"],\\n    \"keyphrases\": [\"PIMCO funds\"],\\n    \"named_entities\": [\"PIMCO\", \"California\"],\\n    \"numerical_values\": [\"2020\", \"2023\"]\\n}\\n\\nExample Question: \"Show me BlackRock funds with total assets over 1 billion managed in New York\"\\n{\\n    \"keywords\": [\"funds\", \"assets\", \"managed\"],\\n    \"keyphrases\": [\"total assets\"],\\n    \"named_entities\": [\"BlackRock\", \"New York\"],\\n    \"numerical_values\": [\"1 billion\"]\\n}\\nQuestion: \"Show me all funds with total assets over 1 billion\"\\n\\nExtract the key components and return as JSON.'}], 'model': 'gpt-4o', 'response_format': {'type': 'json_object'}}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002489C4C2E90>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x00000248E6F1DF40> server_hostname='api.openai.com' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002489C4D9690>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 21 Nov 2024 01:47:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-annfuni26pdtuawdwdj6zorw'), (b'openai-processing-ms', b'880'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999576'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'12ms'), (b'x-request-id', b'req_b8102023415a644a8873cadb30b98f33'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=5AdQeQt4T7Ym5HSgIy6Jxx_YcqR_d6RG0J0kb3grkzQ-1732153668-1.0.1.1-kc23ahwBr3Hy1B64GCFfQvYJCmjfMrsS78cKtCvs9aPbT8.HBQmmtazXI8Y5qkH2Dj5Ksa5Ulv6UN60ZKuAonA; path=/; expires=Thu, 21-Nov-24 02:17:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=6pjGH2WOeSrzyBFBfxAbqzX.uUEvM77jnP.p94MUNUY-1732153668638-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e5d03863c862b68-LAX'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Thu, 21 Nov 2024 01:47:48 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-annfuni26pdtuawdwdj6zorw'), ('openai-processing-ms', '880'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '2000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '1999576'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '12ms'), ('x-request-id', 'req_b8102023415a644a8873cadb30b98f33'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=5AdQeQt4T7Ym5HSgIy6Jxx_YcqR_d6RG0J0kb3grkzQ-1732153668-1.0.1.1-kc23ahwBr3Hy1B64GCFfQvYJCmjfMrsS78cKtCvs9aPbT8.HBQmmtazXI8Y5qkH2Dj5Ksa5Ulv6UN60ZKuAonA; path=/; expires=Thu, 21-Nov-24 02:17:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=6pjGH2WOeSrzyBFBfxAbqzX.uUEvM77jnP.p94MUNUY-1732153668638-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e5d03863c862b68-LAX'), ('content-encoding', 'br'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_b8102023415a644a8873cadb30b98f33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEBUG: Finding matches for 'billion'\n",
      "Found 2 matches for 'billion':\n",
      "  submission.filing_date: 0.6154\n",
      "  submission.is_last_filing: 0.6154\n",
      "\n",
      "DEBUG: Finding matches for 'total'\n",
      "Found 279 matches for 'total':\n",
      "  fund_reported_info.total_assets: 1.0000\n",
      "  fund_reported_info.total_liabilities: 1.0000\n",
      "  monthly_total_return.monthly_total_return_id: 1.0000\n",
      "  monthly_total_return.monthly_total_return1: 1.0000\n",
      "  monthly_total_return.monthly_total_return2: 1.0000\n",
      "\n",
      "DEBUG: Finding matches for '1'\n",
      "Found 0 matches for '1':\n",
      "\n",
      "DEBUG: Finding matches for 'asset'\n",
      "Found 7 matches for 'asset':\n",
      "  fund_reported_holding.asset_cat: 1.0000\n",
      "  monthly_return_cat_instrument.asset_cat: 1.0000\n",
      "  fund_reported_info.total_assets: 0.9000\n",
      "  fund_reported_info.net_assets: 0.9000\n",
      "  fund_reported_info.assets_attrbt_to_misc_security: 0.9000\n",
      "\n",
      "DEBUG: Finding matches for 'fund'\n",
      "Found 279 matches for 'fund':\n",
      "  securities_lending.is_loan_by_fund: 1.0000\n",
      "  registrant.accession_number: 0.9000\n",
      "  registrant.cik: 0.9000\n",
      "  registrant.registrant_name: 0.9000\n",
      "  registrant.file_num: 0.9000\n",
      "\n",
      "Processed Schema Links:\n",
      "Table Columns: ['fund_reported_info.total_assets', 'fund_reported_holding.asset_cat', 'securities_lending.is_loan_by_fund']\n",
      "Primary Keys: ['FUND_REPORTED_INFO.ACCESSION_NUMBER', 'FUND_REPORTED_HOLDING.ACCESSION_NUMBER', 'FUND_REPORTED_HOLDING.HOLDING_ID', 'SECURITIES_LENDING.HOLDING_ID']\n",
      "Foreign Keys: ['REGISTRANT.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'INTEREST_RATE_RISK.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'BORROWER.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'BORROW_AGGREGATE.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'MONTHLY_TOTAL_RETURN.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'MONTHLY_RETURN_CAT_INSTRUMENT.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'FUND_VAR_INFO.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'FUND_REPORTED_HOLDING.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'EXPLANATORY_NOTE.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'SUBMISSION.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'IDENTIFIERS.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'DEBT_SECURITY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'DEBT_SECURITY_REF_INSTRUMENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'CONVERTIBLE_SECURITY_CURRENCY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'REPURCHASE_AGREEMENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'REPURCHASE_COUNTERPARTY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'REPURCHASE_COLLATERAL.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'DERIVATIVE_COUNTERPARTY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'SWAPTION_OPTION_WARNT_DERIV.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'DESC_REF_INDEX_BASKET.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'DESC_REF_INDEX_COMPONENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'DESC_REF_OTHER.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'FUT_FWD_NONFOREIGNCUR_CONTRACT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'FWD_FOREIGNCUR_CONTRACT_SWAP.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'NONFOREIGN_EXCHANGE_SWAP.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'FLOATING_RATE_RESET_TENOR.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'OTHER_DERIV.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'OTHER_DERIV_NOTIONAL_AMOUNT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'SECURITIES_LENDING.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID']\n",
      "Schema Links: {'table_columns': ['fund_reported_info.total_assets', 'fund_reported_holding.asset_cat', 'securities_lending.is_loan_by_fund'], 'primary_keys': ['FUND_REPORTED_INFO.ACCESSION_NUMBER', 'FUND_REPORTED_HOLDING.ACCESSION_NUMBER', 'FUND_REPORTED_HOLDING.HOLDING_ID', 'SECURITIES_LENDING.HOLDING_ID'], 'foreign_keys': ['REGISTRANT.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'INTEREST_RATE_RISK.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'BORROWER.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'BORROW_AGGREGATE.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'MONTHLY_TOTAL_RETURN.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'MONTHLY_RETURN_CAT_INSTRUMENT.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'FUND_VAR_INFO.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'FUND_REPORTED_HOLDING.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'EXPLANATORY_NOTE.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'SUBMISSION.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'IDENTIFIERS.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'DEBT_SECURITY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'DEBT_SECURITY_REF_INSTRUMENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'CONVERTIBLE_SECURITY_CURRENCY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'REPURCHASE_AGREEMENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'REPURCHASE_COUNTERPARTY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'REPURCHASE_COLLATERAL.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'DERIVATIVE_COUNTERPARTY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'SWAPTION_OPTION_WARNT_DERIV.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'DESC_REF_INDEX_BASKET.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'DESC_REF_INDEX_COMPONENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'DESC_REF_OTHER.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'FUT_FWD_NONFOREIGNCUR_CONTRACT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'FWD_FOREIGNCUR_CONTRACT_SWAP.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'NONFOREIGN_EXCHANGE_SWAP.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'FLOATING_RATE_RESET_TENOR.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'OTHER_DERIV.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'OTHER_DERIV_NOTIONAL_AMOUNT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'SECURITIES_LENDING.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID']}\n"
     ]
    }
   ],
   "source": [
    "############################################ VALUE RETRIEVAL AND SCHEMA LINKING\n",
    "class PSLsh:\n",
    "    def __init__(self, vectors, n_planes=10, n_tables=5, seed: int = 42):\n",
    "        self.n_planes = n_planes\n",
    "        self.n_tables = n_tables\n",
    "        self.hash_tables = [{} for _ in range(n_tables)]\n",
    "        self.random_planes = []\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        for _ in range(n_tables):\n",
    "            planes = np.random.randn(vectors.shape[1], n_planes)\n",
    "            self.random_planes.append(planes)\n",
    "            \n",
    "        self.num_vectors = vectors.shape[0]\n",
    "        self.vectors = vectors\n",
    "        self.build_hash_tables()\n",
    "\n",
    "    def build_hash_tables(self):\n",
    "        for idx in range(self.num_vectors):\n",
    "            vector = self.vectors[idx].toarray()[0]\n",
    "            hashes = self.hash_vector(vector)\n",
    "            for i, h in enumerate(hashes):\n",
    "                if h not in self.hash_tables[i]:\n",
    "                    self.hash_tables[i][h] = []\n",
    "                self.hash_tables[i][h].append(idx)\n",
    "\n",
    "    def hash_vector(self, vector):\n",
    "        hashes = []\n",
    "        for planes in self.random_planes:\n",
    "            projections = np.dot(vector, planes)\n",
    "            hash_code = ''.join(['1' if x > 0 else '0' for x in projections])\n",
    "            hashes.append(hash_code)\n",
    "        return hashes\n",
    "\n",
    "    def query(self, vector):\n",
    "        hashes = self.hash_vector(vector)\n",
    "        candidates = set()\n",
    "        for i, h in enumerate(hashes):\n",
    "            candidates.update(self.hash_tables[i].get(h, []))\n",
    "        return candidates\n",
    "\n",
    "\n",
    "class ValueRetrieval:\n",
    "    financial_terms = {\n",
    "            'total': ['total', 'sum', 'aggregate', 'combined'],\n",
    "            'assets': ['asset', 'holdings', 'investments', 'securities'],\n",
    "            'liabilities': ['liability', 'debt', 'obligations'],\n",
    "            'net': ['net', 'pure', 'adjusted'],\n",
    "            'fund': ['fund', 'portfolio', 'investment vehicle'],\n",
    "            'return': ['return', 'yield', 'profit', 'gain'],\n",
    "            'monthly': ['monthly', 'month', 'monthly basis'],\n",
    "            'rate': ['rate', 'percentage', 'ratio'],\n",
    "            'risk': ['risk', 'exposure', 'vulnerability']\n",
    "        }\n",
    "    def __init__(self, schema_path: str = 'chatgpt_api/schema.json', lsh_seed: int = 42):\n",
    "        load_dotenv()\n",
    "        self.client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "        # Load schema\n",
    "        print(\"DEBUG: Loading schema file:\", schema_path)\n",
    "        with open(schema_path, 'r') as f:\n",
    "            self.schema = json.load(f)\n",
    "\n",
    "        # Initialize lemmatizer and stop words\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        # Build column name index\n",
    "        self.column_index = self._build_column_index()\n",
    "        \n",
    "        # Build common financial terms dictionary\n",
    "        \n",
    "\n",
    "        # Build vectorizer and LSH for backup matching\n",
    "        self.build_vectorizer_and_lsh(seed=lsh_seed)\n",
    "        \n",
    "        # Get schema relationships\n",
    "        self.primary_keys, self.foreign_keys = self.discover_schema_relationships()\n",
    "\n",
    "    def _build_column_index(self) -> Dict:\n",
    "        \"\"\"Build an index of all columns with their metadata.\"\"\"\n",
    "        column_index = {}\n",
    "        tables = self.schema.get('schema', {}).get('tables', [])\n",
    "        \n",
    "        for table in tables:\n",
    "            table_name = table.get('name', '').lower()\n",
    "            for column in table.get('columns', []):\n",
    "                column_name = column.get('name', '').lower()\n",
    "                \n",
    "                # Store both the full qualified name and column properties\n",
    "                qualified_name = f\"{table_name}.{column_name}\"\n",
    "                column_index[qualified_name] = {\n",
    "                    'table': table_name,\n",
    "                    'column': column_name,\n",
    "                    'type': column.get('type', ''),\n",
    "                    'words': self._split_column_name(column_name),\n",
    "                    'synonyms': self._get_column_synonyms(column_name)\n",
    "                }\n",
    "                \n",
    "        return column_index\n",
    "\n",
    "    def _split_column_name(self, column_name: str) -> List[str]:\n",
    "        \"\"\"Split column name into individual words.\"\"\"\n",
    "        # Handle both underscore and camel case\n",
    "        words = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', column_name)).split()\n",
    "        words.extend(column_name.split('_'))\n",
    "        return [word.lower() for word in words if word]\n",
    "\n",
    "    def _get_column_synonyms(self, column_name: str) -> List[str]:\n",
    "        \"\"\"Get synonyms for words in column name.\"\"\"\n",
    "        words = self._split_column_name(column_name)\n",
    "        synonyms = []\n",
    "        \n",
    "        for word in words:\n",
    "            if word in self.financial_terms:\n",
    "                synonyms.extend(self.financial_terms[word])\n",
    "                \n",
    "        return list(set(synonyms))\n",
    "\n",
    "    def build_vectorizer_and_lsh(self, seed: int):\n",
    "        self.vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1, 3), min_df=1, max_df=0.95)\n",
    "        self.term_list = self.get_schema_terms()\n",
    "        self.term_vectors = self.vectorizer.fit_transform(self.term_list)\n",
    "        self.lsh = PSLsh(self.term_vectors, n_planes=10, n_tables=5)\n",
    "\n",
    "    def get_schema_terms(self) -> List[str]:\n",
    "        terms = []\n",
    "        tables = self.schema.get('schema', {}).get('tables', [])\n",
    "        for table in tables:\n",
    "            table_name = table.get('name', '').lower()\n",
    "            terms.append(table_name)\n",
    "            for column in table.get('columns', []):\n",
    "                column_name = column.get('name', '').lower()\n",
    "                terms.append(f\"{table_name}.{column_name}\")\n",
    "        return terms\n",
    "\n",
    "    def discover_schema_relationships(self):\n",
    "        # Define our primary keys and foreign keys here\n",
    "        primary_keys = {\n",
    "            'SUBMISSION': ['ACCESSION_NUMBER'],\n",
    "            'REGISTRANT': ['ACCESSION_NUMBER'],\n",
    "            'FUND_REPORTED_INFO': ['ACCESSION_NUMBER'],\n",
    "            'INTEREST_RATE_RISK': ['ACCESSION_NUMBER', 'INTEREST_RATE_RISK_ID'],\n",
    "            'BORROWER': ['ACCESSION_NUMBER', 'BORROWER_ID'],\n",
    "            'BORROW_AGGREGATE': ['ACCESSION_NUMBER', 'BORROW_AGGREGATE_ID'],\n",
    "            'MONTHLY_TOTAL_RETURN': ['ACCESSION_NUMBER', 'MONTHLY_TOTAL_RETURN_ID'],\n",
    "            'MONTHLY_RETURN_CAT_INSTRUMENT': ['ACCESSION_NUMBER', 'ASSET_CAT', 'INSTRUMENT_KIND'],\n",
    "            'FUND_VAR_INFO': ['ACCESSION_NUMBER'],\n",
    "            'FUND_REPORTED_HOLDING': ['ACCESSION_NUMBER', 'HOLDING_ID'],\n",
    "            'IDENTIFIERS': ['HOLDING_ID', 'IDENTIFIERS_ID'],\n",
    "            'DEBT_SECURITY': [],  \n",
    "            'DEBT_SECURITY_REF_INSTRUMENT': ['HOLDING_ID', 'DEBT_SECURITY_REF_ID'],\n",
    "            'CONVERTIBLE_SECURITY_CURRENCY': ['HOLDING_ID', 'CONVERTIBLE_SECURITY_ID'],\n",
    "            'REPURCHASE_AGREEMENT': ['HOLDING_ID'],\n",
    "            'REPURCHASE_COUNTERPARTY': ['HOLDING_ID', 'REPURCHASE_COUNTERPARTY_ID'],\n",
    "            'REPURCHASE_COLLATERAL': ['HOLDING_ID', 'REPURCHASE_COLLATERAL_ID'],\n",
    "            'DERIVATIVE_COUNTERPARTY': ['HOLDING_ID', 'DERIVATIVE_COUNTERPARTY_ID'],\n",
    "            'SWAPTION_OPTION_WARNT_DERIV': ['HOLDING_ID'],\n",
    "            'DESC_REF_INDEX_BASKET': ['HOLDING_ID'],\n",
    "            'DESC_REF_INDEX_COMPONENT': ['HOLDING_ID', 'DESC_REF_INDEX_COMPONENT_ID'],\n",
    "            'DESC_REF_OTHER': ['HOLDING_ID', 'DESC_REF_OTHER_ID'],\n",
    "            'FUT_FWD_NONFOREIGNCUR_CONTRACT': ['HOLDING_ID'],\n",
    "            'FWD_FOREIGNCUR_CONTRACT_SWAP': ['HOLDING_ID'],\n",
    "            'NONFOREIGN_EXCHANGE_SWAP': ['HOLDING_ID'],\n",
    "            'FLOATING_RATE_RESET_TENOR': ['HOLDING_ID', 'RATE_RESET_TENOR_ID'],\n",
    "            'OTHER_DERIV': ['HOLDING_ID'],\n",
    "            'OTHER_DERIV_NOTIONAL_AMOUNT': ['HOLDING_ID', 'OTHER_DERIV_NOTIONAL_AMOUNT_ID'],\n",
    "            'SECURITIES_LENDING': ['HOLDING_ID'],\n",
    "            'EXPLANATORY_NOTE': ['ACCESSION_NUMBER', 'EXPLANATORY_NOTE_ID']\n",
    "        }\n",
    "\n",
    "        foreign_keys = [\n",
    "            # ACCESSION_NUMBER relationships\n",
    "            'REGISTRANT.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'INTEREST_RATE_RISK.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'BORROWER.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'BORROW_AGGREGATE.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'MONTHLY_TOTAL_RETURN.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'MONTHLY_RETURN_CAT_INSTRUMENT.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'FUND_VAR_INFO.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'FUND_REPORTED_HOLDING.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'EXPLANATORY_NOTE.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "            'SUBMISSION.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER',\n",
    "\n",
    "            # HOLDING_ID relationships\n",
    "            'IDENTIFIERS.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'DEBT_SECURITY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'DEBT_SECURITY_REF_INSTRUMENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'CONVERTIBLE_SECURITY_CURRENCY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'REPURCHASE_AGREEMENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'REPURCHASE_COUNTERPARTY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'REPURCHASE_COLLATERAL.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'DERIVATIVE_COUNTERPARTY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'SWAPTION_OPTION_WARNT_DERIV.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'DESC_REF_INDEX_BASKET.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'DESC_REF_INDEX_COMPONENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'DESC_REF_OTHER.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'FUT_FWD_NONFOREIGNCUR_CONTRACT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'FWD_FOREIGNCUR_CONTRACT_SWAP.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'NONFOREIGN_EXCHANGE_SWAP.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'FLOATING_RATE_RESET_TENOR.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'OTHER_DERIV.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'OTHER_DERIV_NOTIONAL_AMOUNT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID',\n",
    "            'SECURITIES_LENDING.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID'\n",
    "        ]\n",
    "\n",
    "        formatted_pks = []\n",
    "        for table, keys in primary_keys.items():\n",
    "            for key in keys:\n",
    "                formatted_pks.append(f\"{table}.{key}\")\n",
    "\n",
    "        return formatted_pks, foreign_keys\n",
    "\n",
    "    def find_similar_words(self, word: str) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Enhanced matching using multiple techniques.\"\"\"\n",
    "        if not word:\n",
    "            return []\n",
    "\n",
    "        word = word.lower()\n",
    "        print(f\"\\nDEBUG: Finding matches for '{word}'\")\n",
    "        \n",
    "        matches = []\n",
    "        \n",
    "        # 1. Direct matching with column names and their components\n",
    "        for qualified_name, metadata in self.column_index.items():\n",
    "            score = 0.0\n",
    "            \n",
    "            # Check exact matches in column words\n",
    "            if word in metadata['words']:\n",
    "                matches.append((qualified_name, 1.0))\n",
    "                continue\n",
    "                \n",
    "            # Check synonyms\n",
    "            if word in self.financial_terms.get(word, []):\n",
    "                matches.append((qualified_name, 0.9))\n",
    "                continue\n",
    "            \n",
    "            # Fuzzy match with column words\n",
    "            for col_word in metadata['words']:\n",
    "                ratio = fuzz.ratio(word, col_word) / 100.0\n",
    "                if ratio > score:\n",
    "                    score = ratio\n",
    "            \n",
    "            # Fuzzy match with synonyms\n",
    "            for term, synonyms in self.financial_terms.items():\n",
    "                if term in metadata['words']:\n",
    "                    for synonym in synonyms:\n",
    "                        ratio = fuzz.ratio(word, synonym) / 100.0\n",
    "                        if ratio > score:\n",
    "                            score = ratio * 0.9  # Slightly lower weight for synonym matches\n",
    "            \n",
    "            if score > 0.6:  # Only include if similarity is above 60%\n",
    "                matches.append((qualified_name, score))\n",
    "\n",
    "        # 2. LSH-based matching as backup\n",
    "        if len(matches) < 5:  # If we have fewer than 5 matches, try LSH\n",
    "            try:\n",
    "                word_vector = self.vectorizer.transform([word]).toarray()[0]\n",
    "                candidate_indices = self.lsh.query(word_vector)\n",
    "                \n",
    "                for idx in candidate_indices:\n",
    "                    term = self.term_list[idx]\n",
    "                    if not any(term == m[0] for m in matches):  # Avoid duplicates\n",
    "                        candidate_vector = self.term_vectors[idx].toarray()[0]\n",
    "                        dist = np.linalg.norm(word_vector - candidate_vector)\n",
    "                        sim = 1 / (1 + dist)\n",
    "                        if sim > 0.5:  # Only include if similarity is above 50%\n",
    "                            matches.append((term, sim * 0.8))\n",
    "            except Exception as e:\n",
    "                print(f\"LSH matching failed: {e}\")\n",
    "\n",
    "        # Remove duplicates keeping highest score and sort by score\n",
    "        unique_matches = {}\n",
    "        for term, score in matches:\n",
    "            if term not in unique_matches or score > unique_matches[term]:\n",
    "                unique_matches[term] = score\n",
    "        \n",
    "        matches = [(term, score) for term, score in unique_matches.items()]\n",
    "        matches.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Print debug info\n",
    "        print(f\"Found {len(matches)} matches for '{word}':\")\n",
    "        for match, score in matches[:5]:\n",
    "            print(f\"  {match}: {score:.4f}\")\n",
    "        \n",
    "        return matches[:5] if matches else [('fund_reported_info.total_assets', 0.6)] if word in ['total', 'asset', 'assets'] else []\n",
    "\n",
    "    def extract_keywords(self, question: str) -> Dict:\n",
    "        system_prompt = \"\"\"You are an expert financial data analyst specializing in natural language understanding and database schema analysis.\n",
    "Your task is to analyze questions about financial data and extract key components that will help in database queries.\n",
    "\n",
    "Objective: Break down the given question into essential components that will help formulate a database query.\n",
    "\n",
    "Instructions:\n",
    "1. Read the question carefully to identify:\n",
    "- Individual keywords that map to database columns or values\n",
    "- Technical terms related to financial data\n",
    "- Named entities (companies, funds, locations)\n",
    "- Numerical thresholds or values\n",
    "\n",
    "2. For each identified element, categorize it as:\n",
    "- keywords: Individual significant words that might match database columns\n",
    "- keyphrases: Multi-word expressions that represent single concepts\n",
    "- named_entities: Specific names of companies, funds, or locations\n",
    "- numerical_values: Any numbers, amounts, or thresholds\n",
    "\n",
    "3. Return a JSON object with these categories.\"\"\"\n",
    "\n",
    "        few_shot_examples = \"\"\"\n",
    "Example Question: \"Which PIMCO funds were registered between 2020 and 2023 with California addresses?\"\n",
    "{\n",
    "    \"keywords\": [\"funds\", \"registered\", \"addresses\"],\n",
    "    \"keyphrases\": [\"PIMCO funds\"],\n",
    "    \"named_entities\": [\"PIMCO\", \"California\"],\n",
    "    \"numerical_values\": [\"2020\", \"2023\"]\n",
    "}\n",
    "\n",
    "Example Question: \"Show me BlackRock funds with total assets over 1 billion managed in New York\"\n",
    "{\n",
    "    \"keywords\": [\"funds\", \"assets\", \"managed\"],\n",
    "    \"keyphrases\": [\"total assets\"],\n",
    "    \"named_entities\": [\"BlackRock\", \"New York\"],\n",
    "    \"numerical_values\": [\"1 billion\"]\n",
    "}\"\"\"\n",
    "\n",
    "        formatted_prompt = system_prompt\n",
    "        user_prompt = f\"Question: \\\"{question}\\\"\\n\\nExtract the key components and return as JSON.\"\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": formatted_prompt},\n",
    "                {\"role\": \"user\", \"content\": few_shot_examples + \"\\n\" + user_prompt}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        return json.loads(response.choices[0].message.content)\n",
    "\n",
    "    def preprocess_text(self, text: str) -> List[str]:\n",
    "        \"\"\"Tokenize and lemmatize input text, removing stop words.\"\"\"\n",
    "        if not text:  # Add check for empty text\n",
    "            return []\n",
    "            \n",
    "        try:\n",
    "            tokens = nltk.word_tokenize(str(text).lower())\n",
    "            filtered_tokens = [word for word in tokens if word not in self.stop_words and word.isalnum()]\n",
    "            lemmatized_tokens = [self.lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "            return lemmatized_tokens\n",
    "        except Exception as e:\n",
    "            print(f\"Error in preprocessing text '{text}': {str(e)}\")\n",
    "            return []  # Return empty list instead of None on error\n",
    "       \n",
    "       \n",
    "    def process_schema(self, question: str) -> str:\n",
    "        # Get all the processing results\n",
    "        results = self.process_question(question)\n",
    "        \n",
    "        # Organize schema links by type\n",
    "        table_columns = []\n",
    "        relevant_primary_keys = []\n",
    "        relevant_foreign_keys = []\n",
    "        \n",
    "        # 1. Get main table/column matches\n",
    "        for word, matches in results['similar_matches'].items():\n",
    "            if matches:\n",
    "                # Only take the top match if score > 0.7\n",
    "                top_match = matches[0]  # (match, score)\n",
    "                if top_match[1] > 0.7:\n",
    "                    # Handle numerical values\n",
    "                    if word in results['extracted_info'].get('numerical_values', []):\n",
    "                        if 'billion' in word.lower():\n",
    "                            table_columns.append(f\"{top_match[0]} > 1000000000\")\n",
    "                        elif 'million' in word.lower():\n",
    "                            table_columns.append(f\"{top_match[0]} > 1000000\")\n",
    "                        else:\n",
    "                            table_columns.append(f\"{top_match[0]} > {word}\")\n",
    "                    else:\n",
    "                        table_columns.append(top_match[0])\n",
    "        \n",
    "        # 2. Get relevant tables\n",
    "        tables_needed = set()\n",
    "        for link in table_columns:\n",
    "            if '.' in link:\n",
    "                tables_needed.add(link.split('.')[0].upper())\n",
    "        \n",
    "        # 3. Add relevant primary keys\n",
    "        for pk in results['schema_relationships']['primary_keys']:\n",
    "            table = pk.split('.')[0]\n",
    "            if table in tables_needed:\n",
    "                relevant_primary_keys.append(pk)\n",
    "        \n",
    "        # 4. Add relevant foreign keys\n",
    "        for fk in results['schema_relationships']['foreign_keys']:\n",
    "            tables_in_fk = set(part.split('.')[0] for part in fk.split(' = '))\n",
    "            if tables_in_fk.intersection(tables_needed):\n",
    "                relevant_foreign_keys.append(fk)\n",
    "        \n",
    "        # Format output with sections\n",
    "        schema_dict = {\n",
    "            \"table_columns\": table_columns,\n",
    "            \"primary_keys\": relevant_primary_keys,\n",
    "            \"foreign_keys\": relevant_foreign_keys\n",
    "        }\n",
    "        \n",
    "        print(\"\\nProcessed Schema Links:\")\n",
    "        print(\"Table Columns:\", table_columns)\n",
    "        print(\"Primary Keys:\", relevant_primary_keys)\n",
    "        print(\"Foreign Keys:\", relevant_foreign_keys)\n",
    "        \n",
    "        return str(schema_dict)\n",
    "\n",
    "\n",
    "    def process_question(self, question: str) -> Dict:\n",
    "        # Extract keywords using gpt\n",
    "        extracted_info = self.extract_keywords(question)\n",
    "\n",
    "        words = []\n",
    "        for key in ['keywords', 'keyphrases', 'named_entities', 'numerical_values']:\n",
    "            words.extend(extracted_info.get(key, []))\n",
    "\n",
    "        # Preprocess the words (lemmatize, remove stop words)\n",
    "        processed_words = []\n",
    "        for word in words:\n",
    "            processed_words.extend(self.preprocess_text(word))\n",
    "\n",
    "        # Remove duplicates\n",
    "        processed_words = list(set(processed_words))\n",
    "\n",
    "        # Find similar columns for each word\n",
    "        similar_matches = {}\n",
    "        for word in processed_words:\n",
    "            similar_matches[word] = self.find_similar_words(word)\n",
    "\n",
    "        # Combine the results\n",
    "        result = {\n",
    "            \"question\": question,\n",
    "            \"extracted_info\": extracted_info,\n",
    "            \"processed_words\": processed_words,\n",
    "            \"similar_matches\": similar_matches,\n",
    "            \"schema_relationships\": {\n",
    "                \"primary_keys\": self.primary_keys,\n",
    "                \"foreign_keys\": self.foreign_keys\n",
    "            }\n",
    "        }\n",
    "        return result\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    vr = ValueRetrieval(schema_path='chatgpt_api/schema.json')\n",
    "    schema_links = vr.process_schema(\"Show me all funds with total assets over 1 billion\")\n",
    "    print(\"Schema Links:\", schema_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ CLASSIFICATION\n",
    "classification_prompt = '''Q: \"Find the filing date and submission number of all reports filed for an NPORT-P submission.\"\n",
    "schema_links: [submission.filing_date, submission.sub_type = \"NPORT-P\", submission.accession_number]\n",
    "A: Lets think step by step. The SQL query for the question \"Find the filing date and submission number of all reports filed for an NPORT-P submission.\" needs these tables = [submission], so we don't need JOIN.\n",
    "Plus, it doesn't require nested queries with (INTERSECT, UNION, EXCEPT, IN, NOT IN), and we need the answer to the questions = [\"\"]. \n",
    "So, we don't need JOIN and don't need nested queries, then the SQL query can be classified as \"EASY\".\n",
    "Label: \"EASY\"\n",
    "\n",
    "Q: \"Get the names and CIK of registrants who are located in California.\"\n",
    "schema_links: [registrant.registrant_name, registrant.cik, registrant.state = \"US-CA\"]\n",
    "A: Lets think step by step. The SQL query for the question \"Get the names and CIK of registrants who are located in California.\" needs these tables = [registrant], so we don't need JOIN.\n",
    "Plus, it doesn't require nested queries with (INTERSECT, UNION, EXCEPT, IN, NOT IN), and we need the answer to the questions = [\"\"]. \n",
    "So, we don't need JOIN and don't need nested queries, then the SQL query can be classified as \"EASY\".\n",
    "Label: \"EASY\"\n",
    "\n",
    "Q: \"Find the names and CIK of registrants in California, but only for those whose total assets are above 100 million.\"\n",
    "schema_links: [registrant.registrant_name, registrant.cik, registrant.state = \"US-CA\", fund_reported_info.total_assets > 100000000]\n",
    "A: Let's analyze this. The query involves data from two tables: \"registrant\" for registrant details and \"fund_reported_info\" for total assets. Since we need to check if total assets exceed 100 million, a nested query is necessary to filter based on this condition. This is a nested query. So, the SQL query can be classified as \"NESTED.\"\n",
    "Label: \"NESTED\"\n",
    "\n",
    "'''\n",
    "\n",
    "def classification_prompt_maker(question,relevant_schema_links):\n",
    "  instruction = \"# For the given question, classify it as EASY, NON-NESTED, or NESTED based on nested queries and JOIN.\\n\"\n",
    "  instruction += \"\\nif need nested queries: predict NESTED\\n\"\n",
    "  instruction += \"elif need JOIN and don't need nested queries: predict NON-NESTED\\n\"\n",
    "  instruction += \"elif don't need JOIN and don't need nested queries: predict EASY\\n\\n\"\n",
    "  prompt = instruction + classification_prompt + 'Q: \"' + question + '\\nrelevant_schema_links: ' + relevant_schema_links + '\\nA: Lets think step by step.'\n",
    "  return prompt\n",
    "\n",
    "def process_question_classification(question, relevant_schema_links):\n",
    "    classification = None\n",
    "    attempts = 0\n",
    "    while classification is None and attempts < 3:\n",
    "        try:\n",
    "            print(\"Attempting classification...\")\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[{\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": classification_prompt_maker(question, relevant_schema_links=relevant_schema_links)\n",
    "                }],\n",
    "                n=1,\n",
    "                stream=False,\n",
    "                temperature=0.0,\n",
    "                max_tokens=300,  # Reduced max tokens\n",
    "                top_p=1.0,\n",
    "                frequency_penalty=0.0,\n",
    "                presence_penalty=0.0\n",
    "                # Removed the stop sequence\n",
    "            )\n",
    "            classification = response.choices[0].message.content\n",
    "            print(\"Raw response:\", classification)\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {str(e)}\")\n",
    "            time.sleep(3)\n",
    "            attempts += 1\n",
    "    \n",
    "    if classification is None:\n",
    "        print(\"Failed to get classification after 3 attempts\")\n",
    "        return '\"NESTED\"'\n",
    "        \n",
    "    try:\n",
    "        predicted_class = classification.split(\"Label: \")[1].strip().strip('\"')\n",
    "        return f'\"{predicted_class}\"'\n",
    "    except:\n",
    "        print(\"Slicing error for the classification module\")\n",
    "        return '\"NESTED\"'\n",
    "\n",
    "\n",
    "############################################ SQL GENERATION\n",
    "easy_prompt = '''Q: \"Find the issuers with a balance greater than 1 million.\"\n",
    "Schema_links: [fund_reported_holding.balance]\n",
    "SQL: SELECT DISTINCT issuer_name \n",
    "      FROM fund_reported_holding \n",
    "      WHERE balance > 1000000\n",
    "'''\n",
    "\n",
    "medium_prompt = '''Q: \"Find the total upfront payments and receipts for swaps with fixed rate receipts.\"\n",
    "Schema_links: [nonforeign_exchange_swap.upfront_payment, nonforeign_exchange_swap.upfront_receipt, nonforeign_exchange_swap.fixed_rate_receipt]\n",
    "A: Lets think step by step. For creating the SQL for the given question, we need to filter the swaps that have fixed rate receipts. Then, sum up the upfront payments and receipts. First, create an intermediate representation, then use it to construct the SQL query.\n",
    "Intermediate_representation: \n",
    "SELECT SUM(nonforeign_exchange_swap.upfront_payment) + SUM(nonforeign_exchange_swap.upfront_receipt) \n",
    "FROM nonforeign_exchange_swap \n",
    "WHERE nonforeign_exchange_swap.fixed_rate_receipt IS NOT NULL\n",
    "SQL: \n",
    "SELECT SUM(upfront_payment) + SUM(upfront_receipt) \n",
    "FROM nonforeign_exchange_swap \n",
    "WHERE fixed_rate_receipt IS NOT NULL\n",
    "'''\n",
    "\n",
    "hard_prompt = '''Q: \"Find the borrowers with aggregate value greater than $1 million and whose interest rate change at 10-year maturity for a 100 basis point change is positive.\"\n",
    "Schema_links: [borrower.aggregate_value, borrower.name, interest_rate_risk.intrst_rate_change_10yr_dv100]\n",
    "A: Let's think step by step. First, we need to filter borrowers with aggregate values greater than $1 million. Then, we need to check for interest rate changes at 10-year maturity where the change is positive. \n",
    "The SQL query for the sub-question \"What are the borrowers with aggregate value greater than $1 million and positive interest rate change at 10-year maturity for 100 basis points?\" is:\n",
    "\n",
    "Intermediate_representation: \n",
    "SELECT borrower.name \n",
    "FROM borrower \n",
    "JOIN interest_rate_risk \n",
    "ON borrower.accession_number = interest_rate_risk.accession_number \n",
    "WHERE borrower.aggregate_value > 1000000 \n",
    "AND interest_rate_risk.intrst_rate_change_10yr_dv100 > 0\n",
    "\n",
    "SQL: \n",
    "SELECT borrower.name \n",
    "FROM borrower \n",
    "JOIN interest_rate_risk \n",
    "ON borrower.accession_number = interest_rate_risk.accession_number \n",
    "WHERE borrower.aggregate_value > 1000000 \n",
    "AND interest_rate_risk.intrst_rate_change_10yr_dv100 > 0\n",
    "'''\n",
    "\n",
    "def hard_prompt_maker(question,database,schema_links,sub_questions=\"\"):\n",
    "    instruction = \"# Use the intermediate representation and the schema links to generate the SQL queries for each of the questions.\\n\"\n",
    "    if sub_questions==\"\":\n",
    "        stepping = f'''\\nA: Let's think step by step. \"{question}\" can be solved by first solving a sub-question using nested queries\".'''\n",
    "    else:\n",
    "        stepping = f'''\\nA: Let's think step by step. \"{question}\" can be solved by first solving the answer to the following sub-question \"{sub_questions}\".'''\n",
    "    prompt = instruction + hard_prompt+ chat_prompt.gpt_queries_hard+ 'Q: \"' + question + '\"' + '\\nschema_links: ' + schema_links + stepping +'\\nThe SQL query for the sub-question:\"'\n",
    "    return prompt\n",
    "\n",
    "def medium_prompt_maker(question,database,schema_links):\n",
    "    instruction = \"# Use the the schema links and Intermediate_representation to generate the SQL queries for each of the questions.\\n\"\n",
    "    prompt = instruction + medium_prompt + chat_prompt.gpt_queries_medium+ 'Q: \"' + question + '\\nSchema_links: ' + schema_links + '\\nA: Lets think step by step.'\n",
    "    return prompt\n",
    "\n",
    "def easy_prompt_maker(question,database,schema_links):\n",
    "    instruction = \"# Use the the schema links to generate the SQL queries for each of the questions.\\n\"\n",
    "    prompt = instruction + easy_prompt + chat_prompt.gpt_queries_easy + 'Q: \"' + question + '\\nSchema_links: ' + schema_links + '\\nSQL:'\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def process_question_sql(question, predicted_class, schema_links, max_retries=3):\n",
    "    if '\"EASY\"' in predicted_class:\n",
    "        print(\"EASY\")\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                SQL = GPT4_generation(easy_prompt_maker(\n",
    "                    question=question,\n",
    "                    database='nport',  # Added database parameter\n",
    "                    schema_links=schema_links\n",
    "                ))\n",
    "                if SQL:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(3)\n",
    "                else:\n",
    "                    SQL = \"SELECT\"  # Default fallback\n",
    "                    \n",
    "    elif '\"NON-NESTED\"' in predicted_class:\n",
    "        print(\"NON-NESTED\")\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                SQL = GPT4_generation(medium_prompt_maker(\n",
    "                    question=question,\n",
    "                    database='nport',  # Added database parameter\n",
    "                    schema_links=schema_links\n",
    "                ))\n",
    "                if SQL:\n",
    "                    try:\n",
    "                        SQL = SQL.split(\"SQL: \")[1]\n",
    "                        break\n",
    "                    except:\n",
    "                        print(\"SQL slicing error\")\n",
    "                        SQL = \"SELECT\"\n",
    "            except Exception as e:\n",
    "                print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(3)\n",
    "                else:\n",
    "                    SQL = \"SELECT\"  # Default fallback\n",
    "                    \n",
    "    else:\n",
    "        print(\"NESTED\")\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                SQL = GPT4_generation(hard_prompt_maker(\n",
    "                    question=question,\n",
    "                    database='nport',  # Added database parameter\n",
    "                    schema_links=schema_links\n",
    "                ))\n",
    "                if SQL:\n",
    "                    try:\n",
    "                        SQL = SQL.split(\"SQL: \")[1]\n",
    "                        break\n",
    "                    except:\n",
    "                        print(\"SQL slicing error\")\n",
    "                        SQL = \"SELECT\"\n",
    "            except Exception as e:\n",
    "                print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(3)\n",
    "                else:\n",
    "                    SQL = \"SELECT\"  # Default fallback\n",
    "\n",
    "    #print(\"Generated SQL:\", SQL)\n",
    "    return SQL if SQL else \"SELECT\"\n",
    "\n",
    "\n",
    "def GPT4_generation(prompt, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\", \n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                n = 1,\n",
    "                stream = False,\n",
    "                temperature=0.0,\n",
    "                max_tokens=600,\n",
    "                top_p = 1.0,\n",
    "                frequency_penalty=0.0,\n",
    "                presence_penalty=0.0\n",
    "                # Removed stop=[\"Q:\"] as it cause issues\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(3)\n",
    "            else:\n",
    "                print(\"Max retries reached\")\n",
    "                return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ SELF CORRECTION\n",
    "def debuger(test_sample_text,sql):\n",
    "\tinstruction = \"\"\"#### For the given question, use the provided tables, columns, foreign keys, and primary keys to fix the given SQLite SQL QUERY for any issues. If there are any problems, fix them and return the fixed SQLite QUERY in the output. If there are no issues, return the SQLite SQL QUERY as is in the output.\n",
    "#### Use the following instructions for fixing the SQL QUERY:\n",
    "1) Use the database values that are explicitly mentioned in the question.\n",
    "2) Pay attention to the columns that are used for the JOIN by using the Foreign_keys.\n",
    "3) Use DESC and DISTINCT when needed.\n",
    "4) Pay attention to the columns that are used for the GROUP BY statement.\n",
    "5) Pay attention to the columns that are used for the SELECT statement.\n",
    "6) Only change the GROUP BY clause when necessary (Avoid redundant columns in GROUP BY).\n",
    "7) Use GROUP BY on one column only.\n",
    "\"\"\"\n",
    "\tprompt = instruction + '#### Question: ' + test_sample_text + '\\n#### SQLite SQL QUERY\\n' + sql +'\\n#### SQLite FIXED SQL QUERY'\n",
    "\treturn prompt\n",
    "\n",
    "\n",
    "\n",
    "def GPT4_debug(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        n = 1,\n",
    "        stream = False,\n",
    "        temperature=0.0,\n",
    "        max_tokens=350,\n",
    "        top_p = 1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0,\n",
    "        stop = [\"#\", \";\",\"\\n\\n\"]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def refine_query(question, sql):\n",
    "\tdebugged_SQL = None\n",
    "\twhile debugged_SQL is None:\n",
    "\t\ttry:\n",
    "\t\t\tdebugged_SQL = GPT4_debug(debuger(question,sql)).replace(\"\\n\", \" \")\n",
    "\t\texcept:\n",
    "\t\t\ttime.sleep(3)\n",
    "\t\t\tpass\n",
    "\tSQL = debugged_SQL.split('sql', 1)\n",
    "\tprint(SQL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='C:\\\\Users\\\\User\\\\anaconda3\\\\Library\\\\ssl\\\\cacert.pem'\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are an expert financial data analyst specializing in natural language understanding and database schema analysis.\\nYour task is to analyze questions about financial data and extract key components that will help in database queries.\\n\\nObjective: Break down the given question into essential components that will help formulate a database query.\\n\\nInstructions:\\n1. Read the question carefully to identify:\\n- Individual keywords that map to database columns or values\\n- Technical terms related to financial data\\n- Named entities (companies, funds, locations)\\n- Numerical thresholds or values\\n\\n2. For each identified element, categorize it as:\\n- keywords: Individual significant words that might match database columns\\n- keyphrases: Multi-word expressions that represent single concepts\\n- named_entities: Specific names of companies, funds, or locations\\n- numerical_values: Any numbers, amounts, or thresholds\\n\\n3. Return a JSON object with these categories.'}, {'role': 'user', 'content': '\\nExample Question: \"Which PIMCO funds were registered between 2020 and 2023 with California addresses?\"\\n{\\n    \"keywords\": [\"funds\", \"registered\", \"addresses\"],\\n    \"keyphrases\": [\"PIMCO funds\"],\\n    \"named_entities\": [\"PIMCO\", \"California\"],\\n    \"numerical_values\": [\"2020\", \"2023\"]\\n}\\n\\nExample Question: \"Show me BlackRock funds with total assets over 1 billion managed in New York\"\\n{\\n    \"keywords\": [\"funds\", \"assets\", \"managed\"],\\n    \"keyphrases\": [\"total assets\"],\\n    \"named_entities\": [\"BlackRock\", \"New York\"],\\n    \"numerical_values\": [\"1 billion\"]\\n}\\nQuestion: \"Show me all funds with total assets over 1 billion\"\\n\\nExtract the key components and return as JSON.'}], 'model': 'gpt-4o', 'response_format': {'type': 'json_object'}}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002489B0BFE10>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Loading schema file: chatgpt_api/schema.json\n",
      "\n",
      "==================================================\n",
      "\n",
      "Processing question: Show me all funds with total assets over 1 billion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x00000248E703A840> server_hostname='api.openai.com' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002489B0D4790>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 21 Nov 2024 01:47:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-annfuni26pdtuawdwdj6zorw'), (b'openai-processing-ms', b'869'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999576'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'12ms'), (b'x-request-id', b'req_c8813e6d477dc64d1804430d2fa522c2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=jFl46mUYt3Gu4gu3X0P3xgqgoTfIp6VXUTZk5hUTOnY-1732153671-1.0.1.1-.uAjrw9_f_eXVWhf88D2KoA7FISjRpNiNFfxrx.mGWRBHP5IDobbKCmRO_CuR7mZmWSOS.tERtc29g3WMncmQA; path=/; expires=Thu, 21-Nov-24 02:17:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=a2dJ0p2hWROpvYZ.PNHEnvTd8ISnUrgEQokwW76qHRw-1732153671502-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e5d0398afe00fb1-LAX'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Thu, 21 Nov 2024 01:47:51 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-annfuni26pdtuawdwdj6zorw'), ('openai-processing-ms', '869'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '2000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '1999576'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '12ms'), ('x-request-id', 'req_c8813e6d477dc64d1804430d2fa522c2'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=jFl46mUYt3Gu4gu3X0P3xgqgoTfIp6VXUTZk5hUTOnY-1732153671-1.0.1.1-.uAjrw9_f_eXVWhf88D2KoA7FISjRpNiNFfxrx.mGWRBHP5IDobbKCmRO_CuR7mZmWSOS.tERtc29g3WMncmQA; path=/; expires=Thu, 21-Nov-24 02:17:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=a2dJ0p2hWROpvYZ.PNHEnvTd8ISnUrgEQokwW76qHRw-1732153671502-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e5d0398afe00fb1-LAX'), ('content-encoding', 'br'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_c8813e6d477dc64d1804430d2fa522c2\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': '# For the given question, classify it as EASY, NON-NESTED, or NESTED based on nested queries and JOIN.\\n\\nif need nested queries: predict NESTED\\nelif need JOIN and don\\'t need nested queries: predict NON-NESTED\\nelif don\\'t need JOIN and don\\'t need nested queries: predict EASY\\n\\nQ: \"Find the filing date and submission number of all reports filed for an NPORT-P submission.\"\\nschema_links: [submission.filing_date, submission.sub_type = \"NPORT-P\", submission.accession_number]\\nA: Lets think step by step. The SQL query for the question \"Find the filing date and submission number of all reports filed for an NPORT-P submission.\" needs these tables = [submission], so we don\\'t need JOIN.\\nPlus, it doesn\\'t require nested queries with (INTERSECT, UNION, EXCEPT, IN, NOT IN), and we need the answer to the questions = [\"\"]. \\nSo, we don\\'t need JOIN and don\\'t need nested queries, then the SQL query can be classified as \"EASY\".\\nLabel: \"EASY\"\\n\\nQ: \"Get the names and CIK of registrants who are located in California.\"\\nschema_links: [registrant.registrant_name, registrant.cik, registrant.state = \"US-CA\"]\\nA: Lets think step by step. The SQL query for the question \"Get the names and CIK of registrants who are located in California.\" needs these tables = [registrant], so we don\\'t need JOIN.\\nPlus, it doesn\\'t require nested queries with (INTERSECT, UNION, EXCEPT, IN, NOT IN), and we need the answer to the questions = [\"\"]. \\nSo, we don\\'t need JOIN and don\\'t need nested queries, then the SQL query can be classified as \"EASY\".\\nLabel: \"EASY\"\\n\\nQ: \"Find the names and CIK of registrants in California, but only for those whose total assets are above 100 million.\"\\nschema_links: [registrant.registrant_name, registrant.cik, registrant.state = \"US-CA\", fund_reported_info.total_assets > 100000000]\\nA: Let\\'s analyze this. The query involves data from two tables: \"registrant\" for registrant details and \"fund_reported_info\" for total assets. Since we need to check if total assets exceed 100 million, a nested query is necessary to filter based on this condition. This is a nested query. So, the SQL query can be classified as \"NESTED.\"\\nLabel: \"NESTED\"\\n\\nQ: \"Show me all funds with total assets over 1 billion\\nrelevant_schema_links: {\\'table_columns\\': [\\'fund_reported_info.total_assets\\', \\'fund_reported_holding.asset_cat\\', \\'securities_lending.is_loan_by_fund\\'], \\'primary_keys\\': [\\'FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'FUND_REPORTED_HOLDING.ACCESSION_NUMBER\\', \\'FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'SECURITIES_LENDING.HOLDING_ID\\'], \\'foreign_keys\\': [\\'REGISTRANT.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'INTEREST_RATE_RISK.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'BORROWER.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'BORROW_AGGREGATE.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'MONTHLY_TOTAL_RETURN.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'MONTHLY_RETURN_CAT_INSTRUMENT.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'FUND_VAR_INFO.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'FUND_REPORTED_HOLDING.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'EXPLANATORY_NOTE.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'SUBMISSION.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'IDENTIFIERS.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'DEBT_SECURITY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'DEBT_SECURITY_REF_INSTRUMENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'CONVERTIBLE_SECURITY_CURRENCY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'REPURCHASE_AGREEMENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'REPURCHASE_COUNTERPARTY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'REPURCHASE_COLLATERAL.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'DERIVATIVE_COUNTERPARTY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'SWAPTION_OPTION_WARNT_DERIV.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'DESC_REF_INDEX_BASKET.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'DESC_REF_INDEX_COMPONENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'DESC_REF_OTHER.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'FUT_FWD_NONFOREIGNCUR_CONTRACT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'FWD_FOREIGNCUR_CONTRACT_SWAP.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'NONFOREIGN_EXCHANGE_SWAP.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'FLOATING_RATE_RESET_TENOR.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'OTHER_DERIV.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'OTHER_DERIV_NOTIONAL_AMOUNT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'SECURITIES_LENDING.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\']}\\nA: Lets think step by step.'}], 'model': 'gpt-4', 'frequency_penalty': 0.0, 'max_tokens': 300, 'n': 1, 'presence_penalty': 0.0, 'stream': False, 'temperature': 0.0, 'top_p': 1.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002489B098E90>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x00000248E6F1F140> server_hostname='api.openai.com' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002489C4CA8D0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEBUG: Finding matches for 'billion'\n",
      "Found 2 matches for 'billion':\n",
      "  submission.filing_date: 0.6154\n",
      "  submission.is_last_filing: 0.6154\n",
      "\n",
      "DEBUG: Finding matches for 'total'\n",
      "Found 279 matches for 'total':\n",
      "  fund_reported_info.total_assets: 1.0000\n",
      "  fund_reported_info.total_liabilities: 1.0000\n",
      "  monthly_total_return.monthly_total_return_id: 1.0000\n",
      "  monthly_total_return.monthly_total_return1: 1.0000\n",
      "  monthly_total_return.monthly_total_return2: 1.0000\n",
      "\n",
      "DEBUG: Finding matches for '1'\n",
      "Found 0 matches for '1':\n",
      "\n",
      "DEBUG: Finding matches for 'asset'\n",
      "Found 7 matches for 'asset':\n",
      "  fund_reported_holding.asset_cat: 1.0000\n",
      "  monthly_return_cat_instrument.asset_cat: 1.0000\n",
      "  fund_reported_info.total_assets: 0.9000\n",
      "  fund_reported_info.net_assets: 0.9000\n",
      "  fund_reported_info.assets_attrbt_to_misc_security: 0.9000\n",
      "\n",
      "DEBUG: Finding matches for 'fund'\n",
      "Found 279 matches for 'fund':\n",
      "  securities_lending.is_loan_by_fund: 1.0000\n",
      "  registrant.accession_number: 0.9000\n",
      "  registrant.cik: 0.9000\n",
      "  registrant.registrant_name: 0.9000\n",
      "  registrant.file_num: 0.9000\n",
      "\n",
      "Processed Schema Links:\n",
      "Table Columns: ['fund_reported_info.total_assets', 'fund_reported_holding.asset_cat', 'securities_lending.is_loan_by_fund']\n",
      "Primary Keys: ['FUND_REPORTED_INFO.ACCESSION_NUMBER', 'FUND_REPORTED_HOLDING.ACCESSION_NUMBER', 'FUND_REPORTED_HOLDING.HOLDING_ID', 'SECURITIES_LENDING.HOLDING_ID']\n",
      "Foreign Keys: ['REGISTRANT.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'INTEREST_RATE_RISK.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'BORROWER.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'BORROW_AGGREGATE.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'MONTHLY_TOTAL_RETURN.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'MONTHLY_RETURN_CAT_INSTRUMENT.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'FUND_VAR_INFO.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'FUND_REPORTED_HOLDING.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'EXPLANATORY_NOTE.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'SUBMISSION.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER', 'IDENTIFIERS.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'DEBT_SECURITY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'DEBT_SECURITY_REF_INSTRUMENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'CONVERTIBLE_SECURITY_CURRENCY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'REPURCHASE_AGREEMENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'REPURCHASE_COUNTERPARTY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'REPURCHASE_COLLATERAL.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'DERIVATIVE_COUNTERPARTY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'SWAPTION_OPTION_WARNT_DERIV.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'DESC_REF_INDEX_BASKET.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'DESC_REF_INDEX_COMPONENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'DESC_REF_OTHER.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'FUT_FWD_NONFOREIGNCUR_CONTRACT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'FWD_FOREIGNCUR_CONTRACT_SWAP.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'NONFOREIGN_EXCHANGE_SWAP.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'FLOATING_RATE_RESET_TENOR.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'OTHER_DERIV.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'OTHER_DERIV_NOTIONAL_AMOUNT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID', 'SECURITIES_LENDING.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID']\n",
      "Attempting classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 21 Nov 2024 01:47:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-annfuni26pdtuawdwdj6zorw'), (b'openai-processing-ms', b'3913'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'300000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'298528'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'294ms'), (b'x-request-id', b'req_fd7c348c2803520c19ecc638a8243c88'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=tFdi9GrQ3HxifghX6YNyB2k3.a.C4_31Cfsy3v.e96Y-1732153675-1.0.1.1-AypxH5b9j_Q2CVk8Ljx4dbshKgHlkBHiOYtvsdIVGm9_ln_FfiiGVGo.TrVpxpPZACRZ2hNPSVefmGsjhqv7jQ; path=/; expires=Thu, 21-Nov-24 02:17:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=1U3dDV0reg2JA52z5a0v_X5c9LSAjrzOiegit4wuvNk-1732153675629-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e5d039f6e0b2eff-LAX'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Thu, 21 Nov 2024 01:47:55 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-annfuni26pdtuawdwdj6zorw'), ('openai-processing-ms', '3913'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '300000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '298528'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '294ms'), ('x-request-id', 'req_fd7c348c2803520c19ecc638a8243c88'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=tFdi9GrQ3HxifghX6YNyB2k3.a.C4_31Cfsy3v.e96Y-1732153675-1.0.1.1-AypxH5b9j_Q2CVk8Ljx4dbshKgHlkBHiOYtvsdIVGm9_ln_FfiiGVGo.TrVpxpPZACRZ2hNPSVefmGsjhqv7jQ; path=/; expires=Thu, 21-Nov-24 02:17:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=1U3dDV0reg2JA52z5a0v_X5c9LSAjrzOiegit4wuvNk-1732153675629-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8e5d039f6e0b2eff-LAX'), ('content-encoding', 'br'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_fd7c348c2803520c19ecc638a8243c88\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': '# Use the the schema links to generate the SQL queries for each of the questions.\\nQ: \"Find the issuers with a balance greater than 1 million.\"\\nSchema_links: [fund_reported_holding.balance]\\nSQL: SELECT DISTINCT issuer_name \\n      FROM fund_reported_holding \\n      WHERE balance > 1000000\\n\\n```\\nExample queries set (easy difficulty) that should not require any nested queries or join statements.\\n1. \"Show me the top 5 largest funds by total assets\"\\nSELECT \\n    SERIES_NAME,\\n    TOTAL_ASSETS \\nFROM \\n    FUND_REPORTED_INFO \\nORDER BY \\n    CAST(TOTAL_ASSETS AS FLOAT) DESC \\nLIMIT 5;\\n\\n2. \"Show me the top 20 largest funds by total assets\"\\nWITH FundSizes AS (\\n    SELECT \\n        SERIES_NAME,\\n        CAST(TOTAL_ASSETS AS FLOAT) as Total_Assets,\\n        CAST(NET_ASSETS AS FLOAT) as Net_Assets\\n    FROM \\n        FUND_REPORTED_INFO\\n    WHERE \\n        TOTAL_ASSETS IS NOT NULL\\n)\\nSELECT \\n    SERIES_NAME,\\n    ROUND(Total_Assets / 1000000, 2) as Total_Assets_Millions,\\n    ROUND(Net_Assets / 1000000, 2) as Net_Assets_Millions\\nFROM \\n    FundSizes\\nORDER BY \\n    Total_Assets DESC\\nLIMIT 20;\\n\\n3. \"List all funds with net assets over 1 billion dollars\"\\nSELECT \\n    SERIES_NAME,\\n    NET_ASSETS \\nFROM \\n    FUND_REPORTED_INFO \\nWHERE \\n    CAST(NET_ASSETS AS FLOAT) > 1000000000;\\n\\n4. \"How many funds does each registrant have?\"\\nSELECT \\n    REGISTRANT_NAME,\\n    COUNT(F.SERIES_NAME) as Fund_Count\\nFROM \\n    REGISTRANT R\\n    JOIN FUND_REPORTED_INFO F \\n        ON R.ACCESSION_NUMBER = F.ACCESSION_NUMBER\\nGROUP BY \\n    REGISTRANT_NAME;\\n\\n5. \"What are the total assets of BlackRock funds?\"\\nSELECT \\n    SUM(CAST(TOTAL_ASSETS AS FLOAT)) as Total_BlackRock_Assets\\nFROM \\n    FUND_REPORTED_INFO F\\n    JOIN REGISTRANT R \\n        ON F.ACCESSION_NUMBER = R.ACCESSION_NUMBER\\nWHERE \\n    R.REGISTRANT_NAME LIKE \\'%BLACKROCK%\\';\\n\\n6. \"List all funds with their registrant names\"\\nSELECT \\n    R.REGISTRANT_NAME,\\n    F.SERIES_NAME\\nFROM \\n    REGISTRANT R\\n    JOIN FUND_REPORTED_INFO F \\n        ON R.ACCESSION_NUMBER = F.ACCESSION_NUMBER;\\n\\n7. \"Which funds have the highest total liabilities?\"\\nSELECT \\n    SERIES_NAME,\\n    TOTAL_LIABILITIES \\nFROM \\n    FUND_REPORTED_INFO \\nORDER BY \\n    CAST(TOTAL_LIABILITIES AS FLOAT) DESC \\nLIMIT 10;\\n\\n8. \"Which asset categories have the highest total investment value?\"\\nWITH AssetTotals AS (\\n    SELECT \\n        ASSET_CAT,\\n        COUNT(*) as Holdings_Count,\\n        SUM(CAST(CURRENCY_VALUE AS FLOAT)) as Total_Value\\n    FROM \\n        FUND_REPORTED_HOLDING\\n    WHERE \\n        ASSET_CAT IS NOT NULL\\n    GROUP BY \\n        ASSET_CAT\\n)\\nSELECT \\n    ASSET_CAT,\\n    Holdings_Count,\\n    ROUND(Total_Value / 1000000, 2) as Value_Millions\\nFROM \\n    AssetTotals\\nORDER BY \\n    Total_Value DESC;\\n\\n9. \"What\\'s the latest filing date for each fund?\"\\nSELECT \\n    F.SERIES_NAME,\\n    MAX(S.FILING_DATE) as Latest_Filing\\nFROM \\n    FUND_REPORTED_INFO F\\n    JOIN SUBMISSION S \\n        ON F.ACCESSION_NUMBER = S.ACCESSION_NUMBER\\nGROUP BY \\n    F.SERIES_NAME;\\n\\n10. \"Show me the largest bond funds\"\\nSELECT \\n    SERIES_NAME,\\n    ROUND(CAST(TOTAL_ASSETS AS FLOAT) / 1000000, 2) as Assets_Millions\\nFROM \\n    FUND_REPORTED_INFO\\nWHERE \\n    SERIES_NAME LIKE \\'%BOND%\\'\\nORDER BY \\n    Assets_Millions DESC\\nLIMIT 15;\\n\\n11. \"Show me the phone numbers of all Vanguard registrants\"\\nSELECT \\n    REGISTRANT_NAME,\\n    PHONE \\nFROM \\n    REGISTRANT \\nWHERE \\n    REGISTRANT_NAME LIKE \\'%VANGUARD%\\';\\n\\n12. \"Which funds have assets between 100M and 500M?\"\\nSELECT \\n    SERIES_NAME,\\n    TOTAL_ASSETS \\nFROM \\n    FUND_REPORTED_INFO \\nWHERE \\n    CAST(TOTAL_ASSETS AS FLOAT) BETWEEN 100000000 AND 500000000;\\n\\n13. \"List all registrants and their cities\"\\nSELECT \\n    REGISTRANT_NAME,\\n    CITY,\\n    STATE \\nFROM \\n    REGISTRANT \\nORDER BY \\n    STATE,\\n    CITY;\\n\\n14. \"Show me the earliest filing date for each registrant\"\\nSELECT \\n    R.REGISTRANT_NAME,\\n    MIN(S.FILING_DATE) as First_Filing\\nFROM \\n    REGISTRANT R\\n    JOIN SUBMISSION S \\n        ON R.ACCESSION_NUMBER = S.ACCESSION_NUMBER\\nGROUP BY \\n    R.REGISTRANT_NAME;\\n\\n15. \"Which funds have total assets equal to net assets?\"\\nSELECT \\n    SERIES_NAME \\nFROM \\n    FUND_REPORTED_INFO \\nWHERE \\n    TOTAL_ASSETS = NET_ASSETS;\\n\\n16. \"List all funds with \\'Income\\' in their name\"\\nSELECT \\n    SERIES_NAME,\\n    TOTAL_ASSETS \\nFROM \\n    FUND_REPORTED_INFO \\nWHERE \\n    SERIES_NAME LIKE \\'%INCOME%\\';\\n\\n17. \"Group funds into size categories based on their net assets\"\\nWITH FundSizeBuckets AS (\\n    SELECT \\n        SERIES_NAME,\\n        CAST(NET_ASSETS AS FLOAT) as Net_Assets,\\n        CASE \\n            WHEN CAST(NET_ASSETS AS FLOAT) >= 10000000000 THEN \\'Very Large (>10B)\\'\\n            WHEN CAST(NET_ASSETS AS FLOAT) >= 1000000000 THEN \\'Large (1B-10B)\\'\\n            WHEN CAST(NET_ASSETS AS FLOAT) >= 100000000 THEN \\'Medium (100M-1B)\\'\\n            ELSE \\'Small (<100M)\\'\\n        END as Size_Category\\n    FROM \\n        FUND_REPORTED_INFO\\n    WHERE \\n        NET_ASSETS IS NOT NULL\\n)\\nSELECT \\n    Size_Category,\\n    COUNT(*) as Number_of_Funds,\\n    ROUND(AVG(Net_Assets) / 1000000, 2) as Avg_Net_Assets_Millions,\\n    ROUND(MIN(Net_Assets) / 1000000, 2) as Min_Net_Assets_Millions,\\n    ROUND(MAX(Net_Assets) / 1000000, 2) as Max_Net_Assets_Millions\\nFROM \\n    FundSizeBuckets\\nGROUP BY \\n    Size_Category\\nORDER BY \\n    MIN(Net_Assets);\\n\\n18. \"Which funds have the highest liabilities to assets ratio?\"\\nSELECT \\n    SERIES_NAME,\\n    CAST(TOTAL_LIABILITIES AS FLOAT) / CAST(TOTAL_ASSETS AS FLOAT) as Liability_Ratio\\nFROM \\n    FUND_REPORTED_INFO\\nWHERE \\n    TOTAL_ASSETS != \\'0\\'\\nORDER BY \\n    Liability_Ratio DESC\\nLIMIT 5;\\n\\n19. \"List all registrants with their fund count and total assets\"\\nSELECT \\n    R.REGISTRANT_NAME,\\n    COUNT(F.SERIES_NAME) as Fund_Count,\\n    SUM(CAST(F.TOTAL_ASSETS AS FLOAT)) as Total_Assets\\nFROM \\n    REGISTRANT R\\n    JOIN FUND_REPORTED_INFO F \\n        ON R.ACCESSION_NUMBER = F.ACCESSION_NUMBER\\nGROUP BY \\n    R.REGISTRANT_NAME;\\n\\n20. \"Show me all funds with \\'Growth\\' in their name\"\\nSELECT \\n    SERIES_NAME,\\n    TOTAL_ASSETS \\nFROM \\n    FUND_REPORTED_INFO \\nWHERE \\n    SERIES_NAME LIKE \\'%GROWTH%\\';\\n\\n21. \"Show me the funds with over $1 billion in assets\"\\nWITH LargeFunds AS (\\n    SELECT \\n        SERIES_NAME,\\n        CAST(TOTAL_ASSETS AS FLOAT) / 1000000 as Assets_Millions\\n    FROM \\n        FUND_REPORTED_INFO\\n    WHERE \\n        TOTAL_ASSETS >= 1000000000\\n)\\nSELECT * FROM LargeFunds\\nORDER BY Assets_Millions DESC\\nLIMIT 15;\\n\\n22. \"List the top 10 funds by net assets\"\\nSELECT \\n    SERIES_NAME,\\n    NET_ASSETS \\nFROM \\n    FUND_REPORTED_INFO \\nORDER BY \\n    CAST(NET_ASSETS AS FLOAT) DESC \\nLIMIT 10;\\n\\n23. \"Show me all Fidelity funds\"\\nSELECT \\n    F.SERIES_NAME,\\n    F.TOTAL_ASSETS\\nFROM \\n    FUND_REPORTED_INFO F\\n    JOIN REGISTRANT R \\n        ON F.ACCESSION_NUMBER = R.ACCESSION_NUMBER\\nWHERE \\n    R.REGISTRANT_NAME LIKE \\'%FIDELITY%\\';\\n\\n24. \"Which funds have zero liabilities?\"\\nSELECT \\n    SERIES_NAME \\nFROM \\n    FUND_REPORTED_INFO \\nWHERE \\n    TOTAL_LIABILITIES = \\'0\\' \\n    OR TOTAL_LIABILITIES IS NULL;\\n\\n25. \"List all registrants with their latest fund\\'s assets\"\\nSELECT \\n    R.REGISTRANT_NAME,\\n    F.TOTAL_ASSETS\\nFROM \\n    REGISTRANT R\\n    JOIN FUND_REPORTED_INFO F \\n        ON R.ACCESSION_NUMBER = F.ACCESSION_NUMBER;\\n\\n26. \"Show me all funds with \\'International\\' in their name\"\\nSELECT \\n    SERIES_NAME,\\n    TOTAL_ASSETS \\nFROM \\n    FUND_REPORTED_INFO \\nWHERE \\n    SERIES_NAME LIKE \\'%INTERNATIONAL%\\';\\n\\n27. \"Which funds have the most cash on hand?\"\\nWITH CashHoldings AS (\\n    SELECT \\n        SERIES_NAME,\\n        ROUND(CAST(CASH_NOT_RPTD_IN_C_OR_D AS FLOAT) / 1000000, 2) as Cash_Millions\\n    FROM \\n        FUND_REPORTED_INFO\\n    WHERE \\n        CASH_NOT_RPTD_IN_C_OR_D IS NOT NULL\\n)\\nSELECT * FROM CashHoldings\\nORDER BY Cash_Millions DESC\\nLIMIT 10;\\n\\n28. \"List all funds with their submission dates\"\\nSELECT \\n    F.SERIES_NAME,\\n    S.FILING_DATE\\nFROM \\n    FUND_REPORTED_INFO F\\n    JOIN SUBMISSION S \\n        ON F.ACCESSION_NUMBER = S.ACCESSION_NUMBER;\\n\\n29. \"Show me the smallest 5 funds by total assets\"\\nSELECT \\n    SERIES_NAME,\\n    TOTAL_ASSETS \\nFROM \\n    FUND_REPORTED_INFO \\nWHERE \\n    TOTAL_ASSETS IS NOT NULL\\nORDER BY \\n    CAST(TOTAL_ASSETS AS FLOAT) ASC \\nLIMIT 5;\\n\\n30. \"Which registrants have multiple phone numbers?\"\\nSELECT \\n    REGISTRANT_NAME,\\n    COUNT(DISTINCT PHONE) as Phone_Count\\nFROM \\n    REGISTRANT\\nGROUP BY \\n    REGISTRANT_NAME\\nHAVING \\n    Phone_Count > 1;\\n\\n31. \"List all funds with \\'Bond\\' in their name\"\\nSELECT \\n    SERIES_NAME,\\n    TOTAL_ASSETS \\nFROM \\n    FUND_REPORTED_INFO \\nWHERE \\n    SERIES_NAME LIKE \\'%BOND%\\';\\n\\n32. \"Show me all registrants from Florida\"\\nSELECT \\n    REGISTRANT_NAME,\\n    CITY,\\n    ADDRESS1 \\nFROM \\n    REGISTRANT \\nWHERE \\n    STATE = \\'FL\\';\\n\\n33. \"Show me funds with the highest ratio of cash to total assets\"\\nSELECT \\n    SERIES_NAME,\\n    ROUND(CAST(CASH_NOT_RPTD_IN_C_OR_D AS FLOAT) * 100.0 / \\n          CAST(TOTAL_ASSETS AS FLOAT), 2) as Cash_Percentage\\nFROM \\n    FUND_REPORTED_INFO\\nWHERE \\n    CASH_NOT_RPTD_IN_C_OR_D IS NOT NULL \\n    AND TOTAL_ASSETS > 0\\nORDER BY \\n    Cash_Percentage DESC\\nLIMIT 15;\\n\\n34. \"List all funds with \\'Index\\' in their name\"\\nSELECT \\n    SERIES_NAME,\\n    TOTAL_ASSETS \\nFROM \\n    FUND_REPORTED_INFO \\nWHERE \\n    SERIES_NAME LIKE \\'%INDEX%\\';\\n\\n35. \"Show me the registrants with the most recent filings\"\\nSELECT \\n    R.REGISTRANT_NAME,\\n    MAX(S.FILING_DATE) as Latest_Filing\\nFROM \\n    REGISTRANT R\\n    JOIN SUBMISSION S \\n        ON R.ACCESSION_NUMBER = S.ACCESSION_NUMBER\\nGROUP BY \\n    R.REGISTRANT_NAME\\nORDER BY \\n    Latest_Filing DESC\\nLIMIT 5;\\n\\n36. \"Which funds have \\'ETF\\' in their name?\"\\nSELECT \\n    SERIES_NAME,\\n    TOTAL_ASSETS \\nFROM \\n    FUND_REPORTED_INFO \\nWHERE \\n    SERIES_NAME LIKE \\'%ETF%\\';\\n\\n37. \"List all registrants with their ZIP codes\"\\nSELECT \\n    REGISTRANT_NAME,\\n    ZIP,\\n    STATE \\nFROM \\n    REGISTRANT \\nORDER BY \\n    ZIP;\\n\\n38.\"Show me all equity-focused funds\"\\nSELECT \\n    SERIES_NAME,\\n    ROUND(CAST(TOTAL_ASSETS AS FLOAT) / 1000000, 2) as Assets_Millions\\nFROM \\n    FUND_REPORTED_INFO\\nWHERE \\n    SERIES_NAME LIKE \\'%EQUITY%\\'\\n    OR SERIES_NAME LIKE \\'%STOCK%\\'\\nORDER BY \\n    Assets_Millions DESC\\nLIMIT 20;\\n\\n39. \"Which funds have assets over 10 billion?\"\\nSELECT \\n    SERIES_NAME,\\n    TOTAL_ASSETS \\nFROM \\n    FUND_REPORTED_INFO \\nWHERE \\n    CAST(TOTAL_ASSETS AS FLOAT) > 10000000000;\\n\\n40. \"List all registrants with their country\"\\nSELECT \\n    REGISTRANT_NAME,\\n    COUNTRY,\\n    STATE \\nFROM \\n    REGISTRANT \\nORDER BY \\n    COUNTRY,\\n    STATE;\\n```\\nQ: \"Show me all funds with total assets over 1 billion\\nSchema_links: {\\'table_columns\\': [\\'fund_reported_info.total_assets\\', \\'fund_reported_holding.asset_cat\\', \\'securities_lending.is_loan_by_fund\\'], \\'primary_keys\\': [\\'FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'FUND_REPORTED_HOLDING.ACCESSION_NUMBER\\', \\'FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'SECURITIES_LENDING.HOLDING_ID\\'], \\'foreign_keys\\': [\\'REGISTRANT.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'INTEREST_RATE_RISK.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'BORROWER.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'BORROW_AGGREGATE.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'MONTHLY_TOTAL_RETURN.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'MONTHLY_RETURN_CAT_INSTRUMENT.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'FUND_VAR_INFO.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'FUND_REPORTED_HOLDING.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'EXPLANATORY_NOTE.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'SUBMISSION.ACCESSION_NUMBER = FUND_REPORTED_INFO.ACCESSION_NUMBER\\', \\'IDENTIFIERS.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'DEBT_SECURITY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'DEBT_SECURITY_REF_INSTRUMENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'CONVERTIBLE_SECURITY_CURRENCY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'REPURCHASE_AGREEMENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'REPURCHASE_COUNTERPARTY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'REPURCHASE_COLLATERAL.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'DERIVATIVE_COUNTERPARTY.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'SWAPTION_OPTION_WARNT_DERIV.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'DESC_REF_INDEX_BASKET.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'DESC_REF_INDEX_COMPONENT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'DESC_REF_OTHER.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'FUT_FWD_NONFOREIGNCUR_CONTRACT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'FWD_FOREIGNCUR_CONTRACT_SWAP.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'NONFOREIGN_EXCHANGE_SWAP.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'FLOATING_RATE_RESET_TENOR.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'OTHER_DERIV.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'OTHER_DERIV_NOTIONAL_AMOUNT.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\', \\'SECURITIES_LENDING.HOLDING_ID = FUND_REPORTED_HOLDING.HOLDING_ID\\']}\\nSQL:'}], 'model': 'gpt-4o', 'frequency_penalty': 0.0, 'max_tokens': 600, 'n': 1, 'presence_penalty': 0.0, 'stream': False, 'temperature': 0.0, 'top_p': 1.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw response: The SQL query for the question \"Show me all funds with total assets over 1 billion\" needs these tables = [fund_reported_info], so we don't need JOIN.\n",
      "Plus, it doesn't require nested queries with (INTERSECT, UNION, EXCEPT, IN, NOT IN), and we need the answer to the questions = [\"\"]. \n",
      "So, we don't need JOIN and don't need nested queries, then the SQL query can be classified as \"EASY\".\n",
      "Label: \"EASY\"\n",
      "Classification: \"EASY\"\n",
      "EASY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 21 Nov 2024 01:47:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-annfuni26pdtuawdwdj6zorw'), (b'openai-processing-ms', b'1042'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1996210'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'113ms'), (b'x-request-id', b'req_fa42ddb19d1f083b1a1d7c7572b017ed'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e5d03b8dcf52eff-LAX'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Thu, 21 Nov 2024 01:47:56 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-annfuni26pdtuawdwdj6zorw', 'openai-processing-ms': '1042', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1996210', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '113ms', 'x-request-id': 'req_fa42ddb19d1f083b1a1d7c7572b017ed', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e5d03b8dcf52eff-LAX', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_fa42ddb19d1f083b1a1d7c7572b017ed\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': '#### For the given question, use the provided tables, columns, foreign keys, and primary keys to fix the given SQLite SQL QUERY for any issues. If there are any problems, fix them and return the fixed SQLite QUERY in the output. If there are no issues, return the SQLite SQL QUERY as is in the output.\\n#### Use the following instructions for fixing the SQL QUERY:\\n1) Use the database values that are explicitly mentioned in the question.\\n2) Pay attention to the columns that are used for the JOIN by using the Foreign_keys.\\n3) Use DESC and DISTINCT when needed.\\n4) Pay attention to the columns that are used for the GROUP BY statement.\\n5) Pay attention to the columns that are used for the SELECT statement.\\n6) Only change the GROUP BY clause when necessary (Avoid redundant columns in GROUP BY).\\n7) Use GROUP BY on one column only.\\n#### Question: Show me all funds with total assets over 1 billion\\n#### SQLite SQL QUERY\\n```sql\\nSELECT \\n    SERIES_NAME,\\n    TOTAL_ASSETS \\nFROM \\n    FUND_REPORTED_INFO \\nWHERE \\n    CAST(TOTAL_ASSETS AS FLOAT) > 1000000000;\\n```\\n#### SQLite FIXED SQL QUERY'}], 'model': 'gpt-4o', 'frequency_penalty': 0.0, 'max_tokens': 350, 'n': 1, 'presence_penalty': 0.0, 'stop': ['#', ';', '\\n\\n'], 'stream': False, 'temperature': 0.0, 'top_p': 1.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    TOTAL_ASSETS \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "WHERE \n",
      "    CAST(TOTAL_ASSETS AS FLOAT) > 1000000000;\n",
      "```\n",
      "#### For the given question, use the provided tables, columns, foreign keys, and primary keys to fix the given SQLite SQL QUERY for any issues. If there are any problems, fix them and return the fixed SQLite QUERY in the output. If there are no issues, return the SQLite SQL QUERY as is in the output.\n",
      "#### Use the following instructions for fixing the SQL QUERY:\n",
      "1) Use the database values that are explicitly mentioned in the question.\n",
      "2) Pay attention to the columns that are used for the JOIN by using the Foreign_keys.\n",
      "3) Use DESC and DISTINCT when needed.\n",
      "4) Pay attention to the columns that are used for the GROUP BY statement.\n",
      "5) Pay attention to the columns that are used for the SELECT statement.\n",
      "6) Only change the GROUP BY clause when necessary (Avoid redundant columns in GROUP BY).\n",
      "7) Use GROUP BY on one column only.\n",
      "#### Question: Show me all funds with total assets over 1 billion\n",
      "#### SQLite SQL QUERY\n",
      "```sql\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    TOTAL_ASSETS \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "WHERE \n",
      "    CAST(TOTAL_ASSETS AS FLOAT) > 1000000000;\n",
      "```\n",
      "#### SQLite FIXED SQL QUERY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 21 Nov 2024 01:47:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-annfuni26pdtuawdwdj6zorw'), (b'openai-processing-ms', b'856'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'2000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1999377'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'18ms'), (b'x-request-id', b'req_54880d46000d833903538550d85df518'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8e5d03c05dbf2eff-LAX'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Thu, 21 Nov 2024 01:47:57 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-annfuni26pdtuawdwdj6zorw', 'openai-processing-ms': '856', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '2000000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '1999377', 'x-ratelimit-reset-requests': '6ms', 'x-ratelimit-reset-tokens': '18ms', 'x-request-id': 'req_54880d46000d833903538550d85df518', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8e5d03c05dbf2eff-LAX', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_54880d46000d833903538550d85df518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT \n",
      "    SERIES_NAME,\n",
      "    TOTAL_ASSETS \n",
      "FROM \n",
      "    FUND_REPORTED_INFO \n",
      "WHERE \n",
      "    TOTAL_ASSETS > 1000000000\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "# Test pipeline\n",
    "def test_pipeline():\n",
    "   vr = ValueRetrieval(schema_path='chatgpt_api/schema.json')\n",
    "   \n",
    "   test_questions = [\n",
    "       \"Show me all funds with total assets over 1 billion\",\n",
    "   ]\n",
    "\n",
    "   for question in test_questions:\n",
    "       print(\"\\n\" + \"=\"*50)\n",
    "       print(f\"\\nProcessing question: {question}\")\n",
    "       \n",
    "       # Get schema info\n",
    "       schema_info = vr.process_schema(question)\n",
    "       #print(\"\\nSchema Info:\")\n",
    "       #print(schema_info)\n",
    "       \n",
    "       # Pass to classification\n",
    "       #print(\"\\nGetting classification...\")\n",
    "       classification = process_question_classification(question, schema_info)\n",
    "       print(\"Classification:\", classification)\n",
    "\n",
    "       # Component 3\n",
    "       process_thesql = process_question_sql(question, classification, schema_info)\n",
    "       print(process_thesql)\n",
    "\n",
    "      # debugger creates the prompt that will be passsed to GPT \n",
    "       final = debuger(question, process_thesql)\n",
    "       print(final)\n",
    "       yay = GPT4_debug(final)\n",
    "       print(yay)\n",
    "# Run test \n",
    "test_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
